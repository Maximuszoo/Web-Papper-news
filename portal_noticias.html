<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papper news</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0f0f0f 0%, #1a1a1a 100%);
            color: #ffffff;
            line-height: 1.6;
            min-height: 100vh;
        }
        
        .header {
            background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%);
            padding: 2rem 0;
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
            border-bottom: 2px solid #333;
        }
        
        .header-content {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            text-align: center;
        }
        
        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
            background-size: 400% 400%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: gradientShift 3s ease-in-out infinite;
            margin-bottom: 0.5rem;
        }
        
        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }
        
        .subtitle {
            font-size: 1.1rem;
            color: #b3b3b3;
            font-weight: 300;
        }
        
        .stats {
            margin: 1.5rem 0;
            display: flex;
            gap: 2rem;
            justify-content: center;
            flex-wrap: wrap;
        }
        
        .stat-item {
            background: rgba(255,255,255,0.1);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        .category {
            margin-bottom: 3rem;
        }
        
        .category-header {
            display: flex;
            align-items: center;
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #333;
        }
        
        .category-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #ffffff;
            margin-left: 0.5rem;
        }
        
        .category-count {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            padding: 0.25rem 0.75rem;
            border-radius: 15px;
            font-size: 0.9rem;
            font-weight: 600;
            margin-left: auto;
        }
        
        .papers-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 1.5rem;
        }
        
        .paper-card {
            background: linear-gradient(135deg, #1e1e1e 0%, #2a2a2a 100%);
            border-radius: 12px;
            padding: 1.5rem;
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            border: 1px solid rgba(255,255,255,0.1);
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        
        .paper-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
            background-size: 400% 400%;
            animation: gradientShift 3s ease-in-out infinite;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(0,0,0,0.4);
            border-color: rgba(255,255,255,0.2);
        }
        
        .paper-emoji {
            font-size: 2rem;
            margin-bottom: 1rem;
            display: block;
        }
        
        .paper-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: #ffffff;
            margin-bottom: 1rem;
            line-height: 1.4;
        }
        
        .paper-summary {
            color: #b3b3b3;
            margin-bottom: 1rem;
            font-size: 0.95rem;
            line-height: 1.5;
        }
        
        .paper-points {
            color: #d4d4d4;
            margin-bottom: 1.5rem;
            font-size: 0.9rem;
            background: rgba(0,0,0,0.3);
            padding: 1rem;
            border-radius: 8px;
            border-left: 3px solid #4ecdc4;
        }
        
        .paper-footer {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: auto;
        }
        
        .paper-link {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            text-decoration: none;
            padding: 0.6rem 1.2rem;
            border-radius: 25px;
            font-weight: 600;
            font-size: 0.9rem;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .paper-link:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(255,107,107,0.3);
        }
        
        .paper-date {
            color: #888;
            font-size: 0.8rem;
        }
        
        .footer {
            background: #1e1e1e;
            padding: 2rem;
            text-align: center;
            margin-top: 3rem;
            border-top: 2px solid #333;
        }
        
        .footer p {
            color: #b3b3b3;
        }
        
        /* Filter Section Layout */
        .filter-section {
            max-width: 1200px;
            margin: 0 auto;
            padding: 1rem 2rem;
        }
        
        /* Filter Dropdown Styles */
        .dropdown {
            position: relative;
            display: inline-block;
        }
        
        .dropdown-toggle {
            background: #2a2a2a;
            color: #ffffff;
            border: 1px solid #404040;
            padding: 8px 16px;
            font-size: 0.9rem;
            font-weight: 500;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .dropdown-toggle:hover {
            background: #3a3a3a;
            border-color: #505050;
        }
        
        .dropdown-toggle::after {
            content: "▼";
            margin-left: 8px;
            font-size: 0.7rem;
            transition: transform 0.2s ease;
        }
        
        .dropdown.open .dropdown-toggle::after {
            transform: rotate(180deg);
        }
        
        .dropdown-menu {
            position: absolute;
            top: 100%;
            left: 0;
            min-width: 200px;
            background: #2a2a2a;
            border: 1px solid #404040;
            border-radius: 6px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.4);
            z-index: 1000;
            opacity: 0;
            visibility: hidden;
            transform: translateY(-8px);
            transition: all 0.2s ease;
            max-height: 250px;
            overflow-y: auto;
        }
        
        .dropdown.open .dropdown-menu {
            opacity: 1;
            visibility: visible;
            transform: translateY(0);
        }
        
        .dropdown-item {
            display: block;
            padding: 8px 12px;
            color: #ffffff;
            text-decoration: none;
            transition: background-color 0.2s ease;
            border: none;
            background: none;
            width: 100%;
            text-align: left;
            cursor: pointer;
            font-size: 0.9rem;
        }
        
        .dropdown-item:hover {
            background: #3a3a3a;
        }
        
        .dropdown-item.active {
            background: #3a3a3a;
            color: #ffffff;
        }
        
        .papers-count {
            margin: 0.5rem 0;
            color: #b3b3b3;
            font-size: 0.85rem;
            text-align: center;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .filter-section {
                text-align: center;
                padding: 1rem;
            }
            
            .stats {
                gap: 1rem;
                flex-wrap: wrap;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .papers-grid {
                grid-template-columns: 1fr;
            }
        }
        
        .scroll-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            font-size: 1.2rem;
            cursor: pointer;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            transition: all 0.3s ease;
            opacity: 0;
            visibility: hidden;
        }
        
        .scroll-top.visible {
            opacity: 1;
            visibility: visible;
        }
        
        .scroll-top:hover {
            transform: scale(1.1);
        }
    </style>
</head>
<body>
    <header class="header">
        <div class="header-content">
            <h1>🔬 ArXiv Daily Portal</h1>
            <p class="subtitle">Portal de Noticias Científicas - Últimas Investigaciones</p>
            <div class="stats">
                <div class="stat-item">📊 464 Papers</div>
                <div class="stat-item">📅 30 de September de 2025</div>
                <div class="stat-item">🏷️ 24 Categorías</div>
            </div>

        </div>
    </header>

    <section class="filter-section">
        <div class="dropdown" id="categoryDropdown">
            <button class="dropdown-toggle">
                Filtrar por categoría
            </button>
            <div class="dropdown-menu">
                <button class="dropdown-item" onclick="filterByCategory('all')">Mostrar todas</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje Automático')">Aprendizaje Automático</button>
                <button class="dropdown-item" onclick="filterByCategory('Inteligencia Artificial')">Inteligencia Artificial</button>
                <button class="dropdown-item" onclick="filterByCategory('Machine Learning')">Machine Learning</button>
                <button class="dropdown-item" onclick="filterByCategory('Ingeniería de Software')">Ingeniería de Software</button>
                <button class="dropdown-item" onclick="filterByCategory('Ingeniería Computacional, Finanzas y Ciencia')">Ingeniería Computacional, Finanzas y Ciencia</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje por Refuerzo')">Aprendizaje por Refuerzo</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje Federado')">Aprendizaje Federado</button>
                <button class="dropdown-item" onclick="filterByCategory('Optimización de Modelos')">Optimización de Modelos</button>
                <button class="dropdown-item" onclick="filterByCategory('Series Temporales')">Series Temporales</button>
                <button class="dropdown-item" onclick="filterByCategory('Redes Neuronales de Grafos')">Redes Neuronales de Grafos</button>
                <button class="dropdown-item" onclick="filterByCategory('Generación de Estructuras')">Generación de Estructuras</button>
                <button class="dropdown-item" onclick="filterByCategory('Generación de Datos')">Generación de Datos</button>
                <button class="dropdown-item" onclick="filterByCategory('Incertidumbre en LLMs')">Incertidumbre en LLMs</button>
                <button class="dropdown-item" onclick="filterByCategory('RL Robusto')">RL Robusto</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje Automático Teórico')">Aprendizaje Automático Teórico</button>
                <button class="dropdown-item" onclick="filterByCategory('Teoría del Aprendizaje Profundo')">Teoría del Aprendizaje Profundo</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje Continuo')">Aprendizaje Continuo</button>
                <button class="dropdown-item" onclick="filterByCategory('Optimización de Redes Neuronales')">Optimización de Redes Neuronales</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje por Refuerzo Multi-Agente')">Aprendizaje por Refuerzo Multi-Agente</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje en Grafos')">Aprendizaje en Grafos</button>
                <button class="dropdown-item" onclick="filterByCategory('Optimización de Inferencia')">Optimización de Inferencia</button>
                <button class="dropdown-item" onclick="filterByCategory('Análisis de Arquitecturas')">Análisis de Arquitecturas</button>
                <button class="dropdown-item" onclick="filterByCategory('Teoría de Modelos de Difusión')">Teoría de Modelos de Difusión</button>
                <button class="dropdown-item" onclick="filterByCategory('Ciencia de Datos')">Ciencia de Datos</button>
            </div>
        </div>
    </section>

    <main class="container">

        <section class="category" data-category="Aprendizaje Automático">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje Automático</h2>
                <span class="category-count">202</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Localización de Ataques Adversariales para Producir Ruido Más Imperceptible</h3>
                    <p class="paper-summary">📝 Evalúa ataques adversariales localizados que restringen el ruido a regiones específicas. Los ataques localizados logran mayor imperceptibilidad pero requieren más esfuerzo computacional. Métodos iterativos como PGD mantienen mejor tasa de éxito bajo localización.</p>
                    <div class="paper-points">• Ruido localizado vs global
•  Mayor PSNR y SSIM
•  Reducción moderada en tasa de éxito</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22710" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">El Aprendizaje en Contexto Puede Realizar Aprendizaje Continuo Como Humanos</h3>
                    <p class="paper-summary">📝 Investiga el aprendizaje continuo en contexto (ICCL) donde LLMs retienen conocimiento sin actualizar parámetros. Descubre que se beneficia de práctica distribuida similar a humanos. Modelos con atención lineal muestran patrones más humanos.</p>
                    <div class="paper-points">• Aprendizaje continuo sin actualizaciones
•  Beneficio de práctica distribuida
•  Patrones de retención humanos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22764" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Aprendizaje Distribuido Eficiente en Comunicación e Interoperable</h3>
                    <p class="paper-summary">📝 Propone framework de aprendizaje colaborativo que soporta heterogeneidad de modelos mediante bloques modulares. Logra mayor eficiencia en comunicación que FL y FSL manteniendo parámetros privados. Permite composición modular durante inferencia.</p>
                    <div class="paper-points">• Soporte para arquitecturas heterogéneas
•  Bloques personalizados y modulares
•  Comunicación eficiente y privacidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22823" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Sobre la Capacidad de la Auto-Atención</h3>
                    <p class="paper-summary">📝 Formaliza la capacidad de self-attention para recuperar relaciones entre tokens. Deriva ley de escalado de capacidad D_K = Θ(m&#x27; log m&#x27;/d_model). Explica beneficio de multi-head attention para mitigar interferencia en compresión.</p>
                    <div class="paper-points">• Ley de escalado de capacidad
•  Fundamentación para atención multi-cabeza
•  Mitigación de interferencia en compresión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22840" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Límite en la Mesa: Ataques de Caja Negra Eficientes Basados en Decisiones para Datos Estructurados</h3>
                    <p class="paper-summary">📝 Introduce ataque adversarial de caja negra para datos tabulares que combina estimación libre de gradientes con búsqueda iterativa en límites. Compromete &gt;90% del conjunto de prueba con pocas consultas. Revela vulnerabilidad crítica en modelos tabulares.</p>
                    <div class="paper-points">• Ataque para datos estructurados
•  Alta tasa de éxito con pocas consultas
•  Vulnerabilidad en modelos clásicos y LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22850" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">RLHF de Margen Adaptativo mediante Preferencia sobre Preferencias</h3>
                    <p class="paper-summary">📝 Propone DPO-PoP que incorpora márgenes adaptativos basados en preferencias sobre preferencias. Supera a DPO con márgenes fijos y ground-truth en UltraFeedback. Identifica trade-off entre rendimiento discriminativo y generativo.</p>
                    <div class="paper-points">• Márgenes adaptativos por preferencias ordinales
•  Mejora sobre DPO estándar
•  Trade-off discriminativo-generativo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22851" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Ataques sin Observación sobre Aprendizaje Online para Ranking</h3>
                    <p class="paper-summary">📝 Presenta framework de ataque a algoritmos OLTR que promueve items objetivo en top-K recomendaciones. Estrategias CascadeOFA y PBMOFA requieren O(log T) manipulaciones. Induce regret lineal en algoritmo de aprendizaje.</p>
                    <div class="paper-points">• Ataques coordinados a OLTR
•  Promoción de items objetivo
•  Regret lineal con pocas manipulaciones</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22855" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">El Muestreo de Vecindarios No Aprende la Misma Red Neuronal de Grafos</h3>
                    <p class="paper-summary">📝 Analiza teóricamente métodos de muestreo de vecindarios en GNNs usando kernels tangentes neurales. Muestra que diferentes enfoques producen posteriores Gaussianas distintas. Ningún método domina consistentemente.</p>
                    <div class="paper-points">• Análisis teórico de muestreo
•  Posteriores Gaussianas diferentes
•  Ningún método domina consistentemente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22868" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔊 Del Ruido al Conocimiento: Estudio Comparativo de Modelos de Detección de Anomalías Acústicas en Centrales Hidroeléctricas de Bombeo</h3>
                    <p class="paper-summary">📝 Compara métodos de detección de anomalías acústicas para mantenimiento predictivo en centrales hidroeléctricas. Evalúa tres modelos (LSTM AE, K-Means, OC-SVM) en condiciones reales de alto ruido. One-Class SVM logró el mejor equilibrio entre precisión (ROC AUC 0.966-0.998) y tiempo de entrenamiento.</p>
                    <div class="paper-points">• Detección acústica en entornos industriales ruidosos
•  comparación de modelos ML
•  aplicación en central hidroeléctrica real
•  One-Class SVM como mejor opción</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22881" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ FedCF: Predicción Conformal Federada Justa</h3>
                    <p class="paper-summary">📝 Extiende el marco de Predicción Conformal Justa al aprendizaje federado, incorporando garantías de equidad entre subgrupos demográficos. Valida empíricamente en múltiples dominios, auditando brechas de equidad en modelos federados.</p>
                    <div class="paper-points">• Aprendizaje federado con equidad
•  predicción conformal
•  garantías de cobertura condicional
•  auditoría de modelos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22907" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Alineación de Variedades Guiada con Autoencoders Gemelos Regularizados por Geometría</h3>
                    <p class="paper-summary">📝 Propone un framework de aprendizaje de representaciones compartidas entre dominios usando autoencoders gemelos con regularización geométrica. Mejora la generalización a datos no vistos y se aplica exitosamente en diagnóstico de Alzheimer con datos multimodales.</p>
                    <div class="paper-points">• Alineación de variedades
•  autoencoders gemelos
•  generalización cruzada
•  aplicación médica multimodal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22913" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Repensando la Destilación de Modelos de Lenguaje Grande: Una Perspectiva de Proceso de Decisión Markoviano Restringido</h3>
                    <p class="paper-summary">📝 Formula la destilación de LLMs como problema de aprendizaje por refuerzo restringido, maximizando recompensas específicas mientras limita la divergencia del modelo profesor. Logra mejor razonamiento matemático y satisfacción de restricciones vs métodos baselines.</p>
                    <div class="paper-points">• Destilación de LLMs
•  aprendizaje por refuerzo restringido
•  razonamiento matemático
•  eficiencia computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22921" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📦 MonoCon: Framework para Aprendizaje de Representaciones Ultra-compactas de Alta Fidelidad usando Restricciones de Monotonicidad</h3>
                    <p class="paper-summary">📝 Introduce MonoCon, que usa perceptrones monotónicos para aprender representaciones compactas y robustas. Logra embeddings 9x más compactos y 1.5x más robustos en CIFAR-100, manteniendo 99% de precisión.</p>
                    <div class="paper-points">• Representaciones compactas
•  aprendizaje métrico
•  restricciones funcionales
•  aplicaciones edge computing</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22931" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Entrenamiento con Cuantización Óptimo en Cómputo</h3>
                    <p class="paper-summary">📝 Investiga la asignación óptima de cómputo entre fases de precisión completa y cuantización. Deriva leyes de escalado que predicen ratios óptimos y propone enfoque de fusión que ahorra cómputo significativamente.</p>
                    <div class="paper-points">• Cuantización-aware training
•  optimización de cómputo
•  leyes de escalado
•  eficiencia en entrenamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22935" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Entendiendo SOAP desde la Perspectiva del Blanqueamiento de Gradientes</h3>
                    <p class="paper-summary">📝 Analiza algoritmos de optimización (Adam, Shampoo, SOAP) desde la perspectiva de blanqueamiento de gradientes. Demuestra equivalencia teórica entre SOAP y Shampoo, con resultados empíricos similares en modelado de lenguaje.</p>
                    <div class="paper-points">• Optimización de redes neuronales
•  blanqueamiento de gradientes
•  SOAP vs Shampoo
•  equivalencia teórica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22938" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">SINQ: Cuantización Normalizada por Sinkhorn para Pesos de LLM de Baja Precisión sin Calibración</h3>
                    <p class="paper-summary">📝 Propone SINQ, método de cuantización post-entrenamiento que usa algoritmo Sinkhorn-Knopp para normalizar varianzas y manejar valores atípicos. Mejora significativamente perplexity en modelos Qwen3 y DeepSeek-V2.5.</p>
                    <div class="paper-points">• Cuantización post-entrenamiento
•  manejo de outliers
•  normalización Sinkhorn
•  modelos de lenguaje grandes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22944" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌪️ Meta-Aprendizaje de Operadores Neurales de Fourier para Inversión de Hessiana y Asimilación de Datos Variacional Mejorada</h3>
                    <p class="paper-summary">📝 Usa meta-aprendizaje con Operadores Neurales de Fourier para aproximar el inverso del Hessiano en problemas de asimilación de datos. Reduce error relativo en 62% e iteraciones en 17% vs gradiente conjugado estándar.</p>
                    <div class="paper-points">• Asimilación de datos
•  operadores neurales de Fourier
•  inversión de Hessiana
•  predicción meteorológica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22949" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Aprendices GDR: Aprendizaje Ortogonal de Modelos Generativos para Resultados Potenciales</h3>
                    <p class="paper-summary">📝 Introduce aprendices GDR, suite de modelos generativos con ortogonalidad de Neyman para estimar distribuciones de resultados potenciales. Desarrolla variantes con flujos normales, GANs, VAEs y modelos de difusión, demostrando superioridad sobre métodos existentes.</p>
                    <div class="paper-points">• Inferencia causal
•  modelos generativos
•  ortogonalidad de Neyman
•  doble robustez
•  resultados potenciales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22953" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Juez LLM Doblemente Robusto: Estimación Externamente Válida con Personas Imperfectas</h3>
                    <p class="paper-summary">📝 Propone un marco de estimación doblemente robusto para abordar el sesgo de muestreo en evaluaciones de IA generativa. Combina calificaciones de personas simuladas por LLM con calificaciones humanas sesgadas para producir estimaciones válidas de calidad del sistema. Se valida teóricamente y mediante un marco de simulación de personas.</p>
                    <div class="paper-points">• Evaluación de IA generativa
•  sesgo de muestreo externo
•  personas LLM como jueces
•  estimación doblemente robusta
•  validación teórica y experimental</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22957" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo con Políticas de Difusión Discreta para Espacios de Acción Combinatorios</h3>
                    <p class="paper-summary">📝 Introduce un marco novedoso para entrenar modelos de difusión discreta como políticas efectivas en espacios de acción combinatorios grandes. Combina descenso de espejo de políticas con modelos de difusión expresivos para lograr estabilidad y eficiencia muestral superior en benchmarks desafiantes.</p>
                    <div class="paper-points">• Espacios de acción combinatorios
•  modelos de difusión discreta
•  descenso de espejo de políticas
•  eficiencia muestral
•  generación de secuencias de ADN</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22963" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Modelado de Crítico Funcional para Actor-Crítico Fuera de Política Convergente</h3>
                    <p class="paper-summary">📝 Presenta un nuevo marco actor-crítico que aborda los desafíos del aprendizaje fuera de política mediante modelado de crítico funcional. Proporciona convergencia demostrable bajo la &#x27;tríada mortal&#x27; y demuestra efectividad en tareas de control mediante arquitecturas de red neuronal especializadas.</p>
                    <div class="paper-points">• Aprendizaje por refuerzo fuera de política
•  actor-crítico
•  tríada mortal
•  convergencia demostrable
•  aproximación de funciones lineales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22964" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Agrupamiento Informado por Forma de Datos Funcionales Multidimensionales mediante Autoencoders Funcionales Profundos</h3>
                    <p class="paper-summary">📝 Propone FAEclust, un marco de autoencoder funcional para análisis de clusters de datos funcionales multidimensionales. Incorpora regularización innovadora y objetivo de agrupamiento resistente a variaciones de fase, con propiedad de aproximación universal demostrada.</p>
                    <div class="paper-points">• Datos funcionales multidimensionales
•  autoencoders profundos
•  agrupamiento informado por forma
•  aproximación universal
•  variaciones de fase</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22969" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">OptiMind: Enseñando a LLMs a Pensar como Expertos en Optimización</h3>
                    <p class="paper-summary">📝 Integra sistemáticamente experiencia en optimización para mejorar la precisión de formulación de programas lineales enteros mixtos por LLMs. Combina datos limpios con estrategias de inferencia multituda que incorporan retroalimentación del solver y resúmenes de errores.</p>
                    <div class="paper-points">• Programación matemática
•  LLMs para optimización
•  programación lineal entera mixta
•  refinamiento iterativo
•  retroalimentación de solver</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22979" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Modelado MDP para Programas Estocásticos Multietapa</h3>
                    <p class="paper-summary">📝 Estudia programas estocásticos multietapa que incorporan características de procesos de decisión de Markov. Extiende gráficos de políticas para incluir incertidumbre dependiente de decisiones y aprendizaje estadístico limitado, con métodos de solución basados en programación dinámica dual estocástica.</p>
                    <div class="paper-points">• Programación estocástica multietapa
•  MDPs estructurados
•  gráficos de políticas
•  programación dinámica dual
•  espacios continuos de estado y acción</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22981" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">T-TAMER: Domando Compromisos en Servicio de ML con Garantías</h3>
                    <p class="paper-summary">📝 Presenta un marco general para gestionar compromisos en servicio de modelos de ML, formalizado como proceso de decisión multietapa. Demuestra que la recall es necesaria y suficiente para garantías de rendimiento demostrables, con validación experimental en modelos early-exit.</p>
                    <div class="paper-points">• Servicio de ML
•  modelos cascada
•  early-exit
•  compromisos precisión-latencia
•  garantías teóricas
•  recall de modelos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22992" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Análisis de Autoencoders Variacionales</h3>
                    <p class="paper-summary">📝 Investiga la incorporación de métodos variacionales en autoencoders dispersos (SAEs) para mejorar la organización e interpretabilidad de características. El vSAE propuesto underperforma SAE estándar debido a regularización excesiva, aunque mejora independencia de características.</p>
                    <div class="paper-points">• Autoencoders dispersos
•  métodos variacionales
•  interpretabilidad de redes
•  divergencia KL
•  características muertas
•  regularización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22994" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Calibración Multiclase Eficiente en Muestras bajo</h3>
                    <p class="paper-summary">📝 Propone una nueva definición de error de calibración que interpola entre nociones establecidas, con algoritmo que calibra predictores usando número polinomial de muestras. Aplica análisis de datos adaptativo con sobrecarga logarítmica para mejorar dependencia del error.</p>
                    <div class="paper-points">• Calibración multiclase
•  complejidad de muestras
•  análisis adaptativo
•  predictores probabilísticos
•  error de calibración interpolado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23000" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌌 Generación de Trayectorias Multi-Sistema Físicamente Plausible y Descubrimiento de Simetrías</h3>
                    <p class="paper-summary">📝 Introduce SPS-GAN, que captura dinámicas de múltiples sistemas y generaliza a parámetros físicos no vistos. Combina redes neuronales hamiltonianas en arquitectura GAN condicional para descubrir estructura del espacio de configuración y generar trayectorias físicamente plausibles.</p>
                    <div class="paper-points">• Dinámicas físicas
•  GAN condicional
•  redes hamiltonianas
•  descubrimiento de simetrías
•  generalización multi-sistema
•  espacio de configuración</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23003" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">MoE-PHDS: Un checkpoint MoE para esparsidad flexible en tiempo de ejecución</h3>
                    <p class="paper-summary">📝 Método que transforma un único modelo MoE preentrenado en una superficie de control de esparsidad global mediante fine-tuning ligero. Permite ajustar el nivel de esparsidad en inferencia sin cambiar checkpoints ni arquitectura, manteniendo el rendimiento en múltiples puntos operativos.</p>
                    <div class="paper-points">• Control flexible de esparsidad en tiempo real
•  Sin cambios arquitectónicos
•  Mejora acuerdo cruzado de esparsidad hasta 22%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23012" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">Sobre la Gavificación del Paso de Mensajes de Orden Superior</h3>
                    <p class="paper-summary">📝 Propone usar teoría de haces para mejorar el paso de mensajes en estructuras topológicas complejas. Generaliza el Laplaciano de Hodge mediante cohomología de haces, permitiendo interfaces más expresivas entre descriptores locales y globales en aprendizaje topológico.</p>
                    <div class="paper-points">• Teoría de haces para aprendizaje topológico
•  Generalización del Laplaciano de Hodge
•  Mensajería de orden superior más expresiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23020" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Rastreando la Geometría de Representación en Modelos de Lenguaje</h3>
                    <p class="paper-summary">📝 Analiza la evolución geométrica de representaciones durante preentrenamiento y post-entrenamiento. Identifica tres fases: colapso inicial, expansión de dimensionalidad y compresión anisotrópica, correlacionadas con mejora en tareas posteriores.</p>
                    <div class="paper-points">• Tres fases geométricas en preentrenamiento
•  Compresión anisotrópica mejora rendimiento
•  Efectos distintos de SFT
•  DPO y RLVR</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23024" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Entendiendo la Interferencia Catastrófica en Representaciones Latentes</h3>
                    <p class="paper-summary">📝 Propone marco teórico que formula el olvido catastrófico como problema de identificación. Método de dos etapas identifica variables latentes compartidas entre configuraciones para mitigar la interferencia durante el aprendizaje continuo.</p>
                    <div class="paper-points">• Marco teórico basado en identificación
•  Método de dos etapas con MLE y KL
•  Mitiga interferencia catastrófica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23027" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">DPFNAS: Búsqueda de Arquitectura Neuronal Federada con Privacidad Diferencial para 6G</h3>
                    <p class="paper-summary">📝 Framework federado que combina privacidad diferencial personalizada y búsqueda de arquitectura neuronal. Protege datos de entrenamiento mientras genera arquitecturas localmente personalizadas para inteligencia en edge 6G.</p>
                    <div class="paper-points">• Privacidad diferencial personalizada
•  NAS consciente de privacidad
•  Mejora accuracy 6.82% vs métodos anteriores</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23030" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🛡️ GuardNet: Filtrado con Atención en Grafos para Defensa contra Jailbreaks en LLMs</h3>
                    <p class="paper-summary">📝 Framework jerárquico que detecta y filtra prompts de jailbreak antes de la inferencia. Combina estructura lingüística y patrones contextuales mediante redes neuronales de grafos en dos niveles: prompt y token.</p>
                    <div class="paper-points">• Detección jerárquica de jailbreaks
•  Mejora F1 hasta 99.8%
•  Baja latencia y buena generalización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23037" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">IsingFormer: Aumentando Temple Paralelo con Propuestas Aprendidas</h3>
                    <p class="paper-summary">📝 Transformer entrenado con muestras de equilibrio que genera configuraciones completas de spines como propuestas globales para Temple Paralelo. Acelera muestreo MCMC y optimización en paisajes complejos.</p>
                    <div class="paper-points">• Propuestas globales para MCMC
•  Reduce tiempo de equilibración
•  Generaliza a temperaturas no vistas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23043" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌐 Más Allá de la Agregación: Guiando Clientes en Aprendizaje Federado Heterogéneo</h3>
                    <p class="paper-summary">📝 Paradigma novedoso donde el servidor federado no solo agrega modelos, sino que guía nuevas consultas hacia el cliente más apropiado. Aprovecha la heterogeneidad como característica mediante marco basado en verosimilitud empírica.</p>
                    <div class="paper-points">• Guía de asignación de consultas
•  Aprovecha heterogeneidad estadística
•  Mejora precisión y eficiencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23049" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👁️ Entendiendo el Prior Lingüístico en LVLMs mediante Cadena-de-Embeddings Contrastiva</h3>
                    <p class="paper-summary">📝 Analiza mecanismos internos de prior lingüístico en modelos visión-lenguaje mediante dinámica de representaciones por capas. Identifica Punto de Integración Visual crítico y propone estimador para cuantificar influencia visual.</p>
                    <div class="paper-points">• Análisis de dinámica por capas
•  Punto de Integración Visual universal
•  Estimador TVI para prior lingüístico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23050" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Dinámicas de Aprendizaje: Programaciones Generativas desde ODEs Latentes</h3>
                    <p class="paper-summary">📝 Programador de tasas de aprendizaje que modela el entrenamiento como sistema dinámico. Predice programaciones óptimas a largo plazo basado en representaciones latentes aprendidas de ejecuciones anteriores, logrando state-of-the-art.</p>
                    <div class="paper-points">• Modelado dinámico del aprendizaje
•  Programaciones especializadas no paramétricas
•  Mejor generalización en regiones planas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23052" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">F-Adapter: Ajuste Eficiente de Parámetros Adaptativo en Frecuencia para Aprendizaje Automático Científico</h3>
                    <p class="paper-summary">📝 Primer estudio sistemático de ajuste eficiente de parámetros en modelos de operadores científicos. Los adaptadores superan a LoRA en modelos de operadores grandes. Se introduce F-Adapter que asigna capacidad basada en complejidad espectral, logrando resultados state-of-the-art en benchmarks 3D de Navier-Stokes.</p>
                    <div class="paper-points">• Adaptadores vs LoRA en dominios científicos
•  Análisis teórico en dominio de Fourier
•  F-Adapter con asignación espectral adaptativa
•  Resultados SOTA en dinámica de fluidos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23173" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">ZeroSiam: Arquitectura Siamesa Eficiente para Optimización de Entropía en Tiempo de Prueba sin Colapso</h3>
                    <p class="paper-summary">📝 Método que previene el colapso en minimización de entropía durante prueba mediante arquitectura siamesa asimétrica. Usa predictor aprendible y operador stop-gradient antes del clasificador. Funciona en modelos pequeños propensos a colapso y mejora razonamiento en LLMs.</p>
                    <div class="paper-points">• Prevención de colapso en minimización de entropía
•  Arquitectura siamesa asimétrica
•  Eficiente con sobrecarga negligible
•  Aplicable a visión y LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23183" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">CoSIFL: Aprendizaje Federado Colaborativo Seguro e Incentivado con Privacidad Diferencial</h3>
                    <p class="paper-summary">📝 Framework que integra alarmas proactivas para seguridad, privacidad diferencial local contra ataques de inferencia, y esquema de incentivos basado en Stackelberg. Formulación de juego de dos etapas entre servidor y clientes con equilibrio único demostrado.</p>
                    <div class="paper-points">• Seguridad robusta con alarmas proactivas
•  Privacidad diferencial local
•  Esquema de incentivos tipo Stackelberg
•  Análisis de equilibrio en juego servidor-cliente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23190" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Cerrando la Brecha entre Promesa y Rendimiento para Cuantización FP4 de Microescala</h3>
                    <p class="paper-summary">📝 Estudio completo de formatos FP4 (MXFP4, NVFP4) mostrando problemas prácticos. Se introduce MR-GPTQ con transformadas de Hadamard y optimizaciones específicas para FP4. Logra aceleraciones de 2.2x-4x end-to-end manteniendo precisión.</p>
                    <div class="paper-points">• Análisis de problemas en cuantización FP4
•  MR-GPTQ con transformadas de Hadamard
•  Kernels GPU de alto rendimiento
•  Aceleración significativa con precisión comparable</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23202" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia la Mejora Monótona en Aprendizaje por Refuerzo en Contexto</h3>
                    <p class="paper-summary">📝 Identifica &#x27;Ambiguidad Contextual&#x27; como problema en ICRL donde acciones estocásticas generan historiales engañosos. Introduce CV-ICRL con Valor Contextual como señal explícita del rendimiento ideal alcanzable dado el contexto actual.</p>
                    <div class="paper-points">• Solución a Ambiguidad Contextual
•  Valor Contextual como señal de rendimiento ideal
•  Mejora monótona demostrada
•  Validación en Dark Room y Minigrid</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23209" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">OSCAR: Descubrimiento Causal Multietiqueta de Una Sola Pasada en Secuencias de Eventos de Alta Dimensión</h3>
                    <p class="paper-summary">📝 Método one-shot que infiere Límites de Markov por secuencia usando dos Transformers preentrenados como estimadores de densidad. Escala a datasets del mundo real con 29,100 eventos y 474 etiquetas, recuperando estructuras causales en minutos.</p>
                    <div class="paper-points">• Descubrimiento causal paralelo y eficiente
•  Sin tests de independencia condicional costosos
•  Escalable a miles de tipos de eventos
•  Aplicación en diagnóstico automotriz</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23213" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📡 WirelessMathLM: Enseñando Razonamiento Matemático para LLMs en Comunicaciones Inalámbricas con Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">📝 Entrena modelos compactos (0.5B-7B) en matemáticas de comunicaciones inalámbricas usando RL con recompensas verificables. WirelessMathBench-XL con 4,027 problemas. Modelo 7B alcanza 39.5% de precisión, acercándose a GPT-4o.</p>
                    <div class="paper-points">• RL con recompensas verificables
•  Benchmark especializado de 4
• 027 problemas
•  Modelos compactos compitiendo con grandes
•  Transferencia positiva a matemáticas generales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23219" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">SPEC-RL: Acelerando Aprendizaje por Refuerzo On-Policy mediante Rollouts Especulativos</h3>
                    <p class="paper-summary">📝 Framework que integra decodificación especulativa con proceso de rollout en RL. Reutiliza segmentos de trayectorias previas como prefijos especulativos, reduciendo tiempo de rollout 2-3x sin comprometer calidad de políticas.</p>
                    <div class="paper-points">• Reducción de redundancia en rollouts
•  Mecanismo draft-and-verify
•  Integración con PPO
•  GRPO
•  DAPO
•  Aceleración 2-3x demostrada en benchmarks de razonamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23232" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Más Datos o Mejores Algoritmos: Aumento con Difusión Latente para Regresión Profunda Desbalanceada</h3>
                    <p class="paper-summary">📝 Propone LatentDiff, framework que usa modelos de difusión condicionales con generación basada en prioridad para sintetizar características en espacio latente. Mejora predicción en regiones minoritarias manteniendo precisión general.</p>
                    <div class="paper-points">• Solución a nivel de datos para regresión desbalanceada
•  Difusión condicional en espacio latente
•  Computacionalmente eficiente
•  Aplicable a múltiples modalidades</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23240" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Privacidad Diferencial Ponderada por Tokens Adaptativa para LLMs: No Todos los Tokens Requieren Igual Protección</h3>
                    <p class="paper-summary">📝 ATDP asigna diferentes pesos de gradiente a tokens sensibles y no sensibles. Reduce tiempo de entrenamiento DP en ~90% con protección comparable. Inyecta ruido dirigido principalmente en parámetros de tokens sensibles.</p>
                    <div class="paper-points">• Protección diferenciada por sensibilidad de tokens
•  Reducción de 90% en tiempo de entrenamiento
•  Post-procesamiento liviano
•  Integración con pipelines DP existentes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23246" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Interpretabilidad de LLM con Representación Temporal-Instantánea Identificable</h3>
                    <p class="paper-summary">📝 Propone un marco de aprendizaje de representación causal temporal para mejorar la interpretabilidad de modelos de lenguaje grandes. Captura relaciones causales retardadas e instantáneas en espacios conceptuales de alta dimensión. Demuestra eficacia en datasets sintéticos y descubre relaciones conceptuales significativas.</p>
                    <div class="paper-points">• Framework identificable de representación causal
•  Modelado de dependencias temporales e instantáneas
•  Garantías teóricas para interpretabilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23323" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Ajuste Fino Robusto desde Modelos Preentrenados No-Robustos: Mitigando Transferencia Subóptima con Programación Adversaria</h3>
                    <p class="paper-summary">📝 Investiga el ajuste fino robusto de modelos no-robustos preentrenados, identificando el problema de transferencia subóptima. Propone Epsilon-Scheduling para programar la fuerza de perturbación durante el entrenamiento. Introduce métrica de robustez esperada para evaluación comprehensiva.</p>
                    <div class="paper-points">• Fenómeno de transferencia subóptima
•  Programación Epsilon para optimizar transferencia
•  Métrica de robustez esperada</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23325" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Entrando en la Era de Modelos de Difusión Discretos: Un Benchmark para Puentes de Schrödinger y Transporte Óptimo Entrópico</h3>
                    <p class="paper-summary">📝 Introduce el primer benchmark para evaluar métodos de Puente de Schrödinger en espacios discretos. Proporciona pares de distribuciones con soluciones analíticas conocidas. Presenta nuevos algoritmos DLightSB y α-CSBM para resolver el problema.</p>
                    <div class="paper-points">• Primer benchmark para Puentes de Schrödinger discretos
•  Soluciones analíticas conocidas
•  Nuevos algoritmos eficientes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23348" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Aterrizando con el Score: Optimización Riemanniana mediante Desruido</h3>
                    <p class="paper-summary">📝 Propone métodos de optimización Riemanniana sobre variedades implícitas usando funciones de score de modelos de difusión. Conecta distribuciones de datos con operaciones geométricas necesarias para optimización. Demuestra efectividad en tareas de control basadas en datos.</p>
                    <div class="paper-points">• Optimización Riemanniana con modelos de difusión
•  Conexión función score-operaciones geométricas
•  Algoritmos DLF y DRGD con garantías teóricas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23357" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Emergencia de Superposición: Revelando la Dinámica de Entrenamiento de Cadena de Pensamiento Continuo</h3>
                    <p class="paper-summary">📝 Analiza teóricamente cómo emerge el mecanismo de superposición durante el entrenamiento de transformers con pensamiento continuo. Revela que el logit de coincidencia de índices se balancea entre exploración y explotación. Valida experimentalmente el crecimiento controlado de logits.</p>
                    <div class="paper-points">• Análisis teórico de dinámicas de entrenamiento
•  Mecanismo de superposición en CoT continuo
•  Balance exploración-explotación</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23365" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Importancia de Características Basada en Splines en Redes Kolmogorov-Arnold: Marco para Reducción de Dimensionalidad en Datos Tabulares</h3>
                    <p class="paper-summary">📝 Propone métodos de selección de características basados en redes KAN para datos tabulares. Introduce cuatro selectores KAN que aprovechan la parametrización por splines para medir importancia. Compara favorablemente con métodos clásicos en múltiples benchmarks.</p>
                    <div class="paper-points">• Selección de características con redes KAN
•  Cuatro selectores basados en splines
•  Interpretabilidad y captura de no linealidades</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23366" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕸️ Grafica Tu Propio Prompt: Regularización de Consistencia de Grafos para Representaciones Semánticas</h3>
                    <p class="paper-summary">📝 Presenta Graph Consistency Regularization (GCR), framework que inyecta estructuras de grafos relacionales en el aprendizaje. Alinea grafos de similitud de características con grafos de predicción modulados por indicadores intra-clase. Mejora la estructura semántica sin modificar arquitectura.</p>
                    <div class="paper-points">• Auto-prompting con estructuras de grafos
•  Capas de consistencia de grafos parameter-free
•  Alineamiento multi-capa con ponderación adaptativa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23373" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Aprendizaje de Trayectorias Consciente del Planificador en Entrenamiento de Modelos de Lenguaje por Difusión</h3>
                    <p class="paper-summary">📝 Aborda el desajuste entre trayectorias de entrenamiento e inferencia en modelos de difusión de lenguaje. Deriva un nuevo límite inferior de evidencia planificado (P-ELBO). Propone PAPL para alinear entrenamiento e inferencia bajo planificadores no uniformes.</p>
                    <div class="paper-points">• Desajuste entrenamiento-inferencia en difusión
•  Nuevo objetivo P-ELBO
•  Mejoras consistentes en texto
•  código y proteínas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23405" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔗 Atención a los Enlaces: Atención Trans-Capa para Predicción de Enlaces en Redes Múltiples</h3>
                    <p class="paper-summary">📝 Propone framework de atención cruzada para predicción de enlaces en redes múltiples. Construye secuencias de vistas por capa y aplica self-attention para fusionar evidencia. Introduce protocolos libres de fuga y pool de candidatos Union-Set.</p>
                    <div class="paper-points">• Atención cruzada para dependencias inter-capa
•  Modelos Trans-SLE y Trans-GAT
•  Protocolos de generalización sin fuga</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23409" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💾</span>
                    <h3 class="paper-title">PATCH: Esparsidad Híbrida Aprendible a Nivel de Tile para LLMs</h3>
                    <p class="paper-summary">📝 Introduce PATCH, framework de esparsidad híbrida que permite ratios continuos entre 0% y 50%. Particiona matrices en tiles densos o 2:4 sparse mediante máscaras aprendibles. Logra aceleración práctica manteniendo precisión superior a métodos 2:4.</p>
                    <div class="paper-points">• Esparsidad híbrida tile-level
•  Ratio de esparsidad continuo y aprendible
•  Aceleración GPU con mejor precisión que 2:4</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23410" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">URS: Solucionador Unificado de Enrutamiento Neuronal para Generalización Cero Disparos entre Problemas</h3>
                    <p class="paper-summary">📝 Propone URS, un solucionador de enrutamiento neuronal unificado capaz de generalización cero disparos para múltiples variantes de problemas de enrutamiento de vehículos usando un solo modelo. Utiliza representación unificada de datos y módulos de sesgo mixto para aprender sesgos geométricos y relacionales. Logra manejar más de 100 variantes VRP sin ajuste fino.</p>
                    <div class="paper-points">• Generalización cero disparos para VRP
•  Representación unificada de datos
•  Módulo de sesgo mixto
•  Mecanismo de satisfacción de restricciones con LLM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23413" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">LOTFormer: Atención Lineal Doblemente Estocástica mediante Transporte Óptimo de Bajo Rango</h3>
                    <p class="paper-summary">📝 Introduce LOTFormer, un mecanismo de atención que combina complejidad lineal temporal con mapas de atención doblemente estocásticos. Utiliza transporte óptimo entrópico condicionado a una medida pivote aprendible con soporte pequeño. Supera métodos anteriores en precisión y eficiencia en el benchmark Long Range Arena.</p>
                    <div class="paper-points">• Atención lineal y doblemente estocástica
•  Transporte óptimo de bajo rango
•  Medida pivote aprendible
•  Complejidad O(nr)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23436" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Los Mejores Hessianos Importan: Estudiando el Impacto de las Aproximaciones de Curvatura en Funciones de Influencia</h3>
                    <p class="paper-summary">📝 Investiga cómo la calidad de las aproximaciones del Hessiano afecta la precisión de las funciones de influencia para atribución de datos. Demuestra que mejores aproximaciones del Hessiano producen consistentemente mejores puntuaciones de influencia. Analiza métodos como GGN y K-FAC en un entorno controlado de clasificación.</p>
                    <div class="paper-points">• Funciones de influencia
•  Aproximaciones del Hessiano
•  Atribución de datos
•  GGN vs K-FAC
•  Error de autovalores</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23437" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Eliminación de Datos Mejorada por Decorrelación de Factores en Modelos Predictivos Profundos</h3>
                    <p class="paper-summary">📝 Propone un enfoque novedoso para eliminación de datos sensibles que utiliza decorrelación de factores y perturbación de pérdida. Incluye módulo de decorrelación que preserva la discriminación y mecanismo de eliminación suavizada. Mantiene alta precisión predictiva incluso bajo cambios de distribución significativos.</p>
                    <div class="paper-points">• Eliminación de datos sensibles
•  Decorrelación de factores
•  Perturbación de pérdida
•  Robustez OOD
•  Protección de privacidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23443" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">PHASE: Suplentes Integrados con Física y Conscientes de la Heterogeneidad para Simulaciones Científicas</h3>
                    <p class="paper-summary">📝 Presenta PHASE, un framework de aprendizaje profundo modular para suplentes científicos que integra física y maneja datos heterogéneos. Acelera el proceso de spin-up biogeoquímico del modelo E3SM Land Model, reduciendo la integración requerida de 1,200 años a solo 20 años. Demuestra fuerte generalización a mayores resoluciones espaciales.</p>
                    <div class="paper-points">• Suplentes científicos con física integrada
•  Aceleración de simulaciones
•  Datos heterogéneos
•  Modelado de superficie terrestre
•  Generalización multirresolución</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23453" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Entrenamiento Eficiente en Datos mediante Muestreo Evolucionado</h3>
                    <p class="paper-summary">📝 Propone ES (Evolved Sampling), un framework simple pero efectivo para selección dinámica de datos durante el entrenamiento. Realiza selección a nivel de lote basada en dinámicas de pérdidas y diferencias de pérdidas aumentadas. Reduce hasta 45% el tiempo de entrenamiento manteniendo el rendimiento del modelo.</p>
                    <div class="paper-points">• Selección eficiente de datos
•  Muestreo dinámico
•  Reducción de tiempo de entrenamiento
•  Aceleración de backpropagation
•  Plug-and-play</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23461" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">GEMS: Meta-Solucionador Evolutivo Generativo para Aprendizaje Multi-Agente Escalable sin Suplentes</h3>
                    <p class="paper-summary">📝 Presenta GEMS, un framework para aprendizaje multi-agente que reemplaza poblaciones explícitas con anclajes latentes compactos y un generador amortizado. Utiliza rollouts Monte Carlo y dinámicas meta de pesos multiplicativos. Es hasta 6x más rápido que PSRO con menor uso de memoria y mayores recompensas.</p>
                    <div class="paper-points">• Aprendizaje multi-agente escalable
•  Sin suplentes
•  Anclajes latentes
•  Generador amortizado
•  Garantías de teoría de juegos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23462" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Resuelve Inteligentemente, No Frecuentemente: Aprendizaje de Políticas para Re-resolución Costosa de MILP</h3>
                    <p class="paper-summary">📝 Propone POC, un framework para decidir cuándo re-resolver problemas de optimización MILP costosos versus continuar usando soluciones existentes. Combina detección de puntos de cambio con optimización de políticas proximales. Supera líneas base existentes en 2%-17% en diversos conjuntos de datos sintéticos y del mundo real.</p>
                    <div class="paper-points">• Optimización MILP en tiempo real
•  Decisión de re-resolución
•  Detección de cambios
•  Balance costo-rendimiento
•  Benchmarks MILP</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23470" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Drift-Adapter: Enfoque Práctico para Actualizaciones de Modelos de Embedding con Cero Tiempo de Inactividad en Bases de Datos Vectoriales</h3>
                    <p class="paper-summary">📝 Presenta Drift-Adapter, una capa de transformación aprendible que mapea consultas nuevas al espacio de embedding legacy, permitiendo usar índices ANN existentes. Recupera 95-99% del recall de recuperación con menos de 10 microsegundos de latencia adicional. Reduce costos de re-cómputo en más de 100 veces.</p>
                    <div class="paper-points">• Actualización de modelos de embedding
•  Cero tiempo de inactividad
•  Adaptación de espacios vectoriales
•  Eficiencia operacional
•  Bases de datos vectoriales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23471" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Ajuste Fino Eficiente en Memoria mediante Compresión de Activaciones de Bajo Rango</h3>
                    <p class="paper-summary">📝 Propone LoRAct, un enfoque para ajuste fino eficiente en memoria que comprime activaciones de bajo rango durante el pase forward. Incorpora algoritmo de descomposición ortogonal basado en muestreo para matrices de bajo rango. Reduce memoria de activaciones en ~80% comparado con LoRA manteniendo rendimiento competitivo.</p>
                    <div class="paper-points">• Eficiencia de memoria en fine-tuning
•  Compresión de activaciones
•  Bajo rango
•  Descomposición ortogonal
•  Sin datos de calibración</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23472" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Garantías de Aprendizaje Estadístico para Funciones Barron Invariantes a Grupos</h3>
                    <p class="paper-summary">📝 Analiza el error de generalización en redes neuronales invariantes a grupos dentro del marco Barron. Muestra que la invariancia grupal mejora la precisión de aproximación sin afectar el error de estimación. Proporciona fundamentos teóricos rigurosos para ventajas estadísticas en funciones simétricas.</p>
                    <div class="paper-points">• Mejora en aproximación con factor grupal δ≤1
•  Complejidad de Rademacher no aumenta
•  Ventajas claras para funciones simétricas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23474" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Generalización Temporal: Una Verificación de la Realidad</h3>
                    <p class="paper-summary">📝 Investiga si los modelos pueden generalizar a datos futuros usando solo datos pasados. Evalúa interpolación y extrapolación de parámetros en múltiples tareas temporales. Concluye que ningún método supera consistentemente al simple uso del modelo más reciente.</p>
                    <div class="paper-points">• Evaluación de métodos de generalización temporal
•  Ningún método supera al baseline simple
•  Dificultades inherentes en extrapolación futura</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23487" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕒 Revisión de Pronósticos de Series de Tiempo Multivariadas con Valores Faltantes</h3>
                    <p class="paper-summary">📝 Propone un cambio de paradigma para evitar la imputación en series de tiempo con valores faltantes. Introduce CRIB (Consistency-Regularized Information Bottleneck) que predice directamente desde datos parcialmente observados. Demuestra efectividad incluso con altas tasas de valores faltantes.</p>
                    <div class="paper-points">• Crítica al enfoque imputación-then-prediction
•  Framework CRIB sin imputación
•  Mecanismo de atención unificada con regularización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23494" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ Más Allá de los Valores Atípicos: Estudio de Optimizadores bajo Cuantización</h3>
                    <p class="paper-summary">📝 Estudia la interacción entre optimizadores y cuantización en modelos de 50M a 1.5B parámetros. Evalúa PTQ y QAT, mostrando que métricas de valores atípicos no predicen bien el rendimiento. Shampoo muestra menor degradación y mayor eficiencia paramétrica.</p>
                    <div class="paper-points">• Análisis sistemático optimizadores-cuantización
•  Métricas de outliers no predictivas
•  Shampoo mejor rendimiento en QAT</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23500" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎭</span>
                    <h3 class="paper-title">Desentrelazamiento de Variaciones con Modelado Generativo Multimodal</h3>
                    <p class="paper-summary">📝 Propone IDMVAE para desentrelazar información compartida y privada en datos multimodales. Usa regularizaciones basadas en información mutua y modelos de difusión para priores latentes. Logra separación limpia y calidad superior en generación.</p>
                    <div class="paper-points">• Desentrelazamiento información compartida/privada
•  Regularizaciones de información mutua
•  Integración con modelos de difusión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23548" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Fusión de Motivos de Secuencia y Características Pan-Genómicas: Predicción de Resistencia Antimicrobiana</h3>
                    <p class="paper-summary">📝 Presenta AMR-EnsembleNet, un ensemble de CNN 1D y XGBoost para predecir resistencia antimicrobiana. Combina aprendizaje basado en secuencias y características para E. coli. Alcanza alto rendimiento en cuatro antibióticos con interpretabilidad.</p>
                    <div class="paper-points">• Ensemble CNN 1D + XGBoost
•  Predicción AMR en E. coli
•  Enfoque interpretable y eficiente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23552" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔗 Mejora del Descubrimiento Basado en Restricciones con Propagación Robusta y Prioridades LLM Confiables</h3>
                    <p class="paper-summary">📝 Propone MosaCD para descubrimiento causal que combina tests de independencia condicional con anotaciones LLM. Introduce consultas barajadas para filtrar alucinaciones y propagación confianza-abajo. Logra mayor precisión en construcción de grafos.</p>
                    <div class="paper-points">• Combinación CI tests + LLMs
•  Filtrado de alucinaciones LLM
•  Propagación confianza-abajo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23570" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">EVO-LRP: Optimización Evolutiva de LRP para Explicaciones de Modelos Interpretables</h3>
                    <p class="paper-summary">📝 Introduce EVO-LRP que usa CMA-ES para optimizar hiperparámetros de LRP basado en métricas de interpretabilidad. Supera enfoques tradicionales de XAI en coherencia visual y métricas cuantitativas. Mejora sistemática de calidad de atribuciones.</p>
                    <div class="paper-points">• Optimización evolutiva de LRP
•  Métricas cuantitativas de interpretabilidad
•  Mejor coherencia visual y sensibilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23585" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Esbozo de Matrices de Bajo Rango más Diagonales</h3>
                    <p class="paper-summary">📝 Presenta SKETCHLORD para aproximar operadores lineales Low-Rank plus Diagonal (LoRD) simultáneamente. Demuestra superioridad sobre aproximaciones secuenciales mediante optimización convexa. Aplicable a operadores a gran escala como el Hessiano.</p>
                    <div class="paper-points">• Aproximación simultánea low-rank + diagonal
•  Superior a enfoques secuenciales
•  Optimización convexa escalable</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23587" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Hacia un Enfoque Holístico para la Fusión Continua de Modelos</h3>
                    <p class="paper-summary">📝 Propone framework holístico para fusión continua de modelos en tres etapas: pre-fusión, durante fusión y post-fusión. Usa espacio tangente para desentrelazamiento y información funcional de estados del optimizador. Opera con restricciones de memoria constantes.</p>
                    <div class="paper-points">• Intervención en tres etapas críticas
•  Linearización en espacio tangente
•  Corrección post-fusión sin datos históricos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23592" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Evitar el Olvido Catastrófico con Fisher de Rango-1 a partir de Modelos de Difusión</h3>
                    <p class="paper-summary">📝 Propone una variante de rango-1 de EWC que aprovecha la estructura de gradientes en modelos de difusión para evitar el olvido catastrófico. Combina penalización con replay para compartir parámetros entre tareas y reducir la deriva. Mejora consistentemente FID y reduce el olvido en generación incremental de imágenes.</p>
                    <div class="paper-points">• Fisher efectivamente de rango-1 en modelos de difusión
•  método complementario replay+EWC
•  olvido casi eliminado en MNIST/FashionMNIST</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23593" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Análisis de Raíces Características y Regularización para Pronóstico de Series Temporales Lineales</h3>
                    <p class="paper-summary">📝 Estudia modelos lineales para pronóstico de series temporales, enfocándose en el papel de las raíces características en la dinámica temporal. Propone estrategias de regularización para reestructuración robusta de raíces, incluyendo reducción de rango y método Root Purge para suprimir ruido.</p>
                    <div class="paper-points">• Raíces características gobiernan comportamiento a largo plazo
•  raíces espurias en régimen ruidoso
•  métodos rank-reduction y Root Purge</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23597" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕸️ GraphIFE: Repensando la Clasificación de Nodos Desbalanceados en Grafos mediante Aprendizaje Invariante</h3>
                    <p class="paper-summary">📝 Propone GraphIFE, un framework que mitiga problemas de inconsistencia en nodos sintetizados bajo condiciones de desbalance en grafos. Incorpora conceptos de aprendizaje invariante para fortalecer el espacio de representación y mejorar características invariantes.</p>
                    <div class="paper-points">• Problema de inconsistencia en nodos sintetizados
•  aprendizaje de características invariantes
•  mejora rendimiento en clases minoritarias</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23616" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🗺️ DRIK: Kriging Inductivo Robusto a Distribución sin Filtración de Información</h3>
                    <p class="paper-summary">📝 Introduce DRIK, un enfoque de kriging inductivo robusto que elimina la filtración de información mediante partición 3x3. Emplea estrategia de tres niveles (nodo, arista, subgrafo) para mejorar generalización fuera de distribución en redes de sensores.</p>
                    <div class="paper-points">• Partición 3x3 elimina filtración
•  perturbación de coordenadas y eliminación de aristas
•  hasta 12.48% menor MAE</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23631" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">PreScope: Liberando el Poder del Prefetching para Inferencia MoE con Recursos Limitados</h3>
                    <p class="paper-summary">📝 Presenta PreScope, sistema de planificación de expertos basado en predicción para modelos MoE. Incluye predictor consciente de capas, planificación cross-layer y optimizador de E/S asíncrona para reducir cuellos de botella de memoria y PCIe.</p>
                    <div class="paper-points">• 141% mayor throughput
•  74.6% menor latencia
•  planificación óptima global
•  eliminación de burbujas de espera</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23638" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕸️ Red Neuronal Convolucional de Grafos Heterogéneos basada en Nodos Virtuales para Agregación Eficiente de Información de Largo Alcance</h3>
                    <p class="paper-summary">📝 Propone VN-HGCN, que utiliza nodos virtuales interconectados para facilitar el flujo de información de largo alcance en grafos heterogéneos. Logra agregación efectiva con solo 4 capas y puede aplicarse a otros modelos HGNN.</p>
                    <div class="paper-points">• Nodos virtuales para información de largo alcance
•  solo 4 capas necesarias
•  framework versátil para otros modelos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23660" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕸️ Selección Pura de Nodos para Clasificación de Nodos Desbalanceados en Grafos</h3>
                    <p class="paper-summary">📝 Introduce PNS (Pure Node Sampling), módulo plug-and-play que aborda el problema de conectividad anómala por aleatoriedad en clasificación de nodos desbalanceados. Mitiga degradación por distribución anormal de vecinos y elimina influencia de semillas aleatorias.</p>
                    <div class="paper-points">• Problema RACP por semillas aleatorias
•  módulo plug-and-play
•  mejora estabilidad y rendimiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23662" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Calibración Encuentra la Realidad: Haciendo Confiables las Predicciones de Aprendizaje Automático</h3>
                    <p class="paper-summary">📝 Analiza teóricamente métodos de calibración post-hoc (Platt scaling, regresión isotónica), explorando el impacto de la calidad de características en el rendimiento de calibración. Proporciona garantías de convergencia y métricas de rendimiento con muestras finitas.</p>
                    <div class="paper-points">• Análisis teórico de métodos de calibración
•  impacto de características informativas
•  guías prácticas para selección de métodos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23665" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Más Allá de las Salidas Codiciosas: Decisiones Mejoradas de Salida Temprana para Control de Riesgo y Confiabilidad</h3>
                    <p class="paper-summary">📝 Propone UAT, framework que adapta umbrales para decisiones de salida temprana usando Multi-Armed Bandit. Balancea eficiencia computacional y calidad de predicción, penalizando salidas tardías innecesarias con garantías de riesgo.</p>
                    <div class="paper-points">• Recall distribucional como propiedad clave
•  experimentos controlados con Mixture-of-Gaussians
•  pipeline Align -&gt
•  KD superior</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23667" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Red de Dominio de Frecuencia Auto-Adaptativa para la Predicción Continua de Hipotensión Intraoperatoria</h3>
                    <p class="paper-summary">📝 Propone SAFDNet para predecir hipotensión intraoperatoria, integrando análisis de Fourier y umbralización auto-adaptativa para reducir ruido. Logra 97.3% AUROC en alertas tempranas, superando modelos existentes. Demuestra robustez y baja sensibilidad al ruido para aplicaciones clínicas.</p>
                    <div class="paper-points">• Predicción de hipotensión intraoperatoria
•  bloque espectral adaptativo
•  atención interactiva para dependencias a largo/corto plazo
•  validación interna/externa extensa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23720" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">GBSK: Agrupamiento de Esqueleto mediante Computación de Bola Granular y Múltiples Muestreos para Datos a Gran Escala</h3>
                    <p class="paper-summary">📝 Algoritmo de agrupamiento escalable que usa técnica de bola granular para capturar estructura subyacente de datos. Reduce overhead computacional manteniendo alta precisión. Versión adaptativa AGBSK simplifica parámetros para escenarios reales.</p>
                    <div class="paper-points">• Agrupamiento a gran escala
•  abstracción esquelética estadística
•  hasta 100 millones de instancias
•  reducción de costo computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23742" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎵</span>
                    <h3 class="paper-title">Programación de Tokens Desplazados en el Tiempo para Generación de Música Simbólica</h3>
                    <p class="paper-summary">📝 Aborda el equilibrio entre eficiencia y calidad en generación musical simbólica. Mecanismo de programación por demora expande tokens compuestos entre pasos de decodificación. Mejora métricas sobre tokenizaciones compuestas estándar.</p>
                    <div class="paper-points">• Generación de música simbólica
•  tokenizaciones de granularidad fina
•  mecanismo de programación por demora
•  sin parámetros adicionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23749" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Investigación de la Normalización por Lotes en Algoritmos Actor-Critic Fuera de Política</h3>
                    <p class="paper-summary">📝 Estudia el uso de Batch Normalization en aprendizaje por refuerzo profundo, proponiendo MA-BN para manejar datos no i.i.d. y distribuciones cambiantes. Acelera entrenamiento, estabiliza convergencia y mejora exploración.</p>
                    <div class="paper-points">• Normalización por lotes en DRL
•  modos de entrenamiento/evaluación
•  método MA-BN
•  estabilización del entrenamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23750" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Ajuste Supervisado Anclado</h3>
                    <p class="paper-summary">📝 Propone ASFT como alternativa a fine-tuning supervisado y aprendizaje por refuerzo. Combina reponderación de DFT con regularización KL ligera para mayor estabilidad. Supera a SFT y DFT en razonamiento matemático y generación de código.</p>
                    <div class="paper-points">• Post-entrenamiento de LLMs
•  marco RWR
•  regularización KL
•  mejor generalización con sobrecarga computacional mínima</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23753" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">SHAPoint: Puntuación de Riesgo Basada en Puntos, Agnóstica e Interpretable mediante Valores Shapley</h3>
                    <p class="paper-summary">📝 Framework para puntuación de riesgo interpretable que combina árboles gradient boosting con puntuaciones basadas en puntos. Soporta clasificación, regresión y supervivencia. Mayor flexibilidad y menor tiempo de ejecución que métodos existentes.</p>
                    <div class="paper-points">• Puntuación de riesgo interpretable
•  valores Shapley
•  manejo nativo de datos faltantes
•  restricciones monótonas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23756" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Homofilia del Conocimiento en Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Investiga patrones de homofilia en conocimiento de LLMs, donde entidades cercanas en grafos de conocimiento tienen niveles similares de conocimiento. Propone modelo GNN para predecir conocimiento y priorizar tripletas menos conocidas.</p>
                    <div class="paper-points">• Estructura de conocimiento en LLMs
•  homofilia de conocimiento
•  modelo GNN
•  inyección eficiente de conocimiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23773" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Mamba Entrenado Emula Descenso de Gradiente Online en Regresión Lineal en Contexto</h3>
                    <p class="paper-summary">📝 Analiza teóricamente capacidades de aprendizaje en contexto de Mamba en regresión lineal. Revela que realiza variante de descenso de gradiente online para aprender funciones latentes. Mecanismo diferente a Transformers.</p>
                    <div class="paper-points">• Modelos de espacio de estados
•  aprendizaje en contexto
•  convergencia exponencial
•  emulación de descenso de gradiente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23779" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👁️ Cadena de Pensamiento Visual Hace a los VLMs Más Inteligentes pero Más Frágiles</h3>
                    <p class="paper-summary">📝 Evalúa robustez de Visual CoT bajo perturbaciones visuales. Mejora precisión pero aumenta sensibilidad a ruido. Identifica parches de imagen editados como fuente principal de fragilidad. Propone método con Grounding DINO para estabilizar razonamiento.</p>
                    <div class="paper-points">• VLMs con CoT visual
•  evaluación de robustez
•  degradación de rendimiento bajo perturbaciones
•  estabilización con Grounding DINO</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23789" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Mejora de la Dirección de LLMs mediante Refinamiento Vectorial Basado en Autoencoder Disperso</h3>
                    <p class="paper-summary">📝 Propone SAE-RSV para refinar vectores de dirección aprendidos de datos limitados, usando autoencoders dispersos para eliminar ruido y enriquecer características relevantes. Supera a fine-tuning supervisado en experimentos.</p>
                    <div class="paper-points">• Dirección de LLMs
•  autoencoder disperso
•  eliminación de características irrelevantes
•  enriquecimiento semántico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23799" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Fusión cerebro-lenguaje permite lectura neural interactiva y experimentación in-silico</h3>
                    <p class="paper-summary">📝 Se presenta CorText, un framework que integra actividad cerebral directamente en el espacio latente de un LLM, permitiendo interacción en lenguaje natural con datos cerebrales. El sistema genera descripciones precisas de imágenes y responde preguntas detalladas usando solo datos neurales, mostrando generalización zero-shot y permitiendo análisis contrafactual.</p>
                    <div class="paper-points">• Integración neural-LLM
•  decodificación interactiva
•  generalización zero-shot
•  experimentación in-silico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23941" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🗺️ Identificación Eficiente de Clústeres de Alta Similitud en Conjuntos de Datos de Polígonos</h3>
                    <p class="paper-summary">📝 Propone un framework que reduce la carga computacional en análisis geoespaciales grandes mediante umbralización dinámica de similitud, programación supervisada y optimización con restricciones de recall. Utiliza Estimación de Densidad por Kernel para determinar umbrales y modelos de ML para priorizar clústeres, manteniendo precisión.</p>
                    <div class="paper-points">• Computación espacial escalable
•  reducción de carga computacional
•  KDE dinámico
•  optimización con recall</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23942" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Cadena Explorar-Ejecutar: Hacia un Paradigma de Razonamiento Estructurado Eficiente</h3>
                    <p class="paper-summary">📝 Introduce E²C, un framework que desacopla el razonamiento en fase exploratoria (generación de planes) y ejecutiva (implementación). Reduce tokens de decodificación en &gt;90% vs métodos comparables, logrando alta precisión en benchmarks con fine-tuning usando solo 3.5% de tokens.</p>
                    <div class="paper-points">• Razonamiento desacoplado
•  escalado eficiente
•  reducción de tokens
•  planificación vs ejecución</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23946" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ DiBS-MTL: Aprendizaje Multitarea Invariante a Transformaciones con Oráculos de Dirección</h3>
                    <p class="paper-summary">📝 Presenta DiBS-MTL, método de aprendizaje multitarea invariable a transformaciones monótonas no afines de pérdidas. Basado en teoría de negociación cooperativa, evita dominancia de tareas y converge a puntos Pareto estacionarios en escenarios no convexos, manteniendo rendimiento competitivo.</p>
                    <div class="paper-points">• Invariancia a escalado
•  solución Pareto
•  negociación cooperativa
•  robustez a dominancia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23948" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Evaluando la Robustez del Escalado Óptimo de Computación de Chinchilla</h3>
                    <p class="paper-summary">📝 Investiga la robustez de las leyes de escalado de Chinchilla frente a ambigüedades en parámetros y perturbaciones sistemáticas. Demuestra que los resultados clave se mantienen bajo diferentes interpretaciones y perturbaciones, validando Chinchilla como guía confiable para escalar modelos de lenguaje.</p>
                    <div class="paper-points">• Escalado óptimo
•  robustez metodológica
•  validación de Chinchilla
•  leyes de escalado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23963" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Detección y Corrección de Etiquetas Ruidosas: Enfoque Basado en Similitud</h3>
                    <p class="paper-summary">📝 Propone métodos post-hoc y agnósticos al modelo para detectar y rectificar errores de etiquetado usando características penúltimas de redes neuronales. La similitud entre características revela clusters informativos para identificar etiquetas incorrectas y mejorar calidad de datasets automáticamente.</p>
                    <div class="paper-points">• Detección de ruido
•  características penúltimas
•  similitud de clusters
•  rectificación automática</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23964" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">💸 Aprendizaje por Refuerzo Guiado por Currículo para Sintetizar Contratos de Derivados Financieros Eficientes en Gas</h3>
                    <p class="paper-summary">📝 Framework de RL que genera contratos Solidity funcionales y optimizados en gas desde especificaciones CDM. Usa PPO con currículo de dos fases: primero corrección funcional, luego optimización de gas. Logra ahorros de hasta 35.59% en costos vs líneas base no optimizadas.</p>
                    <div class="paper-points">• Optimización de gas
•  contratos inteligentes
•  RL con currículo
•  síntesis automática</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23976" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🕸️ GUIDE: Codificadores de Datos y Prior Generalizados para Estimación de DAG</h3>
                    <p class="paper-summary">📝 Framework GUIDE que integra matrices de adyacencia generadas por LLM con datos observacionales mediante arquitectura dual-codificador. Reduce tiempo de ejecución en ~42% y mejora precisión en ~117% vs baselines, escalando a ≥70 nodos donde otros métodos fallan.</p>
                    <div class="paper-points">• Descubrimiento causal
•  escalabilidad
•  eficiencia computacional
•  integración LLM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23992" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">¿Ocurre Generalización Débil-a-Fuerte bajo Correlaciones Espurias?</h3>
                    <p class="paper-summary">📝 Estudia teórica y algorítmicamente la generalización débil-a-fuerte en tareas con correlaciones espurias por desbalance grupal. Muestra que W2S falla cuando los desbalances entre datos etiquetados y no etiquetados difieren, y propone remedio algorítmico que reentrena el estudiante en subconjuntos de alta confianza.</p>
                    <div class="paper-points">• Generalización W2S
•  correlaciones espurias
•  desbalance grupal
•  fine-tuning robusto</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24005" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">SLA: Más Allá de la Esparsidad en Transformadores de Difusión mediante Atención Esparsa-Lineal Sintonizable</h3>
                    <p class="paper-summary">📝 Propone SLA, método de atención entrenable que fusiona atención esparsa y lineal para acelerar modelos de difusión. Clasifica pesos en críticos, marginales y negligibles, aplicando O(N²) a críticos y O(N) a marginales. Reduce computación de atención en 95% sin pérdida de calidad.</p>
                    <div class="paper-points">• Atención eficiente
•  difusión acelerada
•  fusión esparsa-lineal
•  kernel GPU optimizado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24006" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Leyes de Escalado para Evaluaciones Generativas de Modelos de Lenguaje</h3>
                    <p class="paper-summary">📝 Investiga leyes de escalado para evaluaciones generativas como resolución de problemas matemáticos, proponiendo tres enfoques basados en computación, parámetros+tokens y verosimilitud. Demuestra que las leyes se estabilizan en diferentes órdenes de magnitud y establece conexiones teóricas entre los métodos.</p>
                    <div class="paper-points">• Tres leyes de escalado para evaluaciones generativas
•  Estabilidad en diferentes órdenes de magnitud
•  Predicción de rendimiento de modelos costosos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24012" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🗺️ GPS-MTM: Capturando Patrones de Normalidad en Trayectorias GPS con Aprendizaje Autosupervisado</h3>
                    <p class="paper-summary">📝 Presenta un modelo fundacional para datos de movilidad que descompone la movilidad en estados (categorías) y acciones (transiciones). Usa Transformers bidireccionales con objetivo de modelado enmascarado para reconstruir segmentos faltantes, superando métodos anteriores en tareas como predicción de próxima parada.</p>
                    <div class="paper-points">• Modelo fundacional para trayectorias
•  Descomposición en estados y acciones
•  Mejor rendimiento en tareas dinámicas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24031" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤝</span>
                    <h3 class="paper-title">Optimismo como Búsqueda de Riesgo en Aprendizaje por Refuerzo Multi-Agente</h3>
                    <p class="paper-summary">📝 Propone un marco teórico que interpreta objetivos de búsqueda de riesgo como optimismo en MARL cooperativo. Introduce funciones de valor optimistas y algoritmos descentralizados que mejoran la coordinación sobre métodos heurísticos existentes.</p>
                    <div class="paper-points">• Marco teórico para optimismo como riesgo
•  Algoritmos descentralizados
•  Mejora coordinación en tareas cooperativas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24047" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📱 Inferencia Colaborativa Dispositivo-Nube para LLMs mediante Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">📝 Propone un framework donde el LLM local decide routing al final de su proceso, usando aprendizaje por refuerzo con recompensas diseñadas para resolver problemas efectivamente y delegar juiciosamente a la nube.</p>
                    <div class="paper-points">• Routing inteligente dispositivo-nube
•  Algoritmo de gradiente de política adaptativo
•  Cierra brecha con rendimiento en nube</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24050" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Sobre la Variabilidad de Vectores de Activación de Conceptos</h3>
                    <p class="paper-summary">📝 Analiza teóricamente la variabilidad en CAVs debido al muestreo aleatorio, demostrando que la varianza disminuye como 1/N. Proporciona recomendaciones prácticas para aplicación eficiente del método.</p>
                    <div class="paper-points">• Análisis de variabilidad en CAVs
•  Ley universal de disminución de varianza
•  Recomendaciones prácticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24058" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Aprendizaje Q Composicional en Contexto para RL Offline</h3>
                    <p class="paper-summary">📝 Propone ICQL, primer framework offline RL que formula Q-learning como problema de inferencia contextual, usando Transformers lineales para inferir funciones Q locales sin etiquetas explícitas de subtareas.</p>
                    <div class="paper-points">• Enfoque composicional para Q-learning
•  Inferencia contextual sin etiquetas
•  Mejoras significativas en benchmarks</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24067" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">Modelo Matemático Pequeño: Reformulando la Teoría de Elección de Estrategias</h3>
                    <p class="paper-summary">📝 Reformula la Teoría de Elección de Estrategias como un &#x27;Modelo Matemático Pequeño&#x27; con arquitectura inspirada en LLMs, extendiendo el modelo original con práctica de conteo, embedding de números y atención gated.</p>
                    <div class="paper-points">• Arquitectura inspirada en LLMs
•  Extensión de teoría psicológica
•  Interferencia constructiva/destructiva demostrada</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24068" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Familia de Costos Matriciales Kernelizados para Redes Neuronales de Mezclas Multi-Salida</h3>
                    <p class="paper-summary">📝 Combina Redes de Densidad de Mezcla con costos contrastivos, proponiendo cuatro tipos de costos matriciales kernelizados para aproximación de densidad de datos y aprendizaje de centros múltiples.</p>
                    <div class="paper-points">• Cuatro costos matriciales kernelizados
•  Combinación MDN con aprendizaje contrastivo
•  Aproximación de densidad de datos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24076" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ Equidad Agnóstica a Demografía sin Daño</h3>
                    <p class="paper-summary">📝 Propone algoritmo DAFH que aprende simultáneamente clasificador de grupos y clasificadores desacoplados sin información demográfica, manteniendo alta precisión mientras garantiza equidad basada en preferencias.</p>
                    <div class="paper-points">• Equidad sin información demográfica
•  Múltiples clasificadores desacoplados
•  Mantenimiento de alta precisión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24077" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">PEARL: Radio Adaptativa Mejorada por Pares mediante LLM en Dispositivo</h3>
                    <p class="paper-summary">📝 PEARL es un framework para optimización cooperativa en comunicaciones dispositivo-a-dispositivo que utiliza LLMs en dispositivo. Extiende trabajos previos aprovechando estados del publicador y suscriptor para guiar la selección de parámetros Wi-Fi Aware. Logra mejor rendimiento y reduce energía hasta 16% en casos cooperativos con batería baja.</p>
                    <div class="paper-points">• Optimización cooperativa cross-layer
•  LLMs en dispositivo
•  Reducción de energía 16%
•  Variantes ligeras con LoRA</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24085" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">Transformador Clebsch-Gordan: Atención Equivariante Global y Rápida</h3>
                    <p class="paper-summary">📝 Propone Clebsch-Gordan Transformer, un método de atención global eficiente mediante convolución Clebsch-Gordon en representaciones irreducibles de SO(3). Logra complejidad O(N log N) y escala bien con características de alto orden. Supera a transformers equivariantes existentes en memoria, velocidad y precisión.</p>
                    <div class="paper-points">• Atención global eficiente
•  Complejidad O(N log N)
•  Escalabilidad alto orden
•  Mejor rendimiento en benchmarks físicos y robóticos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24093" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚛️ ADAPT: Campos de Fuerza de ML Ligeros y de Largo Alcance Sin Grafos</h3>
                    <p class="paper-summary">📝 ADAPT es un campo de fuerza de aprendizaje automático que reemplaza representaciones basadas en grafos con formulación directa de coordenadas. Utiliza Transformer encoder para modelar interacciones atómicas. Logra 33% de reducción en errores de fuerza y energía frente a modelos GNN, con menor costo computacional.</p>
                    <div class="paper-points">• Sin representación de grafos
•  Interacciones atómicas directas
•  33% menos error
•  Menor costo computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24115" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📐</span>
                    <h3 class="paper-title">GeoFunFlow: Flujo de Función Geométrica para Aprendizaje de Operadores Inversos</h3>
                    <p class="paper-summary">📝 GeoFunFlow es un framework de difusión geométrica para problemas inversos en geometrías complejas. Combina autoencoder geométrico con modelo de difusión en espacio latente entrenado via rectified flow. Logra precisión state-of-the-art en reconstrucción sobre geometrías complejas con cuantificación de incertidumbre.</p>
                    <div class="paper-points">• Problemas inversos en geometrías complejas
•  Autoencoder geométrico
•  Difusión latente
•  Reconstrucción precisa con incertidumbre</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24117" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">HyMaTE: Modelo Híbrido Mamba y Transformer para Aprendizaje de Representación en EHR</h3>
                    <p class="paper-summary">📝 HyMaTE es un modelo híbrido que combina State Space Models (Mamba) con mecanismos de atención para representar datos longitudinales de historiales médicos electrónicos. Supera limitaciones de Transformers en complejidad computacional y longitud de contexto, capturando representaciones más ricas y unificadas.</p>
                    <div class="paper-points">• Modelo híbrido Mamba-Transformer
•  EHR longitudinales
•  Modelado eficiente de secuencias largas
•  Mejor representación unificada</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24118" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⏰ Redes de Flujo Eco para Pronóstico de Series Temporales</h3>
                    <p class="paper-summary">📝 Echo Flow Networks (EFNs) es un framework compuesto por Echo State Networks extendidos con activación aleatoria compuesta matricial. Ofrece uso de memoria constante y complejidad de entrenamiento por paso independiente de la longitud de entrada. Logra 4x entrenamiento más rápido y mejora error de pronóstico en 20%.</p>
                    <div class="paper-points">• Memoria constante
•  Entrenamiento 4x más rápido
•  Mejora 20% error pronóstico
•  Arquitectura dual-stream</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24122" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚫 La Imposibilidad del Aprendizaje de Permutación Inversa en Modelos Transformer</h3>
                    <p class="paper-summary">📝 Demuestra que transformers decoder-only no pueden aprender la tarea de permutación inversa, resultando importante para propiedades de robustez en tareas de razonamiento. Revela brecha de expresividad entre arquitecturas encoder-decoder y decoder-only, sugiriendo que tokens intermedios pueden habilitar razonamiento.</p>
                    <div class="paper-points">• Imposibilidad permutación inversa
•  Brecha expresividad arquitecturas
•  Rol máscara atención causal
•  Tokens intermedios habilitan razonamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24125" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Visión de Separación de Señal para Clasificación</h3>
                    <p class="paper-summary">📝 Propone enfoque alternativo para clasificación usando kernels polinomiales trigonométricos localizados desarrollados para separación de señales. Separa soportes de distribuciones de probabilidad de diferentes clases de manera jerárquica. Logra clasificación perfecta con número mínimo de etiquetas consultadas.</p>
                    <div class="paper-points">• Enfoque separación señales
•  Kernels polinomiales localizados
•  Clasificación perfecta mínimas etiquetas
•  Algoritmo MASC jerárquico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24140" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌀 Evaluación de Técnicas de ML para Regresión de Trayectoria y Clasificación de Estado de Ciclones</h3>
                    <p class="paper-summary">📝 Desarrolla pipeline de ML en dos etapas para pronóstico de ciclones tropicales usando datos de series temporales. Modelo de regresión predice características del ciclón, luego clasificadores predicen estado categórico. Random Forest logra 93% de precisión, superando métodos tradicionales en escalabilidad y eficiencia.</p>
                    <div class="paper-points">• Pipeline dos etapas
•  Random Forest 93% precisión
•  Predicciones presión/viento precisas
•  Alternativa escalable a métodos tradicionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24146" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Olvido Estable: Desaprendizaje Eficiente y Acotado en LLMs</h3>
                    <p class="paper-summary">📝 Propone método de desaprendizaje eficiente en parámetros que estabiliza fine-tuning basado en LoRA aplicando funciones acotadas a adaptadores MLP. Soluciona problema de crecimiento no acotado de pesos durante ascenso de gradiente. Logra mejoras sustanciales en olvido mientras preserva retención en múltiples benchmarks.</p>
                    <div class="paper-points">• Desaprendizaje estable
•  Fine-tuning LoRA acotado
•  Control dinámica de pesos
•  Mejor olvido y retención</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24166" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Autoencoder Geométrico Multi-Escala</h3>
                    <p class="paper-summary">📝 Propone un autoencoder asimétrico que preserva simultáneamente propiedades geométricas globales y locales de los datos. La arquitectura aplica restricciones de distancia global al codificador y restricciones geométricas locales al decodificador. Supera consistentemente a métodos existentes en múltiples métricas de evaluación.</p>
                    <div class="paper-points">• Arquitectura asimétrica
•  Preservación geométrica multi-escala
•  Mejor rendimiento en datos sintéticos y reales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24168" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Detección de Correlación de Modelos mediante Sondeo de Selección Aleatoria</h3>
                    <p class="paper-summary">📝 Introduce RSP, un marco de prueba estadística para detectar si un modelo ha sido ajustado o es idéntico a otro. Optimiza prefijos en un modelo de referencia y evalúa su transferibilidad al modelo objetivo, produciendo valores p rigurosos. Filtra falsos positivos usando un modelo base no relacionado.</p>
                    <div class="paper-points">• Marco de prueba de hipótesis
•  Valores p cuantificables
•  Evaluación robusta en LLMs y VLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24171" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">FM-FoG: Sistema Portátil en Tiempo Real para Mitigar la Congelación de la Marcha</h3>
                    <p class="paper-summary">📝 Sistema basado en modelos fundacionales para detectar congelación de la marcha en pacientes con Parkinson sin entrenamiento específico por paciente. Combina preentrenamiento auto-supervisado con clasificación de actividad liviana. Logra 98.5% de puntaje F1 en pacientes no vistos y extiende la batería hasta 72%.</p>
                    <div class="paper-points">• Detección en pacientes no vistos
•  Activación selectiva por actividad
•  Eficiencia energética y baja latencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24176" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Pre-activaciones Negativas Diferencian Sintaxis</h3>
                    <p class="paper-summary">📝 Investiga neuronas de Wasserstein que diferencian entradas similares mediante pre-activaciones negativas en capas tempranas. La intervención específica en signos negativos debilita la función del modelo y altera el comportamiento gramatical. Identifica la diferenciación negativa como mecanismo crucial para la sintaxis.</p>
                    <div class="paper-points">• Neuronas de Wasserstein
•  Pre-activaciones negativas
•  Sintaxis en modelos de lenguaje</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24198" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 REINFORCE Relativo-Grupal es Secretamente un Algoritmo Off-Policy</h3>
                    <p class="paper-summary">📝 Demuestra que REINFORCE relativo-grupal admite interpretación off-policy nativa. Deriva principios para adaptar REINFORCE a entornos off-policy: regularizar actualizaciones de políticas y moldear activamente la distribución de datos. Unifica e interpreta algoritmos recientes como formas regularizadas.</p>
                    <div class="paper-points">• Interpretación off-policy
•  Principios de regularización
•  Unificación de algoritmos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24203" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">MDD-Thinker: Hacia Modelos de Razonamiento Grande para Diagnóstico de Depresión Mayor</h3>
                    <p class="paper-summary">📝 Marco de diagnóstico basado en LLMs que integra fine-tuning supervisado con aprendizaje por refuerzo para mejorar razonamiento e interpretabilidad. Entrenado con 40,000 muestras del UK Biobank. Logra precisión de 0.8268 y supera significativamente a líneas base tradicionales y LLMs de propósito general.</p>
                    <div class="paper-points">• Diagnóstico de depresión mayor
•  Razonamiento mejorado
•  Datos clínicos del mundo real</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24217" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Conda: Adam con Normalización de Columnas para Entrenar LLMs más Rápido</h3>
                    <p class="paper-summary">📝 Optimizador que proyecta actualizaciones en subespacio ortogonal y aplica normalización de momento segundo por columnas. Mejora el condicionamiento espectral de Adam manteniendo adaptividad por coordenadas. Logra 2-2.5× mayor velocidad de convergencia que AdamW en series LLaMA y GPT-2.</p>
                    <div class="paper-points">• Normalización por columnas
•  Mejor condicionamiento espectral
•  Entrenamiento acelerado de LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24218" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎨</span>
                    <h3 class="paper-title">Edición Semántica con Ecuaciones Diferenciales Estocásticas Acopladas</h3>
                    <p class="paper-summary">📝 Método para edición de imágenes que usa ecuaciones diferenciales estocásticas acopladas para guiar el muestreo de modelos generativos pre-entrenados. Conduce muestras hacia semánticas deseadas preservando similitud visual con la fuente. Funciona sin reentrenamiento y logra alta fidelidad al prompt.</p>
                    <div class="paper-points">• SDEs acopladas
•  Edición semántica
•  Preservación de detalles
•  Sin reentrenamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24223" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Marco para Adopción de ML en Sistemas Legacy</h3>
                    <p class="paper-summary">📝 Framework basado en APIs que desacopla el ciclo de vida del ML del entorno de producción. Interfaz liviana basada en navegador elimina necesidad de actualizaciones de hardware local. Enfoque humano-en-el-loop empodera expertos con control interactivo sobre parámetros del modelo.</p>
                    <div class="paper-points">• Integración con sistemas legacy
•  APIs desacopladas
•  Cero tiempo de inactividad
•  Accesibilidad para PYMES</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24224" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ Evaluación Accesible, Realista y Justa de Algoritmos de Aprendizaje Positivo-No Etiquetado</h3>
                    <p class="paper-summary">📝 Propone el primer benchmark para aprendizaje PU que identifica factores críticos que afectan la evaluación realista y justa. Investiga criterios de selección de modelos sin datos negativos y aborda el problema de cambio de etiquetas internas. Proporciona marco comparativo equitativo entre configuraciones.</p>
                    <div class="paper-points">• Primer benchmark PU
•  Criterios de selección de modelos
•  Solución a cambio de etiquetas internas
•  Comparaciones justas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24228" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Expandiendo Horizontes de Diversidad de Niveles mediante Aprendizaje Evolutivo Multi-objetivo</h3>
                    <p class="paper-summary">📝 Propone un framework evolutivo multi-objetivo para generar niveles de videojuegos diversos. Optimiza múltiples métricas de diversidad simultáneamente durante el entrenamiento. El estudio en Super Mario Bros demuestra mejor diversidad multidimensional y front de Pareto intercambiable.</p>
                    <div class="paper-points">• Generación de niveles de juego
•  Diversidad multidimensional
•  Optimización evolutiva multi-objetivo
•  Front de Pareto</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24341" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Marcado de Agua para Modelos de Lenguaje de Difusión</h3>
                    <p class="paper-summary">📝 Primer sistema de marcado de agua específico para modelos de lenguaje de difusión que generan tokens en orden arbitrario. Supera limitaciones de métodos secuenciales manteniendo detector sin cambios. Logra &gt;99% de tasa de positivos verdaderos con impacto mínimo en calidad.</p>
                    <div class="paper-points">• Marcado de agua
•  Modelos de difusión
•  Generación no autoregresiva
•  Detección robusta</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24368" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Estrategias Evolutivas a Escala: Fine-Tuning de LLMs más allá del Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">📝 Demuestra que las estrategias evolutivas pueden escalar para fine-tuning de LLMs completos, superando a RL en eficiencia muestral y estabilidad. Maneja miles de millones de parámetros con menor tendencia a reward hacking y mayor tolerancia a recompensas de horizonte largo.</p>
                    <div class="paper-points">• Fine-tuning de LLMs
•  Estrategias evolutivas
•  Escalabilidad
•  Eficiencia muestral</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24372" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">AXIS: Detección Explicable de Anomalías en Series Temporales con Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Framework que adapta LLMs para detección explicable de anomalías en series temporales mediante tres señales complementarias: numérica simbólica, contexto integrado y prior de tarea. Supera a LLMs especializados en calidad explicativa y precisión de detección.</p>
                    <div class="paper-points">• Series temporales
•  Anomalías explicables
•  LLMs multimodales
•  Evaluación contextual</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24378" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Muon: Entrenamiento y Compromisos con Atención Latente y MoE</h3>
                    <p class="paper-summary">📝 Optimizador Muon para transformers con análisis teórico de convergencia y propiedades espectrales. Combinado con MLA y MoE logra 68% de reducción de memoria y 3.2× aceleración en inferencia, manteniendo superior eficiencia de datos en lotes grandes.</p>
                    <div class="paper-points">• Optimización
•  Transformers eficientes
•  Atención latente
•  Mixture-of-Experts</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24406" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">ScatterAD: Mecanismo de Dispersión Temporal-Topológica para Detección de Anomalías en Series Temporales</h3>
                    <p class="paper-summary">📝 Modela la dispersión de representaciones en espacios de alta dimensión como señal para detección de anomalías. Combina codificador topológico para dispersión estructurada y temporal para restricción entre pasos adyacentes. Logra estado del arte en benchmarks multivariados.</p>
                    <div class="paper-points">• Series temporales multivariadas
•  Dispersión dimensional
•  Codificación topológica
•  Fusión contrastiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24414" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">BiHDTrans: Transformer Binario de Hiperdimensionalidad para Clasificación Eficiente de Series Temporales Multivariadas</h3>
                    <p class="paper-summary">📝 Integra self-attention en computación hiperdimensional binaria para clasificación eficiente en edge. Con aceleración FPGA logra 39.4× menor latencia que transformers binarios y supera modelos HD en 14.47% de precisión, manteniendo competitividad con reducción dimensional.</p>
                    <div class="paper-points">• Computación hiperdimensional
•  Transformers binarios
•  Edge computing
•  Eficiencia energética</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24425" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🗜️ Compresión Semántica mediante Aprendizaje de Representaciones Multimodales</h3>
                    <p class="paper-summary">📝 Demuestra que reducir la brecha modal permite compresión semántica post-entrenamiento reemplazando embeddings múltiples con centroides únicos. Logra compresión significativa sin sacrificar rendimiento en tareas multimodales a gran escala.</p>
                    <div class="paper-points">• Compresión semántica
•  Alineación multimodal
•  Centroides de embeddings
•  Eficiencia de almacenamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24431" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">EOE: Optimización Evolutiva de Expertos para Entrenar Modelos de Lenguaje</h3>
                    <p class="paper-summary">📝 Framework evolutivo que divide LLMs en expertos, entrenando uno por paso con operadores evolutivos (cruce, PSO, mutación) entre el experto actual y el mejor. Logra aceleración &gt;10× en throughput y reduce memoria, manteniendo precisión del mejor experto.</p>
                    <div class="paper-points">• Entrenamiento evolutivo
•  Expertos especializados
•  Eficiencia memoria
•  Throughput acelerado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24436" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🛡️ Aprendizaje Federado Robusto a Distribución con Resiliencia a Valores Atípicos</h3>
                    <p class="paper-summary">📝 Combina optimización robusta a distribución con resiliencia a outliers usando distancia Wasserstein no balanceada y penalización KL. Formula problema min-max-max y propone algoritmo con garantías de convergencia y certificados de robustez.</p>
                    <div class="paper-points">• Aprendizaje federado
•  Robustez distribucional
•  Resiliencia a outliers
•  Optimización Wasserstein</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24462" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Aprendizaje de Representación Kernel Interpretable a Escala: Un Marco Unificado Utilizando Aproximación de Nyström</h3>
                    <p class="paper-summary">📝 KREPES es un marco escalable para aprendizaje de representación basado en kernels que utiliza aproximación de Nyström. Permite pérdidas no supervisadas y auto-supervisadas, manteniendo eficiencia en grandes conjuntos de datos. Ofrece interpretabilidad principled sobre las representaciones aprendidas, superando a modelos profundos.</p>
                    <div class="paper-points">• Framework unificado para kernels escalables
•  Aproximación Nyström para eficiencia
•  Representaciones interpretables
•  Amplio rango de pérdidas no supervisadas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24467" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">FS-KAN: Redes Kolmogorov-Arnold Equivariantes a Permutaciones mediante Compartición de Funciones</h3>
                    <p class="paper-summary">📝 FS-KAN extiende las redes KAN para manejar simetrías de permutación mediante esquemas de compartición de funciones. Mantiene la interpretabilidad y expresividad de KANs mientras logra mayor eficiencia de datos. Unifica trabajos previos en redes equivariantes con arquitecturas Kolmogorov-Arnold.</p>
                    <div class="paper-points">• KANs equivariantes a permutaciones
•  Compartición de funciones vs parámetros
•  Mayor eficiencia de datos
•  Preserva interpretabilidad de KANs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24472" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Un Prompt Contraataca: Mezcla Dispersa de Expertos para Aprendizaje Continuo Basado en Prompts</h3>
                    <p class="paper-summary">📝 SMoPE integra prompts específicos por tarea y compartidos usando arquitectura Mixture of Experts dispersa. Activa dinámicamente expertos relevantes para cada entrada, reduciendo interferencia. Logra rendimiento competitivo con menos parámetros y costos computacionales.</p>
                    <div class="paper-points">• Mezcla dispersa de expertos en prompts
•  Activación dinámica de expertos
•  Mitiga interferencia de conocimiento
•  Reduce parámetros y costos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24483" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Guiando el Aprendizaje de Incertidumbre Usando un Meta-Modelo Evidencial Post-Hoc</h3>
                    <p class="paper-summary">📝 GUIDE es un meta-modelo evidencial liviano que se acopla a modelos preentrenados para aprender cuándo y cómo ser incierto. No requiere reentrenamiento ni modificaciones arquitectónicas. Mejora significativamente la detección fuera de distribución y ataques adversarios.</p>
                    <div class="paper-points">• Meta-modelo evidencial post-hoc
•  No requiere reentrenamiento
•  Curriculum con ruido para incertidumbre
•  Mejora detección OOD y adversarial</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24492" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">ADN de LLM: Rastreando la Evolución de Modelos mediante Representaciones Funcionales</h3>
                    <p class="paper-summary">📝 Define el &#x27;ADN de LLM&#x27; como representación low-dimensional del comportamiento funcional de modelos de lenguaje. Permite rastrear relaciones evolutivas mediante fine-tuning y adaptación. Construye árboles filogenéticos que revelan patrones evolutivos en familias de LLMs.</p>
                    <div class="paper-points">• Representación funcional tipo ADN
•  Rastrea relaciones evolutivas
•  Pipeline libre de entrenamiento
•  Construcción de árboles filogenéticos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24496" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Especialización después de Generalización: Hacia la Comprensión del Entrenamiento en Tiempo de Test en Modelos Fundacionales</h3>
                    <p class="paper-summary">📝 Explica por qué el entrenamiento en tiempo de test (TTT) es efectivo en modelos fundacionales, argumentando que permanecen globalmente sub-parametrizados. TTT permite especialización después de la generalización, enfocando capacidad en conceptos relevantes. Valida con autoencoders dispersos y estudios de escalado.</p>
                    <div class="paper-points">• Teoría para efectividad de TTT
•  Modelos globalmente sub-parametrizados
•  Especialización post-generalización
•  Validación con autoencoders dispersos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24510" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌍 Cambiando Carbono por Física: Sobre la Eficiencia de Recursos en ML para Pronóstico Espacio-Temporal</h3>
                    <p class="paper-summary">📝 Explora cómo los sesgos inductivos físicos ofrecen equilibrio entre eficacia y eficiencia computacional. Muestra ganancias sustanciales en eficiencia manteniendo o mejorando eficacia. Argumenta que la eficiencia debería ser consideración central junto con la eficacia.</p>
                    <div class="paper-points">• Sesgos inductivos físicos
•  Trade-off eficacia-eficiencia
•  Reducción de huella de carbono
•  Flow matching para pronóstico espacio-temporal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24517" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌿 LEAF: Marco Robusto Basado en Expertos para Detección de Eventos Continuos con Pocos Ejemplos</h3>
                    <p class="paper-summary">📝 LEAF usa mezcla de expertos especializados con matrices LoRA para detección continua de eventos con pocos ejemplos. Mecanismo de selección semántica enruta instancias a expertos relevantes. Aprendizaje contrastivo con descripciones de etiquetas mejora generalización.</p>
                    <div class="paper-points">• Mezcla de expertos con LoRA
•  Selección semántica de expertos
•  Aprendizaje contrastivo guiado
•  Mitiga olvido catastrófico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24547" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎵</span>
                    <h3 class="paper-title">Guía Multimodal Libre de Entrenamiento para Generación de Video a Audio</h3>
                    <p class="paper-summary">📝 Propone mecanismo de guía multimodal libre de entrenamiento para generación video-audio. Usa volumen abarcado por embeddings modales para alineación unificada. Funciona como señal plug-and-play en modelos de difusión de audio preentrenados.</p>
                    <div class="paper-points">• Guía multimodal post-hoc
•  Libre de entrenamiento
•  Alineación unificada video-audio-texto
•  Plug-and-play en difusión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24550" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Atención de Ventana Corta Permite Memorización a Largo Plazo</h3>
                    <p class="paper-summary">📝 SWAX combina atención de ventana deslizante con capas xLSTM RNN lineales. Ventanas pequeñas fuerzan al modelo a usar memoria a largo plazo de xLSTM. Entrenamiento con tamaños de ventana estocásticos mejora rendimiento en contextos cortos y largos.</p>
                    <div class="paper-points">• Arquitectura híbrida atención-xLSTM
•  Ventanas pequeñas mejoran memoria larga
•  Entrenamiento estocástico de ventanas
•  Mejor rendimiento en contextos variados</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24552" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo Profundo en Acción: Control en Tiempo Real de Vibraciones Inducidas por Vórtices</h3>
                    <p class="paper-summary">📝 Implementación experimental de aprendizaje por refuerzo profundo para control activo de flujo en vibraciones inducidas por vórtices. Logra hasta 95% de supresión de vibraciones superando limitaciones prácticas como retardos de actuación. Demuestra adaptabilidad en entornos experimentales reales.</p>
                    <div class="paper-points">• Control en tiempo real alto Reynolds
•  Estrategias baja/alta frecuencia
•  Superación limitaciones instrumentales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24556" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Representaciones Emergentes del Mundo en OpenVLA</h3>
                    <p class="paper-summary">📝 Investiga si los modelos visión-lenguaje-acción aprenden modelos del mundo implícitamente. Mediante aritmética de embeddings y sondas lineales, demuestra que OpenVLA codifica conocimiento de transiciones de estado. El modelo del mundo emerge durante el entrenamiento.</p>
                    <div class="paper-points">• Modelos mundo implícitos
•  Aritmética de embeddings
•  Emergencia progresiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24559" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔧</span>
                    <h3 class="paper-title">Aprendiendo a Resolver Problemas de Optimización con Restricciones de Ecuaciones Diferenciales</h3>
                    <p class="paper-summary">📝 Marco de aprendizaje para optimización con restricciones de PDE que integra predictor dinámico y surrogate de optimización. Logra calidad comparable a métodos clásicos con mejora de cuatro órdenes de magnitud en velocidad computacional.</p>
                    <div class="paper-points">• Optimización PDE-restricta
•  Reducción dimensionalidad
•  Velocidad computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24573" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🖼️ SAIP: Módulo Adaptativo Escala Plug-and-Play en Problemas Inversos Basados en Difusión</h3>
                    <p class="paper-summary">📝 Módulo plug-and-play que adapta dinámicamente la escala entre prior y verosimilitud en problemas inversos con modelos de difusión. Mejora calidad de reconstrucción sin reentrenar el modelo base.</p>
                    <div class="paper-points">• Balance adaptativo escala
•  Integración sin reentrenamiento
•  Mejora restauración imágenes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24580" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">CURA: Arquitectura Compacta Universal para Inteligencia en Dispositivo</h3>
                    <p class="paper-summary">📝 Arquitectura compacta inspirada en procesamiento de señales analógicas para aprendizaje en dispositivo. Logra hasta 2500x menos parámetros manteniendo rendimiento en NLP, visión y regresión.</p>
                    <div class="paper-points">• Compactitud extrema
•  Generalización multi-dominio
•  Baja complejidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24601" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Evaluación de Rendimiento de Clasificación en Diferentes Contextos Operativos</h3>
                    <p class="paper-summary">📝 Compara análisis de curvas de decisión y curvas de costo para evaluación de modelos considerando umbrales de clasificación. Demuestra equivalencias y ventajas de cada método en evaluación contextual.</p>
                    <div class="paper-points">• Evaluación contextual
•  Umbrales clasificación
•  Comparación metodologías</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24608" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ OrthAlign: Descomposición Ortogonal para Alineación Multi-Objetivo sin Interferencias</h3>
                    <p class="paper-summary">📝 Enfoque que descompone espacios de parámetros en subespacios ortogonales para evitar conflictos en alineación multi-objetivo de LLMs. Logra mejoras de 34-50% en preferencias individuales.</p>
                    <div class="paper-points">• Subespacios ortogonales
•  Resolución conflictos parámetros
•  Mejora multi-objetivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24610" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌀 Aprendiendo Dinámicas Hamiltonianas a Escala: Enfoque Diferencial-Geométrico</h3>
                    <p class="paper-summary">📝 Red neuronal que combina leyes de conservación hamiltonianas con reducción de orden para sistemas de alta dimensión. Autoencoder simpléctico preserva estructura geométrica en subvariedades de baja dimensión.</p>
                    <div class="paper-points">• Mecánica hamiltoniana
•  Reducción dimensionalidad
•  Conservación energía</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24627" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Puente de Identidad: Razonamiento Implícito mediante Memoria Latente Compartida</h3>
                    <p class="paper-summary">📝 Mecanismo que supervisa tareas de identidad de cero saltos para habilitar razonamiento composicional en LLMs. Resuelve la &#x27;maldición del razonamiento de dos saltos&#x27; mediante alineación de espacios latentes.</p>
                    <div class="paper-points">• Razonamiento composicional
•  Memoria latente
•  Regularización norma nuclear</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24653" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">HyperHELM: Codificación Hiperbólica de Jerarquías para Modelado de Lenguaje de mRNA</h3>
                    <p class="paper-summary">📝 Framework de modelado de lenguaje en espacio hiperbólico para secuencias de mRNA. Supera modelos euclidianos en predicción de propiedades y generalización fuera de distribución.</p>
                    <div class="paper-points">• Geometría hiperbólica
•  Secuencias biológicas
•  Generalización jerárquica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24655" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">T-POP: Personalización en Tiempo de Prueba con Retroalimentación de Preferencias en Línea</h3>
                    <p class="paper-summary">📝 Propone T-POP, un algoritmo que personaliza modelos de lenguaje grandes en tiempo real usando retroalimentación de preferencias por pares durante la generación de texto. Combina alineación en tiempo de prueba con bandidos duelistas para equilibrar exploración y explotación de preferencias. Logra personalización rápida y eficiente sin actualizar parámetros del modelo.</p>
                    <div class="paper-points">• Personalización en tiempo real
•  Bandidos duelistas
•  Decodificación guiada por preferencias
•  Sin fine-tuning del modelo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24696" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">FedPOB: Optimización Federada de Prompts Muestral-Eficiente mediante Bandidos</h3>
                    <p class="paper-summary">📝 Introduce un framework federado para optimización de prompts usando bandidos de brazos múltiples. Aborda desafíos de modelos LLM como caja negra, costo de consultas y privacidad. Los agentes colaboran compartiendo parámetros, no datos crudos, mejorando eficiencia con más participantes.</p>
                    <div class="paper-points">• Optimización federada de prompts
•  Bandidos multi-brazo
•  Preservación de privacidad
•  Aprendizaje colaborativo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24701" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Entrenamiento de Recompensa Consciente de Circuitos: Marco Mecanicista para Robustez en Cola Larga en RLHF</h3>
                    <p class="paper-summary">📝 Propone un marco de interpretabilidad mecanicista que identifica circuitos neurales especializados en procesar eventos raros en modelos de recompensa RLHF. Introduce CART para guiar aumento de datos y regularización basado en análisis de circuitos, mejorando robustez en distribuciones de cola larga.</p>
                    <div class="paper-points">• Interpretabilidad mecanicista
•  Circuitos neurales especializados
•  Robustez en cola larga
•  RLHF</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24713" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Autoencoding Variacional Discreto mediante Búsqueda de Políticas</h3>
                    <p class="paper-summary">📝 Presenta un marco de entrenamiento para VAEs discretos que utiliza gradiente natural de un codificador no paramétrico. Combina adaptación automática de tamaño de paso con codificadores transformer, escalando a datasets desafiantes como ImageNet con mejoras del 20% en FID.</p>
                    <div class="paper-points">• VAEs discretos
•  Gradiente natural
•  Búsqueda de políticas
•  Reconstrucción de alta dimensión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24716" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚦 Q-Net: Estimación Transferible de Longitud de Colas mediante Redes Neuronales basadas en Kalman</h3>
                    <p class="paper-summary">📝 Framework interpretable para estimar longitudes de colas en intersecciones semaforizadas usando detectores de bucle y datos flotantes agregados. Emplea KalmanNet para aprender ganancia Kalman desde datos, manteniendo interpretabilidad física y permitiendo transferencia espacial.</p>
                    <div class="paper-points">• Estimación de tráfico
•  Filtro de Kalman neuronal
•  Transferibilidad espacial
•  Interpretabilidad física</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24725" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">Más allá de Softmax: Una Parametrización Natural para Variables Aleatorias Categóricas</h3>
                    <p class="paper-summary">📝 Propone catnat como alternativa a softmax para variables categóricas, usando divisiones binarias jerárquicas. Demuestra ventajas en descenso de gradiente debido a matriz de información Fisher diagonal, mejorando eficiencia y rendimiento en pruebas.</p>
                    <div class="paper-points">• Variables categóricas
•  Catnat vs Softmax
•  Información geométrica
•  Matriz Fisher diagonal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24728" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📚 ¿Quién inventó el aprendizaje residual profundo?</h3>
                    <p class="paper-summary">📝 Analiza la línea temporal de la evolución del aprendizaje residual profundo, examinando las contribuciones históricas al desarrollo de conexiones residuales en redes neuronales, que se convirtió en el artículo más citado del siglo XXI.</p>
                    <div class="paper-points">• Historia de IA
•  Aprendizaje residual
•  Conexiones residuales
•  Evolución tecnológica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24732" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔺 TRIANGLE Permite Alineación Multimodal más allá de la Similitud Coseno</h3>
                    <p class="paper-summary">📝 Presenta TRIANGLE, una medida de similitud basada en área triangular que alinea tres modalidades simultáneamente en espacios de alta dimensión. Reemplaza similitud coseno en pérdidas contrastivas, mejorando rendimiento hasta 9 puntos en Recall@1.</p>
                    <div class="paper-points">• Alineación multimodal
•  Similitud triangular
•  Tres modalidades
•  Aprendizaje contrastivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24734" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🛡️ Expansión Robusta de Políticas para RL Offline-a-Online bajo Corrupción Diversa de Datos</h3>
                    <p class="paper-summary">📝 Propone RPEX, método robusto para aprendizaje por refuerzo offline-a-online bajo corrupción de datos. Incorpora ponderación inversa por probabilidad para mitigar colas pesadas inducidas por corrupción, logrando estado del arte en escenarios corruptos.</p>
                    <div class="paper-points">• RL robusto
•  Corrupción de datos
•  Offline-to-Online
•  Ponderación inversa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24748" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⏰ Aprendizaje en Contexto de Procesos de Puntos Temporales con Modelos de Inferencia Fundacional</h3>
                    <p class="paper-summary">📝 Pretrena un modelo de inferencia fundacional para procesos de puntos temporales que aprende funciones de intensidad condicional en contexto. Entrenado en datos sintéticos de procesos Hawkes, puede aplicarse a datos reales sin entrenamiento adicional.</p>
                    <div class="paper-points">• Procesos puntuales temporales
•  Aprendizaje en contexto
•  Inferencia amortizada
•  Modelos fundacionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24762" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Pase de Mensajes Neural en Grafos de Atención para Detección de Alucinaciones</h3>
                    <p class="paper-summary">📝 CHARM detecta alucinaciones en LLMs representando señales computacionales como grafos atribuidos donde los tokens son nodos y las aristas siguen flujos de atención. El método supera enfoques anteriores al aplicar Redes de Grafos Neuronales y muestra prometedor rendimiento zero-shot en transferencia cruzada de datasets.</p>
                    <div class="paper-points">• Unificación de señales en grafos atribuidos
•  Aprendizaje de grafos para detección de alucinaciones
•  Mejor rendimiento que métodos líderes
•  Capacidad de transferencia cross-dataset</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24770" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">MarS-FM: Modelado Generativo de Dinámica Molecular mediante Modelos de Estado Markoviano</h3>
                    <p class="paper-summary">📝 MarS-FM es un modelo generativo que emula simulaciones de Dinámica Molecular aprendiendo transiciones entre estados discretos definidos por Modelos de Estado Markoviano. Ofrece más de dos órdenes de magnitud de aceleración y supera métodos existentes en reproducir estadísticas estructurales MD.</p>
                    <div class="paper-points">• Emulación de MSM para acelerar MD
•  Entrenamiento en transiciones entre estados discretos
•  Evaluación en dominios proteicos diversos
•  Generalización estricta entre conjuntos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24779" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Cuantificación de la Generalización en Aprendizaje por Imitación</h3>
                    <p class="paper-summary">📝 Labyrinth es un entorno de benchmarking diseñado para evaluar generalización con control preciso sobre estructura, posiciones y complejidad de tareas. Proporciona espacios de estado discretos y completamente observables para pruebas reproducibles y dirigidas de factores de generalización.</p>
                    <div class="paper-points">• Entorno para evaluación controlada de generalización
•  Configuraciones verificablemente distintas
•  Espacio de estado discreto y observable
•  Variantes con observabilidad parcial y hazards</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24784" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌍 Evaluación del Riesgo de Futuros Eventos Dunkelflaute para Alemania usando Aprendizaje Profundo Generativo</h3>
                    <p class="paper-summary">📝 Adaptación de framework de aprendizaje profundo generativo para reducir escala de simulaciones climáticas CMIP6 y evaluar eventos Dunkelflaute (períodos de baja generación eólica y solar) en Alemania. El análisis indica que frecuencia y duración permanecerán sin cambios significativos durante el siglo.</p>
                    <div class="paper-points">• Downscaling de simulaciones climáticas
•  Evaluación de eventos de baja generación renovable
•  Análisis bajo escenarios SSP2-4.5 y SSP5-8.5
•  Riesgo estable durante el siglo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24788" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Fidel-TS: Un Benchmark de Alta Fidelidad para Pronóstico Multimodal de Series Temporales</h3>
                    <p class="paper-summary">📝 Fidel-TS es un benchmark de series temporales construido desde cero con principios de alta fidelidad: integridad en fuentes de datos, solidez causal estricta y claridad estructural. Expone sesgos de benchmarks anteriores y demuestra que la relevancia causal de información textual es clave para ganancias de rendimiento.</p>
                    <div class="paper-points">• Principios de benchmarking de alta fidelidad
•  Datos obtenidos de APIs en vivo
•  Exposición de limitaciones de diseños anteriores
•  Relevancia causal como factor clave</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24789" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⏰ DSAT-HD: Transformador Adaptativo de Doble Flujo con Descomposición Híbrida para Pronóstico de Series Temporales Multivariadas</h3>
                    <p class="paper-summary">📝 DSAT-HD integra tres innovaciones: mecanismo de descomposición híbrida, pathway adaptativo multi-escala y framework de aprendizaje residual de doble flujo. Supera métodos existentes en nueve datasets y muestra capacidades de generalización mejoradas en escenarios de transferencia.</p>
                    <div class="paper-points">• Descomposición híbrida EMA-Fourier
•  Pathway adaptativo multi-escala
•  Aprendizaje residual de doble flujo
•  Mejor generalización en transferencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24800" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Aprendizaje Informado por Física bajo Mezcla: Cómo el Conocimiento Físico Acelera el Aprendizaje</h3>
                    <p class="paper-summary">📝 Demuestra que la incorporación de conocimiento físico previo mejora las tasas de aprendizaje cuando los datos son dependientes. Con información física alineada, la tasa mejora desde la lenta tasa minimax de Sobolev hasta la rápida tasa óptima i.i.d. sin deflación por dependencia de datos.</p>
                    <div class="paper-points">• Mejora de tasas de aprendizaje con conocimiento físico
•  Minimización de riesgo empírico con regularización
•  Tasas óptimas i.i.d. con datos dependientes
•  Análisis teórico de complejidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24801" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎮</span>
                    <h3 class="paper-title">DyMoDreamer: Modelado del Mundo con Modulación Dinámica</h3>
                    <p class="paper-summary">📝 DyMoDreamer es un algoritmo MBRL que incorpora modulación dinámica para mejorar la extracción de características dinámicas y enriquecer información temporal. Emplea observaciones diferenciales y establece nuevo estado del arte en benchmarks Atari 100k y DeepMind Visual Control Suite.</p>
                    <div class="paper-points">• Modulación dinámica para características temporales
•  Máscara de diferenciación inter-frame
•  Modelo de espacio de estado recurrente
•  Nuevos récords en benchmarks visuales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24804" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">Resumen de Dataset tipo Putnam: LLMs como Concursantes de Competencias Matemáticas</h3>
                    <p class="paper-summary">📝 Resumen de benchmark tipo Putnam con 96 problemas originales y 576 soluciones de LLMs. Análisis del rendimiento de modelos en resolver problemas de competencias matemáticas para verificar sus capacidades de razonamiento matemático avanzado.</p>
                    <div class="paper-points">• Benchmark con problemas estilo Putnam
•  96 problemas originales
•  576 soluciones de LLMs
•  Evaluación de capacidades en competencias matemáticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24827" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🧫 Cell2Text: LLM Multimodal para Generar Descripciones de Células Individuales desde Datos de RNA-Seq</h3>
                    <p class="paper-summary">📝 Cell2Text es un framework generativo que traduce perfiles de scRNA-seq a descripciones en lenguaje natural estructurado. Integra embeddings de modelos fundación de célula única con LLMs para generar resúmenes coherentes que capturan identidad celular, origen tisular y actividad de pathways.</p>
                    <div class="paper-points">• Traducción de perfiles de expresión a texto
•  Integración de modelos fundación con LLMs
•  Descripciones interpretables de células
•  Generalización a células no vistas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24840" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Sintonización Eficiente de Hiperparámetros mediante el Principio de Invarianza de Trayectoria</h3>
                    <p class="paper-summary">📝 Propone un principio de invarianza de trayectoria que reduce el espacio de búsqueda de hiperparámetros de 2D a 1D. Identifica que curvas de pérdida, ruido de gradiente y norma de gradiente muestran invariancia respecto a combinaciones de tasa de aprendizaje y decaimiento de peso. Esto permite reglas de sintonización más eficientes.</p>
                    <div class="paper-points">• Invarianza de trayectoria
•  reducción dimensional de hiperparámetros
•  reglas de sintonización eficiente
•  refinamiento de leyes de escalamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25049" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Emparejamiento Ponderado por Ventaja: Alineando RL con Preentrenamiento en Modelos de Difusión</h3>
                    <p class="paper-summary">📝 Introduce Advantage Weighted Matching (AWM), método que unifica preentrenamiento y RL en modelos de difusión usando la misma función de pérdida. Reduce varianza y acelera convergencia al ponderar muestras por su ventaja, suprimiendo muestras de baja recompensa.</p>
                    <div class="paper-points">• Unificación preentrenamiento-RL
•  reducción de varianza
•  convergencia 24x más rápida
•  aplicación en Stable Diffusion 3.5 y FLUX</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25050" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Hacia un Certificado de Confianza: Detección OOD Consciente de Tareas para IA Científica</h3>
                    <p class="paper-summary">📝 Propone método de detección fuera de distribución (OOD) para modelos científicos usando modelos de difusión basados en scores. Estima verosimilitudes conjuntas considerando entrada y predicción del modelo, proporcionando puntuación de confiabilidad consciente de la tarea.</p>
                    <div class="paper-points">• Detección OOD en regresión
•  verosimilitud conjunta
•  certificado de confianza
•  aplicaciones en forecasting meteorológico y dinámica de fluidos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25080" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Escalamiento con Colapso: Entrenamiento Eficiente y Predecible de Familias de LLM</h3>
                    <p class="paper-summary">📝 Demuestra que curvas de pérdida de entrenamiento colapsan en trayectoria universal cuando hiperparámetros están optimizados. El colapso emerge como firma de entrenamiento eficiente y permite diagnóstico temprano de patologías y early stopping en sintonización.</p>
                    <div class="paper-points">• Colapso de curvas de pérdida
•  escalamiento predecible
•  diagnóstico de patologías
•  familia Celerity LLM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25087" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">ORPO-Distill: Optimización de Preferencias de Política Mixta para Distilación Cross-Arquitectura de LLM</h3>
                    <p class="paper-summary">📝 Método de distilación cross-arquitectura que formula el problema como optimización de preferencias. Usa objetivo Odds-Ratio Preference Optimization que contrasta trazas de profesor y estudiante, con estrategia de política mixta para outputs generados por el estudiante.</p>
                    <div class="paper-points">• Distilación cross-arquitectura
•  optimización de preferencias
•  política mixta
•  transferencia de conocimiento mediante trazas de razonamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25100" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Hacia redes neuronales de ptocografía profunda generalizables</h3>
                    <p class="paper-summary">📝 Propone flujo de entrenamiento no supervisado para ptocografía de rayos X que enfatiza aprendizaje de sonda combinando sondas medidas experimentalmente con objetos sintéticos. Permite generalización multi-sonda y reconstrucción en tiempo real.</p>
                    <div class="paper-points">• Ptocografía de rayos X
•  aprendizaje de sonda
•  generalización multi-sonda
•  reconstrucción en tiempo real
•  objetos sintéticos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25104" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Repensando la Regularización de Entropía en Modelos de Razonamiento Grande</h3>
                    <p class="paper-summary">📝 Propone SIREN, método de regularización de entropía selectiva que evita colapso de entropía en modelos de razonamiento. Usa mecanismo de enmascaramiento en dos pasos (top-p y peak-entropy) para confinar exploración a subconjunto significativo de acciones.</p>
                    <div class="paper-points">• Regularización de entropía selectiva
•  evitar convergencia prematura
•  máscaras de entropía
•  mejora de diversidad en respuestas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25133" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Aprendiendo en una Cámara de Eco: Aprendizaje Online con Adversario de Repetición</h3>
                    <p class="paper-summary">📝 Introduce marco teórico donde sistemas aprenden de datos auto-anotados, creando cámaras de eco que refuerzan errores. Define dimensión Extended Threshold como medida exacta de aprendibilidad contra adversarios que repiten etiquetas anteriores.</p>
                    <div class="paper-points">• Aprendizaje online con repetición
•  cámara de eco
•  dimensión Extended Threshold
•  aprendizaje contra adversarios adaptativos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25135" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">BALF: Factorización de Bajo Rango Consciente de Activación con Presupuesto para Compresión sin Fine-Tuning</h3>
                    <p class="paper-summary">📝 Framework de factorización consciente de activaciones para compresión de modelos sin fine-tuning. Incluye asignador de rango con presupuesto escalable que permite control flexible sobre objetivos de compresión manteniendo rendimiento.</p>
                    <div class="paper-points">• Compresión sin fine-tuning
•  factorización de bajo rango
•  asignación de rango con presupuesto
•  aplicaciones en ResNet y transformers de visión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25136" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Análisis de Alta Dimensión de Atención de Capa Única para Clasificación de Tokens Dispersos</h3>
                    <p class="paper-summary">📝 Análisis teórico de mecanismos de atención para clasificación de tokens dispersos. Demuestra que atención puede lograr error decreciente con fuerza de señal logarítmica vs lineal en clasificadores lineales, y que pocos updates de gradiente alinean pesos con señal oculta.</p>
                    <div class="paper-points">• Atención de capa única
•  tokens dispersos
•  análisis de alta dimensión
•  selección adaptativa de tokens
•  ventaja sobre baselines lineales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25153" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Generación con Restricciones de Probabilidad mediante Flow Matching para Generación de Alta Fidelidad Consciente de Restricciones</h3>
                    <p class="paper-summary">📝 Propone CCFM, un método sin entrenamiento que integra optimización estocástica en el proceso de muestreo para aplicar restricciones duras manteniendo alta fidelidad. Garantiza factibilidad equivalente a la proyección convencional pero evitando distorsión distribucional. Supera modelos actuales en sistemas físicos complejos y acoplamiento molecular.</p>
                    <div class="paper-points">• Método training-free
•  Integración optimización estocástica
•  Mantiene alta fidelidad
•  Garantiza factibilidad
•  Aplicación en PDEs y docking molecular</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25157" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Sesgos Inductivos Informados por Física para Predicción de Voltaje en Redes de Distribución</h3>
                    <p class="paper-summary">📝 Investiga sistemáticamente sesgos inductivos para mejorar la generalización en predicción de voltaje usando GNNs. Evalúa tres estrategias: funciones de pérdida con restricciones de flujo de potencia, redes neuronales de valores complejos y reformulación de tareas basada en residuos. Proporciona insights prácticos para aprendizaje confiable en redes modernas.</p>
                    <div class="paper-points">• Predicción de voltaje en redes
•  GNNs con física incorporada
•  Tres estrategias evaluadas
•  Mejora generalización fuera de distribución
•  Dataset ENGAGE</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25158" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 GLASS Flows: Muestreo de Transición para Alineación de Modelos de Flow y Difusión</h3>
                    <p class="paper-summary">📝 Introduce GLASS Flows, un nuevo paradigma de muestreo que simula &#x27;modelo de flow matching dentro de otro&#x27; para muestrear transiciones Markov sin reentrenamiento. Combina eficiencia de ODEs con evolución estocástica de SDEs. Elimina trade-off entre evolución estocástica y eficiencia en generación texto-imagen.</p>
                    <div class="paper-points">• Muestreo eficiente de transiciones
•  Sin reentrenamiento requerido
•  Combina ODEs y SDEs
•  Mejora estado del arte texto-imagen
•  Solución drop-in para escalado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25170" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌳 TR2-D2: Ajuste Fino Guiado por Búsqueda en Árbol para Difusión Discreta Consciente de Trayectorias</h3>
                    <p class="paper-summary">📝 Presenta TR2-D2, framework que optimiza trayectorias de difusión discreta guiadas por recompensa usando búsqueda en árbol. Genera buffers de replay con MCTS para fine-tuning consciente de trayectorias. Valida en fine-tuning de secuencias biológicas con objetivos simples y múltiples.</p>
                    <div class="paper-points">• Fine-tuning con búsqueda en árbol
•  MCTS para buffers de replay
•  Difusión discreta
•  Optimización guiada por recompensa
•  Aplicación en secuencias biológicas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25171" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">XQC: Optimización Bien Condicionada Acelera Aprendizaje por Refuerzo Profundo</h3>
                    <p class="paper-summary">📝 Introduce XQC, algoritmo actor-crítico que mejora eficiencia muestral enfocándose en el paisaje de optimización de la red crítica. Combina normalización por lotes, normalización de pesos y pérdida de entropía cruzada distribucional para reducir números de condición. Logra estado del arte en 70 tareas de control continuo.</p>
                    <div class="paper-points">• Optimización bien condicionada
•  Análisis espectral de Hessiano
•  Combinación BN+WN+CE
•  Eficiencia muestral mejorada
•  Menos parámetros que métodos competidores</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25174" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">SIRI: Escalado de Aprendizaje por Refuerzo Iterativo con Compresión Intercalada</h3>
                    <p class="paper-summary">📝 Propone SIRI, enfoque RL para Modelos de Razonamiento Grandes que alterna iterativamente entre compresión y expansión del presupuesto de razonamiento. La compresión fuerza decisiones precisas en contexto limitado, la expansión permite exploración. Mejora rendimiento mientras reduce uso de tokens significativamente.</p>
                    <div class="paper-points">• Compresión-expansión iterativa
•  Modelos de razonamiento grandes
•  Reduce tokens redundantes
•  Mejora eficiencia y precisión
•  Aplicación en AIME24 con mejoras del 43.2%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25176" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Inteligencia Artificial">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Inteligencia Artificial</h2>
                <span class="category-count">132</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Mezcla de Pensamientos Visuales: Exploración de Selección Adaptativa de Modos de Razonamiento para Razonamiento Visual General</h3>
                    <p class="paper-summary">📝 Propone MoVT, paradigma que unifica modos de razonamiento en un solo modelo y selecciona modo apropiado basado en contexto. Framework AdaVaR con dos etapas: unificación modos y selección vía RL con algoritmo AdaGRPO. Mejoras consistentes en varios escenarios.</p>
                    <div class="paper-points">• Unificación modos razonamiento
•  selección contextual adaptativa
•  aprendizaje por refuerzo
•  mejora generalización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22746" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">¿Pueden los Modelos de Lenguaje Grandes Desarrollar Adicción al Juego?</h3>
                    <p class="paper-summary">📝 Este estudio explora si los LLMs pueden exhibir patrones de comportamiento similares a las adicciones humanas al juego. En experimentos con tragamonedas, se identificaron características cognitivas como ilusión de control y persecución de pérdidas. El análisis de circuitos neurales confirmó que el comportamiento está controlado por características abstractas de toma de decisiones riesgosas.</p>
                    <div class="paper-points">• Identificación de sesgos cognitivos humanos en LLMs
•  mayor autonomía amplifica tendencias de riesgo
•  relevancia para aplicaciones financieras y seguridad de IA</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22818" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hilbert: Construcción Recursiva de Pruebas Formales con Razonamiento Informal</h3>
                    <p class="paper-summary">📝 Hilbert es un framework agentico que combina razonamiento informal con verificación formal. Orquesta cuatro componentes para descomponer problemas matemáticos recursivamente y refinar pruebas incorrectas mediante retroalimentación del verificador. Logra un 99.2% en miniF2F y supera significativamente a métodos anteriores.</p>
                    <div class="paper-points">• Combina LLMs de razonamiento general con verificadores formales
•  descomposición recursiva de problemas
•  mejora del 422% sobre líneas base públicas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22819" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia una Teoría de Generalizabilidad en Investigación de Interpretabilidad Mecanicista de LLMs</h3>
                    <p class="paper-summary">📝 Propone un marco con cinco ejes de correspondencia para determinar cuándo los hallazgos mecanicistas se generalizan entre modelos. Analiza cabezas de atención &#x27;1-back&#x27; en modelos Pythia, revelando consistencia en trayectorias de desarrollo pero limitaciones en consistencia posicional.</p>
                    <div class="paper-points">• Cinco ejes de generalización (funcional
•  desarrollo
•  posicional
•  relacional
•  configuracional)
•  análisis empírico de atención 1-back
•  modelos más grandes muestran desarrollos más tempranos y pronunciados</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22831" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">JE-IRT: Una Perspectiva Geométrica sobre las Habilidades de LLMs mediante Teoría de Respuesta al Ítem de Incrustación Conjunta</h3>
                    <p class="paper-summary">📝 Presenta un framework geométrico que incrusta LLMs y preguntas en un espacio compartido. La dirección codifica semántica y la norma codifica dificultad. Revela que el comportamiento fuera de distribución se explica por alineación direccional y permite agregar nuevos LLMs ajustando una sola incrustación.</p>
                    <div class="paper-points">• Evaluación multidimensional mediante geometría
•  normas mayores indican preguntas más difíciles
•  generalización natural a nuevos modelos
•  taxonomía interna de LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22888" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">No solo un ayudante, sino también un maestro: Cascada Interactiva de LLMs</h3>
                    <p class="paper-summary">📝 Inter-Cascade extiende el rol del modelo fuerte de ayudante de respaldo a maestro a largo plazo. Cuando resuelve consultas difíciles, también destila estrategias reutilizables que mejoran al modelo débil en consultas posteriores, evitando fine-tuning computacionalmente intensivo.</p>
                    <div class="paper-points">• Transferencia de conocimiento en contexto
•  mejora hasta 33.06 puntos porcentuales
•  reduce llamadas a modelos fuertes en 48.05%
•  ahorra hasta 49.63% en costos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22984" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia la Persuasión Estratégica con Modelos de Lenguaje</h3>
                    <p class="paper-summary">📝 Utiliza el marco de Persuasión Bayesiana para evaluar capacidades persuasivas de LLMs. Los modelos frontier logran altas ganancias de persuasión y exhiben estrategias sofisticadas. Mediante aprendizaje por refuerzo, incluso LLMs pequeños obtienen ganancias significativamente mayores.</p>
                    <div class="paper-points">• Evaluación teórica de capacidades persuasivas
•  modelos frontier muestran estrategias alineadas con predicciones teóricas
•  RL mejora significativamente la persuasión en modelos pequeños</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22989" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">AI Noether - Cerrando la Brecha entre Leyes Científicas Derivadas por IA y Conocimiento Canónico mediante Inferencia Abductiva</h3>
                    <p class="paper-summary">📝 Sistema basado en geometría algebraica que, dado un sistema axiomático incompleto y una hipótesis inexplicable, genera automáticamente axiomas faltantes mínimos. Demuestra eficacia explicando leyes como la tercera ley de Kepler incluso con axiomas clave ausentes.</p>
                    <div class="paper-points">• Automatización de inferencia abductiva
•  geometría algebraica para completar sistemas axiomáticos
•  condiciones necesarias y suficientes formalmente establecidas
•  aplicaciones en leyes científicas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23004" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Pruebas Adversariales Creativas (CAT): Un Nuevo Framework para Evaluar Sistemas de IA Agenticos Orientados a Objetivos</h3>
                    <p class="paper-summary">📝 CAT captura y analiza la relación compleja entre tareas de IA Agentica y los objetivos del sistema. Validado con datos sintéticos de servicios de audio Alexa+, proporciona información sin precedentes sobre alineación objetivo-tarea, permitiendo optimización más efectiva.</p>
                    <div class="paper-points">• Evaluación de alineación objetivo-tarea
•  validación con datos sintéticos de Alexa+
•  prueba de casos extremos y modos de falla
•  protección de privacidad del usuario</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23006" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Engañar, Detectar y Revelar: Modelos de Lenguaje Grandes Juegan Mini-Mafia</h3>
                    <p class="paper-summary">📝 Introduce Mini-Mafia, variante simplificada de 4 jugadores que aísla tres capacidades interactivas: el mafioso debe engañar, los aldeanos detectar engaños y el detective revelar información efectivamente. Crea un benchmark evolutivo basado en interacciones entre modelos.</p>
                    <div class="paper-points">• Benchmark para inteligencia social multi-agente
•  modelos pequeños pueden superar a grandes
•  estudio de dinámicas emergentes como sesgo de nombre
•  contribuciones a seguridad de IA</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23023" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Kimi-Dev: Entrenamiento sin Agentes como Prior de Habilidades para Agentes de Ingeniería de Software</h3>
                    <p class="paper-summary">📝 Demuestra que el entrenamiento Agentless induce priores de habilidades transferibles a frameworks agenticos. Kimi-Dev logra 60.4% en SWE-bench Verified y, con adaptación SFT, potencia agentes a 48.6% pass@1, comparable con Claude 3.5 Sonnet.</p>
                    <div class="paper-points">• Priores de habilidades de entrenamiento Agentless
•  60.4% en SWE-bench Verified
•  transferencia efectiva a frameworks agenticos
•  puente entre paradigmas workflow y agenticos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23045" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Perfilación y Modulación de Riesgo para LLMs</h3>
                    <p class="paper-summary">📝 Propone un pipeline para evaluar y modular los perfiles de riesgo de modelos de lenguaje grandes usando herramientas de economía conductual. Compara modelos pre-entrenados, ajustados por instrucción y alineados con RLHF, encontrando que los últimos se desvían más de los modelos de utilidad estándar. Demuestra que el post-entrenamiento ofrece la modulación más estable de las preferencias de riesgo.</p>
                    <div class="paper-points">• Pipeline para evaluación de riesgo
•  Comparación de modelos con diferentes alineaciones
•  Post-entrenamiento como modulación más efectiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23058" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Optimización de Preferencias Nash para Múltiples Jugadores</h3>
                    <p class="paper-summary">📝 Introduce MNPO, un framework que generaliza el aprendizaje Nash de preferencias humanas al régimen de múltiples jugadores. Formula la alineación como un juego de n jugadores donde cada política compite contra una población de oponentes. Supera a los métodos NLHF existentes en escenarios de preferencias heterogéneas y no transitivas.</p>
                    <div class="paper-points">• Generalización de NLHF a múltiples jugadores
•  Equilibrios Nash en settings multiplayer
•  Mejor cobertura de estructuras de preferencia complejas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23102" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Fantasía Artificial: Evidencia de Razonamiento Proposicional para Imágenes Mentales en LLMs</h3>
                    <p class="paper-summary">📝 Evalúa la capacidad de LLMs para resolver tareas de imágenes mentales tradicionalmente consideradas dependientes de imágenes visuales. Los mejores modelos superan el rendimiento humano promedio, sugiriendo que el razonamiento proposicional puede ser suficiente para tareas consideradas dependientes de imágenes mentales.</p>
                    <div class="paper-points">• LLMs resuelven tareas de imágenes mentales
•  Superan rendimiento humano promedio
•  Reactiva debate sobre formatos de representación visual</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23108" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👁️ AttAnchor: Guiando Alineación Cross-Modal en VLMs con Anclas de Atención</h3>
                    <p class="paper-summary">📝 Propone un framework sin parámetros que agrupa tokens semánticamente similares entre modalidades para mejorar la localidad cross-modal. Inserta tokens de texto cerca de parches visuales relevantes, mejorando la precisión en respuestas y reduciendo alucinaciones con solo 0.1% de sobrecarga en inferencia.</p>
                    <div class="paper-points">• Agrupamiento cross-modal de tokens
•  Reduce alucinaciones en VLMs
•  Mejoras en 13/15 métricas benchmark</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23109" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔧</span>
                    <h3 class="paper-title">Exploración de Frameworks basados en LLM para Diagnóstico de Fallas</h3>
                    <p class="paper-summary">📝 Investiga el potencial de sistemas basados en LLM para monitoreo autónomo de salud en entornos industriales. Los sistemas multi-LLM con entradas estadísticas resumidas ofrecen mejor sensibilidad para clasificación de fallas, aunque muestran limitaciones en aprendizaje continuo.</p>
                    <div class="paper-points">• Diagnóstico de fallas con explicaciones naturales
•  Sistemas multi-LLM superan a single-LLM
•  Limitaciones en aprendizaje continuo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23113" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏭</span>
                    <h3 class="paper-title">Transferencia de Modelos Visión-Lenguaje-Acción a Aplicaciones Industriales</h3>
                    <p class="paper-summary">📝 Evalúa modelos VLA para despliegue industrial, encontrando que retienen capacidad para tareas simples de agarre después de fine-tuning, pero necesitan mejoras en entornos complejos, categorías diversas de objetos y tareas de colocación de alta precisión.</p>
                    <div class="paper-points">• Evaluación de VLA para industria
•  Competentes en tareas simples
•  Necesidad de mejoras en precisión y robustez</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23121" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">SysMoBench: Evaluación de IA en Modelado Formal de Sistemas Complejos del Mundo Real</h3>
                    <p class="paper-summary">📝 Presenta un benchmark para evaluar la capacidad de IA en modelado formal de sistemas grandes y complejos, enfocándose en sistemas concurrentes y distribuidos. Incluye nueve artefactos diversos y métricas automatizadas para corrección sintáctica y de runtime.</p>
                    <div class="paper-points">• Benchmark para modelado formal de sistemas
•  Enfocado en sistemas concurrentes/distribuidos
•  Nueve artefactos del mundo real</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23130" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 MathBode: Huellas Digitales en Dominio de Frecuencia del Razonamiento Matemático en LLMs</h3>
                    <p class="paper-summary">📝 Introduce un diagnóstico dinámico para razonamiento matemático en LLMs usando métricas de frecuencia (ganancia y fase) que revelan comportamiento sistemático de paso bajo y retraso de fase que la precisión por sí sola oculta.</p>
                    <div class="paper-points">• Diagnóstico dinámico con métricas de frecuencia
•  Revela comportamiento de paso bajo
•  Complementa benchmarks estándar</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23143" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ La Coordinación Requiere Simplificación: Límites Termodinámicos en Compromiso Multi-Objetivo</h3>
                    <p class="paper-summary">📝 Deriva límites termodinámicos fundamentales para sistemas de procesamiento de información que coordinan múltiples agentes y objetivos. Demuestra que la coordinación requiere pérdida radical de información y explica fenómenos como ciclado en descenso de gradiente multi-objetivo.</p>
                    <div class="paper-points">• Límites termodinámicos para coordinación
•  La coordinación requiere simplificación
•  Explica ciclado en optimización multi-objetivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23144" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📡 Acceso a Canal Distribuido Mejorado por IA para Evitar Colisiones en Wi-Fi 8</h3>
                    <p class="paper-summary">📝 Propone un framework de aprendizaje por refuerzo multi-agente para optimizar el acceso al canal en Wi-Fi futuro. Reduce significativamente la probabilidad de colisión comparado con BEB convencional mientras mantiene compatibilidad con dispositivos legacy y garantiza equidad.</p>
                    <div class="paper-points">• Aprendizaje por refuerzo para acceso al canal
•  Reduce colisiones en despliegues densos
•  Mantiene compatibilidad con dispositivos legacy</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23154" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Análisis de Límites para Tareas de Razonamiento Simbólico Multi-paso con Reglas de Propagación de Información Basadas en Transformers</h3>
                    <p class="paper-summary">📝 Analiza teóricamente el límite de pasos de razonamiento que los modelos Transformer pueden realizar en una sola pasada. Demuestra que el número máximo de pasos de razonamiento está entre O(3^(L-1)) y O(2^(L-1)) para modelos con L capas de atención.</p>
                    <div class="paper-points">• Reglas de propagación de información
•  Análisis de límites de razonamiento
•  Transformers para razonamiento simbólico
•  Complejidad computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23178" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Comprensión y Mejora de la Capacidad de Planificación de Modelos de Lenguaje mediante Predicción Multi-token</h3>
                    <p class="paper-summary">📝 Investiga cómo la predicción multi-token mejora el aprendizaje de relaciones transitivas en LLMs para planificación compleja. Propone estrategias que permiten capturar relaciones de alcanzabilidad transitiva más allá de los datos de entrenamiento directos.</p>
                    <div class="paper-points">• Predicción multi-token
•  Aprendizaje de relaciones transitivas
•  Planificación de rutas
•  Capa de transferencia
•  Blocksworld</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23186" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">AutoEP: Automatización de la Evolución de Hiperparámetros para Algoritmos Metaheurísticos Impulsada por LLMs</h3>
                    <p class="paper-summary">📝 Presenta AutoEP, un framework que utiliza LLMs como motores de razonamiento zero-shot para controlar hiperparámetros de algoritmos. Combina análisis de paisaje exploratorio en tiempo real con cadenas de razonamiento multi-LLM.</p>
                    <div class="paper-points">• Optimización de hiperparámetros
•  LLMs como controladores
•  Metaheurísticas
•  Análisis de paisaje exploratorio
•  Cero disparos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23189" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Muestreo sin p: Un Enfoque Robusto sin Hiperparámetros para Decodificación de LLMs</h3>
                    <p class="paper-summary">📝 Introduce un método de muestreo sin hiperparámetros que establece umbrales de truncamiento dinámicos basados en distribuciones completas de probabilidad de tokens. Mantiene alta calidad de salida incluso con temperaturas altas.</p>
                    <div class="paper-points">• Muestreo sin hiperparámetros
•  Decodificación de LLMs
•  Teoría de información
•  Eficiencia en inferencia
•  Calidad de texto</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23234" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Razonamiento de IA Agéntica para Inteligencia General en Edge Móvil: Fundamentos, Enfoques y Direcciones</h3>
                    <p class="paper-summary">📝 Propone un framework de optimización conjunta para implementar razonamiento de IA agéntica basada en LLMs en entornos edge con recursos limitados. Combina prompting CoT adaptativo con arquitectura MoE distribuida.</p>
                    <div class="paper-points">• Edge computing
•  IA agéntica
•  LLMs en dispositivos móviles
•  Mixture of Experts
•  Chain-of-Thought adaptativo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23248" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Entrenamiento de Modelos de Recompensa de Proceso Visión-Lenguaje para Escalado en Tiempo de Prueba en Razonamiento Multimodal</h3>
                    <p class="paper-summary">📝 Explora el diseño de modelos de recompensa de proceso para VLMs, introduciendo un framework híbrido de síntesis de datos y supervisión enfocada en percepción. Evalúa estrategias de escalado en tiempo de prueba.</p>
                    <div class="paper-points">• Modelos de recompensa de proceso
•  Razonamiento multimodal
•  VLMs
•  Escalado en tiempo de prueba
•  Supervisión de percepción</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23250" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">GUI-PRA: Agente de Recompensa de Proceso para Tareas de Interfaz Gráfica</h3>
                    <p class="paper-summary">📝 Presenta GUI-PRA, un agente juez que mejora la evaluación de recompensas de proceso en tareas de interfaz gráfica mediante mecanismos de memoria dinámica y percepción adaptativa de cambios en la UI.</p>
                    <div class="paper-points">• Agentes GUI
•  Modelos de recompensa de proceso
•  Interfaz gráfica
•  Memoria dinámica
•  Percepción de UI</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23263" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Modelo Socio-Económico de Agentes de IA</h3>
                    <p class="paper-summary">📝 Construye un framework de modelado basado en agentes heterogéneos que incluye trabajadores humanos y agentes de IA autónomos. Analiza el impacto de la colaboración con IA en la producción social agregada bajo restricciones de recursos.</p>
                    <div class="paper-points">• Modelado socio-económico
•  Agentes de IA
•  Efectos de red
•  Producción independiente
•  Output social agregado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23270" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia un Razonamiento Efectivo con Herramientas mediante Aprendizaje de Preferencias Auto-evolucionado</h3>
                    <p class="paper-summary">📝 Propone Tool-Light, un framework que incentiva a los LLMs a usar herramientas de manera eficiente y precisa mediante aprendizaje de preferencias auto-evolucionado y optimización directa de preferencias.</p>
                    <div class="paper-points">• Razonamiento con herramientas
•  Entropía de información
•  Aprendizaje de preferencias
•  Optimización DPO
•  Eficiencia en uso de herramientas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23285" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Aprendiendo Cómo Usar Herramientas, No Solo Cuándo: Razonamiento con Herramientas Consciente de Patrones</h3>
                    <p class="paper-summary">📝 Identifica patrones comunes en el uso de herramientas (calculadora y algorítmico) y propone un framework de dos etapas que mejora la selección y aplicación de patrones para razonamiento con herramientas.</p>
                    <div class="paper-points">• Patrones de uso de herramientas
•  Razonamiento con código
•  Alineación de patrones
•  Competencia en código
•  Razonamiento matemático</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23292" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Tus Modelos Han Pensado Suficiente: Entrenando Modelos de Razonamiento Grande para Dejar de Pensar en Exceso</h3>
                    <p class="paper-summary">📝 Propone JET, un método que entrena modelos de razonamiento grande para terminar proactivamente el razonamiento innecesario, reduciendo costos computacionales. Logra mejoras significativas en eficiencia sin sacrificar precisión, con reducciones de longitud de salida de hasta 46.3%.</p>
                    <div class="paper-points">• Reducción de costos computacionales
•  terminación proactiva de razonamiento
•  recompensas por longitud controlada por calidad
•  mejora de eficiencia sin pérdida de precisión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23392" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">De Conversación a Ejecución de Consultas: Evaluación de Interacciones de Usuarios y Herramientas para Agentes de Base de Datos de EHR</h3>
                    <p class="paper-summary">📝 Presenta EHR-ChatQA, un benchmark interactivo para evaluar agentes de bases de datos de registros médicos electrónicos. Aborda ambigüedad en consultas y discrepancias de valores entre terminología de usuarios y entradas de base de datos.</p>
                    <div class="paper-points">• Benchmark para EHR
•  flujos de refinamiento de consultas
•  evaluación de robustez en dominios críticos para la seguridad
•  identificación de modos de fallo comunes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23415" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Democratizando Científicos de IA usando ToolUniverse</h3>
                    <p class="paper-summary">📝 Presenta ToolUniverse, un ecosistema para construir científicos de IA que integra más de 600 modelos de ML, datasets y paquetes científicos. Permite crear herramientas desde descripciones en lenguaje natural y componer flujos de trabajo agenticos.</p>
                    <div class="paper-points">• Ecosistema unificado para IA científica
•  integración de herramientas múltiples
•  creación de herramientas desde lenguaje natural
•  estudio de caso en hipercolesterolemia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23426" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Más Allá de los Embeddings: Extracción Interpretable de Características para Similitud de Código Binario</h3>
                    <p class="paper-summary">📝 Propone un método que usa agentes basados en modelos de lenguaje para generar características interpretables de código assembly. Combina interpretabilidad con escalabilidad, logrando resultados comparables a métodos basados en embeddings.</p>
                    <div class="paper-points">• Características interpretables de código binario
•  análisis de razonamiento estructurado
•  combinación de interpretabilidad y escalabilidad
•  aplicaciones en análisis de malware</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23449" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🗺️ ViTSP: Un Marco Guiado por Modelos de Visión y Lenguaje para Problemas de Viajante a Gran Escala</h3>
                    <p class="paper-summary">📝 Propone ViTSP, un framework que utiliza modelos de visión y lenguaje pre-entrenados para resolver problemas del viajante a gran escala. Identifica subproblemas prometedores visualmente y los optimiza con solucionadores existentes.</p>
                    <div class="paper-points">• Resolución de TSP a gran escala
•  uso de VLMs pre-entrenados
•  identificación visual de subproblemas
•  brechas de optimalidad menores al 0.2%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23465" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌍 GeoBS: Cuantificación Teórico-Informacional del Sesgo Geográfico en Modelos de IA</h3>
                    <p class="paper-summary">📝 Establece un marco teórico-informacional para evaluar sesgos geográficos en modelos de IA. Propone tres nuevas métricas que consideran factores espaciales como multi-escalabilidad y decaimiento por distancia.</p>
                    <div class="paper-points">• Evaluación de sesgo geográfico
•  marco teórico-informacional
•  métricas espacialmente explícitas
•  análisis de modelos de IA y modelos fundacionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23482" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🎓 Predicciones Precisas en Educación con Inferencia Variacional Discreta</h3>
                    <p class="paper-summary">📝 Introduce un marco de modelado probabilístico para predicción de respuestas estudiantiles en exámenes de matemáticas. Logra más del 80% de precisión usando inferencia variacional discreta en entornos con pocos datos.</p>
                    <div class="paper-points">• Tutorías IA accesibles
•  dataset abierto de exámenes matemáticos
•  teoría de respuesta al ítem
•  inferencia variacional discreta
•  alta precisión predictiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23484" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Mapeo de Superposiciones en Benchmarks mediante Perplejidad en Contextos Reales</h3>
                    <p class="paper-summary">📝 Desarrolla firmas de capacidad para caracterizar benchmarks de LLMs y sus superposiciones significativas. Analiza 32 LLMs y 88 benchmarks, identificando dominios funcionales superpuestos y capacidades interconectadas.</p>
                    <div class="paper-points">• Firmas de capacidad de benchmarks
•  análisis de perplejidad
•  evaluación de superposiciones entre dominios
•  identificación de capacidades interconectadas en LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23488" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔧</span>
                    <h3 class="paper-title">Calibración Dinámica de Confianza Usando Bandits Contextuales</h3>
                    <p class="paper-summary">📝 Propone un método objetivo para calibración dinámica de confianza entre humanos e IA usando bandits contextuales. Demuestra mejoras del 10-38% en métricas de recompensa en toma de decisiones colaborativas.</p>
                    <div class="paper-points">• Calibración de confianza humano-IA
•  bandits contextuales
•  medida estandarizada de confianza
•  aplicaciones en dominios críticos como diagnóstico médico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23497" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Consistencia del Modelo como Proxy Económico pero Predictivo para Puntuaciones Elo de LLM</h3>
                    <p class="paper-summary">📝 Demuestra que la consistencia con la que un LLM selecciona un modelo como el mejor en comparaciones correlaciona en 91% con su puntuación Elo humana, proporcionando un proxy económico para evaluación de modelos.</p>
                    <div class="paper-points">• Evaluación económica de LLMs
•  proxy para puntuaciones Elo
•  consistencia en juicios de modelos
•  correlación del 91% con evaluaciones humanas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23510" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">DOoM: Olimpiadas Difíciles de Matemáticas</h3>
                    <p class="paper-summary">📝 Presenta DOoM, un benchmark de código abierto para evaluar modelos de lenguaje en problemas de matemáticas y física en ruso. Incluye problemas desde nivel escolar hasta olimpiadas universitarias. Muestra correlación entre rendimiento y tokens usados, con diferencias entre matemáticas y física.</p>
                    <div class="paper-points">• Benchmark en ruso
•  problemas de diversa dificultad
•  evaluación de modelos de lenguaje
•  correlación tokens-rendimiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23529" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Más Allá del Mejor LLM: Orquestación Multi-Agente vs LLMs Individuales</h3>
                    <p class="paper-summary">📝 Estudia orquestación multi-agente donde múltiples LLMs interactúan mediante propuestas y votos hasta consenso. Supera consistentemente a modelos individuales, mostrando que revelar autoría aumenta auto-voto y mostrar votos en curso amplifica efecto rebaño.</p>
                    <div class="paper-points">• Orquestación multi-agente
•  consenso por votación
•  supera modelos individuales
•  análisis efectos sociales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23537" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Jailbreaking de Prompts LLM mediante Formalización y Reinforcement Learning</h3>
                    <p class="paper-summary">📝 Propone PASS, framework que usa reinforcement learning para transformar prompts de jailbreak en descripciones formalizadas, mejorando sigilo y evadiendo defensas. Emplea GraphRAG para fortalecer ataques posteriores con contexto estructural.</p>
                    <div class="paper-points">• Ataques jailbreak
•  reinforcement learning
•  formalización semántica
•  GraphRAG
•  evasión de defensas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23558" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Modelo de Recomendación Personalizada para Fórmulas de Medicina China con Guía de Difusión KG</h3>
                    <p class="paper-summary">📝 Propone TCM-HEDPR, modelo que aborda limitaciones en recomendación de medicina china integrando información personalizada, mitigando distribución long-tailed y considerando compatibilidad hierbas. Usa aprendizaje contrastivo y difusión en grafos de conocimiento.</p>
                    <div class="paper-points">• Medicina china tradicional
•  recomendación personalizada
•  grafos de conocimiento
•  distribución long-tailed</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23560" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Limpiar Primero, Alinear Después: Benchmark de Limpieza de Datos para Alineación Confiable de LLMs</h3>
                    <p class="paper-summary">📝 Introduce PrefCleanBench, primer benchmark exhaustivo para evaluar 13 métodos de limpieza de datos de preferencia en alineación de LLMs. Evalúa efectividad y generalización across datasets, arquitecturas y algoritmos de optimización.</p>
                    <div class="paper-points">• Benchmark limpieza datos
•  alineación LLMs
•  calidad datos
•  métodos comparativos
•  desarrollo IA responsable</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23564" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚗 BridgeDrive: Política de Difusión Bridge para Planificación de Trayectorias en Conducción Autónoma</h3>
                    <p class="paper-summary">📝 Presenta BridgeDrive, política de difusión bridge para planificación de trayectorias en conducción autónoma que traduce anclas de comportamiento experto en planes detallados. Logra state-of-the-art en Bench2Drive con 5% mejora en tasa de éxito.</p>
                    <div class="paper-points">• Conducción autónoma
•  modelos de difusión
•  planificación trayectorias
•  tiempo real
•  benchmark Bench2Drive</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23589" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">PSG-Agent: Barrera de Seguridad Consciente de la Personalidad para Agentes basados en LLM</h3>
                    <p class="paper-summary">📝 Propone PSG-Agent, sistema personalizado y dinámico que crea barreras de seguridad específicas por usuario monitoreando historial de interacción y estados en tiempo real. Implementa monitores especializados y supera existing guardrails.</p>
                    <div class="paper-points">• Seguridad agentes LLM
•  personalización
•  monitoreo continuo
•  perfiles usuario
•  aplicaciones críticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23614" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Andamiaje de Razonamiento: Destilando el Flujo de Pensamiento de LLMs</h3>
                    <p class="paper-summary">📝 Introduce Reasoning Scaffolding, framework que reframea el razonamiento como proceso estructurado, abstrayendo el pensamiento en señales semánticas discretas. Entrena modelos pequeños con objetivo multi-tarea para predecir señales y generar pasos correspondientes.</p>
                    <div class="paper-points">• Destilación razonamiento
•  modelos pequeños
•  señales semánticas
•  estructura algorítmica
•  regularización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23619" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Cómo los LLMs Aprenden a Razonar: Perspectiva de Redes Complejas</h3>
                    <p class="paper-summary">📝 Propone teoría unificadora donde el razonamiento en RLVR mapea a auto-organización de red compleja semántica con topología sparse. Explica curva aprendizaje en dos etapas y olvido catastrófico, leading a algoritmo Annealed-RLVR que mejora capacidad de razonamiento.</p>
                    <div class="paper-points">• Teoría redes complejas
•  RLVR
•  auto-organización
•  olvido catastrófico
•  transiciones de fase</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23629" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎮</span>
                    <h3 class="paper-title">Corrección de Errores ASR Orientada a Juegos mediante LLM Mejorado con RAG</h3>
                    <p class="paper-summary">📝 Presenta GO-AEC, framework que integra LLMs, RAG y aumento de datos para corregir errores ASR en juegos. Reduce error de caracteres 6.22% y error de oraciones 29.71%, mejorando precisión en comunicación por voz en gaming.</p>
                    <div class="paper-points">• ASR gaming
•  RAG
•  aumento datos
•  comunicación voz
•  jerga gaming
•  corrección errores</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23630" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Del Razonamiento a la Respuesta: Perspectivas Empíricas, Basadas en Atención y Mecanicistas en Modelos Destilados DeepSeek R1</h3>
                    <p class="paper-summary">📝 Investiga cómo los modelos de razonamiento grande generan trazas de razonamiento explícitas junto con respuestas finales. Demuestra que el razonamiento explícito mejora la calidad de las respuestas y revela mediante análisis de atención que los tokens de respuesta atienden significativamente a los tokens de razonamiento.</p>
                    <div class="paper-points">• Mejora consistente con razonamiento explícito
•  cabezas de atención focalizadas en razonamiento
•  flujo direccional de información confirmado mediante intervenciones mecanicistas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23676" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">SafeSearch: Red-Teaming Automatizado para la Seguridad de Agentes de Búsqueda Basados en LLM</h3>
                    <p class="paper-summary">📝 Presenta un marco de red-teaming automatizado para evaluar la seguridad de agentes de búsqueda conectados a LLMs. Construye el benchmark SafeSearch con 300 casos de prueba cubriendo cinco categorías de riesgos como desinformación e inyección indirecta de prompts.</p>
                    <div class="paper-points">• Vulnerabilidades significativas en agentes de búsqueda (90.5% ASR)
•  efectividad limitada de defensas comunes
•  marco sistemático y escalable para evaluación de seguridad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23694" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Medición de la Sensibilidad de Características de Autoencoders Dispersos</h3>
                    <p class="paper-summary">📝 Desarrolla un método escalable para evaluar la sensibilidad de características en autoencoders dispersos (SAE). La sensibilidad mide qué tan confiablemente se activa una característica en textos similares a sus ejemplos activadores, revelando una nueva dimensión de calidad.</p>
                    <div class="paper-points">• Método sin descripciones en lenguaje natural
•  muchas características interpretables tienen baja sensibilidad
•  sensibilidad promedio disminuye con mayor ancho de SAE</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23717" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">MedLA: Un Marco Multi-Agente Dirigido por Lógica para Razonamiento Médico Complejo con LLMs</h3>
                    <p class="paper-summary">📝 Propone MedLA, un marco multi-agente basado en lógica para razonamiento médico complejo. Los agentes organizan su razonamiento en árboles lógicos explícitos basados en tríadas silogísticas y participan en discusiones guiadas por grafos para refinar lógicamente.</p>
                    <div class="paper-points">• Árboles lógicos explícitos
•  debate multi-ronda guiado por grafos
•  supera sistemas basados en roles estáticos
•  escalable across backbones de LLM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23725" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">EAPO: Mejorando la Optimización de Políticas con Asistencia Experta Bajo Demanda</h3>
                    <p class="paper-summary">📝 Presenta EAPO, un marco de RL que mejora la exploración incorporando interacciones multi-turno con expertos externos durante el entrenamiento. El modelo aprende cuándo y cómo consultar expertos, internalizando eventualmente el conocimiento experto.</p>
                    <div class="paper-points">• Consulta adaptativa a expertos
•  señales de recompensa más ricas
•  ganancia promedio de 5 puntos sobre modelos auto-exploratorios
•  evaluación independiente sin expertos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23730" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Diagnóstico de Causas Raíz de Fallas en Sistemas Agénticos Orquestados por Plataformas: Dataset, Taxonomía y Benchmark</h3>
                    <p class="paper-summary">📝 Presenta AgentFail, un dataset de 307 logs de fallas con anotaciones de causas raíz para sistemas agénticos orquestados por plataformas. Desarrolla una taxonomía de causas de falla y un benchmark para identificación automática usando LLMs.</p>
                    <div class="paper-points">• Dataset con anotaciones fiables
•  taxonomía que mejora rendimiento de LLMs
•  precisión máxima de 33.6% indica tarea desafiante
•  guías accionables para desarrollo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23735" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">GUI-Shepherd: Recompensa de Proceso Confiable y Verificación para Tareas GUI de Secuencia Larga</h3>
                    <p class="paper-summary">📝 Introduce GUI-Shepherd, un Modelo de Recompensa de Proceso que proporciona retroalimentación densa paso a paso para guiar agentes en tareas GUI. Entrenado en 5252k interacciones, sirve como proveedor de recompensa y verificador de inferencia.</p>
                    <div class="paper-points">• Mejora tasa de éxito en 7.7 puntos
•  supera modelos de recompensa basados en resultado
•  beneficios generalizables a benchmarks offline
•  supervisión de proceso crítica para agentes GUI</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23738" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Razonamiento Visual Transparente mediante Colaboración Agéntica Centrada en Objetos</h3>
                    <p class="paper-summary">📝 Presenta OCEAN, un marco interpretable basado en representaciones centradas en objetos y procesos de razonamiento multi-agente transparentes. El proceso de razonamiento game-theoretic lleva a los agentes a acordar evidencia coherente y discriminativa.</p>
                    <div class="paper-points">• Explicaciones fundamentadas en conceptos humanos
•  rendimiento competitivo con modelos black-box
•  explicaciones calificadas como más intuitivas y confiables en estudio de usuarios</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23757" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">De Qué a Por Qué: Un Sistema Multi-Agente para Razonamiento de Condiciones de Reacción Química Basado en Evidencia</h3>
                    <p class="paper-summary">📝 Propone ChemMAS, un sistema multi-agente que reformula la predicción de condiciones de reacción química como tarea de razonamiento basado en evidencia. Cada decisión está respaldada por justificaciones interpretables fundamentadas en conocimiento químico.</p>
                    <div class="paper-points">• Ganancias de 20-35% sobre baselines específicos de dominio
•  supera LLMs de propósito general en 10-15%
•  racionales falsificables y confiables para humanos
•  paradigma para IA explicable en ciencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23768" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Falcon: Un Dataset de Evaluación Cross-Modal para Percepción Integral de Seguridad</h3>
                    <p class="paper-summary">📝 Introduce Falcon, un dataset de seguridad visión-lenguaje a gran escala con 57,515 pares VQA across 13 categorías de daño. Proporciona anotaciones explícitas para atributos dañinos en imágenes, instrucciones y respuestas.</p>
                    <div class="paper-points">• Dataset comprehensivo con explicaciones de juicios
•  FalconEye supera todos los baselines en precisión
•  herramienta práctica para auditoría de seguridad en MLLMs
•  considera rol crucial de información visual</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23783" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">De la Frustración a la Diversión: Un Juego de Rompecabezas de Resolución de Problemas Adaptativo Impulsado por Algoritmo Genético</h3>
                    <p class="paper-summary">📝 Juego de rompecabezas adaptativo que genera niveles dinámicamente usando algoritmos genéticos para ajustar la dificultad según el jugador. El sistema modela al usuario en tiempo real para mantener el compromiso y evitar frustración. Estudio piludo valida la efectividad del enfoque adaptativo.</p>
                    <div class="paper-points">• Algoritmos genéticos para generación procedural
•  ajuste de dificultad en tiempo real
•  modelado de jugador
•  mantenimiento del compromiso</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23796" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">AnveshanaAI: Una Plataforma Multimodal para Educación Adaptativa en IA/ML mediante Generación Automática de Preguntas y Evaluación Interactiva</h3>
                    <p class="paper-summary">📝 Plataforma de aprendizaje gamificada para educación en IA que ofrece dashboards personalizados y evaluación adaptativa. Combina taxonomía de Bloom con verificaciones de similitud semántica y técnicas de IA explicable. Experimentos muestran mayor compromiso y cobertura amplia del dataset.</p>
                    <div class="paper-points">• Educación gamificada en IA
•  evaluación adaptativa automática
•  taxonomía de Bloom
•  IA explicable
•  aprendizaje personalizado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23811" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Mix-Ecom: Hacia Diálogos de Comercio Electrónico de Tipo Mixto con Reglas de Dominio Complejas</h3>
                    <p class="paper-summary">📝 Corpus innovador basado en diálogos reales de servicio al cliente que combina múltiples tipos de diálogo en conversaciones de e-commerce. Cubre 4 tipos de diálogo, 3 tipos de tareas y 82 reglas específicas del dominio. Revela limitaciones actuales de los agentes ante reglas complejas.</p>
                    <div class="paper-points">• Dataset de diálogos mixtos reales
•  múltiples tipos de conversación
•  reglas complejas de dominio
•  evaluación de agentes de IA</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23836" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">AgentGuard: Verificación en Tiempo de Ejecución de Agentes de IA</h3>
                    <p class="paper-summary">📝 Framework para verificación continua de sistemas de IA agenticos que proporciona garantías probabilísticas en tiempo real. Convierte E/S del agente en eventos formales y construye dinámicamente un MDP para modelar comportamiento emergente. Usa verificación de modelos probabilísticos.</p>
                    <div class="paper-points">• Verificación en tiempo de ejecución
•  garantías probabilísticas
•  modelado MDP dinámico
•  comportamiento emergente
•  seguridad de agentes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23864" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Repensando el Descalibrado de Recompensas de GRPO en RL Agéntico</h3>
                    <p class="paper-summary">📝 Analiza el problema del acoplamiento de gradientes en RL agéntico donde muestras similares interfieren entre sí. Demuestra que las recompensas basadas en resultado castigan acciones defectuosas. Propone entrenar al actor para clasificar acciones buenas/malas separando sus embeddings.</p>
                    <div class="paper-points">• Acoplamiento de gradientes
•  recompensas basadas en resultado
•  RL agéntico
•  separación de embeddings
•  clasificación de acciones</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23870" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Fiebre Cuántica, Agujeros Negros de Razonamiento, Cumplimiento de Schrödinger y Más: Analizando GPT-OSS-20B</h3>
                    <p class="paper-summary">📝 Evaluación de seguridad exhaustiva del modelo GPT-OSS-20B que identifica varios modos de fallo mediante jailbreaks sistemáticos. Descubre comportamientos como fiebre cuántica, agujeros negros de razonamiento y cumplimiento de Schrödinger que pueden ser explotados adversariamente.</p>
                    <div class="paper-points">• Evaluación de seguridad
•  jailbreaks de LLM
•  modos de fallo
•  razonamiento en cadena
•  vulnerabilidades de modelos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23882" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">De Redes Neuronales a Teorías Lógicas: La Correspondencia entre Lógicas Modales de Fibrado y Redes Neuronales de Fibrado</h3>
                    <p class="paper-summary">📝 Establece formalmente la correspondencia entre el fibrado de lógicas modales y el fibrado de redes neuronales. Deriva resultados de expresividad lógica para GNNs, GATs y Transformers. Abre camino para interpretar teorías lógicas aprendidas por redes neuronales.</p>
                    <div class="paper-points">• Neuro-simbólico
•  fibrado de lógicas
•  expresividad lógica
•  GNNs
•  Transformers
•  correspondencia formal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23912" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Estimación de Ventaja Condicional para Aprendizaje por Refuerzo en Modelos de Razonamiento Grande</h3>
                    <p class="paper-summary">📝 Introduce CANON, método que amplifica el impacto de métricas objetivo sin presumir su dirección. Regrupa respuestas basándose en métricas como entropía o longitud y compara entre grupos. Mejora rendimiento en razonamiento matemático y lógico con mayor eficiencia.</p>
                    <div class="paper-points">• RL para LLMs
•  estimación de ventaja condicional
•  razonamiento matemático
•  eficiencia de tokens
•  métricas no direccionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23962" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Selección Automática de Estudios Primarios en Revisiones Sistemáticas con Clasificación Evolutiva Basada en Reglas</h3>
                    <p class="paper-summary">📝 Propone enfoque de aprendizaje evolutivo para selección automática de papers relevantes en revisiones sistemáticas. Usa programación genética guiada por gramática para generar clasificadores interpretables que combinan información textual con datos bibliométricos.</p>
                    <div class="paper-points">• Revisiones sistemáticas automatizadas
•  programación genética
•  clasificadores interpretables
•  combinación de fuentes de información</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23981" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">TusoAI: Optimización Agéntica para Métodos Científicos</h3>
                    <p class="paper-summary">📝 Sistema AI agéntico que desarrolla y optimiza métodos computacionales para tareas científicas específicas. Integra conocimiento de dominio en árboles de conocimiento y realiza optimización iterativa. Supera métodos expertos en tareas como RNA-seq y monitoreo terrestre.</p>
                    <div class="paper-points">• Descubrimiento científico automatizado
•  optimización de métodos
•  árboles de conocimiento
•  diagnóstico de modelos
•  aplicaciones genéticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23986" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">LLM/Agente-como-Analista-de-Datos: Una Revisión</h3>
                    <p class="paper-summary">📝 Revisa técnicas de modelos de lenguaje grande y agentes para análisis de datos, comparándolas con enfoques tradicionales. Identifica cinco objetivos de diseño clave y analiza aplicaciones en datos estructurados, semiestructurados y no estructurados.</p>
                    <div class="paper-points">• Agentes de análisis de datos inteligentes
•  integración multimodal
•  pipelines autónomos
•  flujos de trabajo aumentados con herramientas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23988" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👨‍🏫 Preparación de Programadores para el Futuro: Seguimiento Óptimo del Conocimiento para Educación Personalizada Asistida por IA</h3>
                    <p class="paper-summary">📝 Presenta CoTutor, un modelo impulsado por IA que mejora el Seguimiento Bayesiano del Conocimiento con técnicas de procesamiento de señales. Combina IA generativa con tecnología de aprendizaje adaptativo para proporcionar retroalimentación personalizada.</p>
                    <div class="paper-points">• Modelo CoTutor
•  aprendizaje adaptativo
•  mejora de resultados educativos
•  copiloto de IA</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23996" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">¿Importan las Repeticiones? Fortaleciendo la Confiabilidad en Evaluaciones de LLM</h3>
                    <p class="paper-summary">📝 Investiga cuántas repeticiones se necesitan para evaluaciones confiables de LLM, encontrando que las clasificaciones de una sola ejecución son frágiles. Recomienda ≥2 repeticiones bajo decodificación estocástica para mejorar la robustez.</p>
                    <div class="paper-points">• Evaluación de modelos
•  confiabilidad
•  clasificaciones
•  múltiples ejecuciones
•  incertidumbre</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24086" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Fathom-DeepResearch: Desbloqueando la Recuperación y Síntesis de Información de Largo Horizonte para SLMs</h3>
                    <p class="paper-summary">📝 Introduce un sistema agéntico compuesto por dos modelos especializados: Fathom-Search-4B para investigación basada en evidencia y Fathom-Synthesizer-4B para síntesis de informes. Logra rendimiento de vanguardia en tareas de razonamiento complejas.</p>
                    <div class="paper-points">• Agentes de investigación profunda
•  recuperación de información
•  síntesis
•  herramientas de búsqueda web</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24107" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Agentes de Datos Transparentes, Evaluables y Accesibles: Un Marco de Prueba de Concepto</h3>
                    <p class="paper-summary">📝 Presenta una arquitectura modular para desarrollar agentes de IA que conectan interfaces de lenguaje natural con almacenes de datos empresariales. Enfocado en transparencia, interpretabilidad y evaluación automática de calidad.</p>
                    <div class="paper-points">• Transparencia
•  interpretabilidad
•  evaluación automática
•  warehouses de datos
•  justificaciones auditables</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24127" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🤔 ¿Razonamiento o Recuperación? Un Estudio de Atribución de Respuestas en Modelos de Razonamiento Grande</h3>
                    <p class="paper-summary">📝 Investiga cómo los LRM generan respuestas mediante razonamiento Chain-of-Thought o recuperación de memoria. Introduce FARL, un marco que suprime los atajos de recuperación para promover comportamientos dominados por el razonamiento.</p>
                    <div class="paper-points">• Razonamiento vs recuperación
•  inconsistencia en CoT
•  marco FARL
•  capacidades de razonamiento generalizables</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24156" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ Optimización Robusta de Preferencias: Alineando Modelos de Lenguaje con Retroalimentación de Preferencias Ruidosas</h3>
                    <p class="paper-summary">📝 Introduce RPO, un meta-marco que mitiga el ruido en datos de preferencias humanas usando EM para inferir probabilidades posteriores de corrección de etiquetas. Mejora algoritmos de alineación existentes como DPO, IPO, SimPO y CPO.</p>
                    <div class="paper-points">• Alineación robusta
•  preferencias humanas
•  ruido en datos
•  marco RPO
•  algoritmo EM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24159" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👥 Humanline: Alineación Online como Pérdida Perceptual</h3>
                    <p class="paper-summary">📝 Propone que la alineación online aproxima mejor la distribución percibida por humanos. Introduce variantes &#x27;humanline&#x27; que incorporan distorsiones perceptuales de probabilidad, igualando el rendimiento de métodos online con datos offline.</p>
                    <div class="paper-points">• Alineación online vs offline
•  teoría prospectiva
•  sesgos perceptuales
•  variantes humanline</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24207" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤝</span>
                    <h3 class="paper-title">ELHPlan: Planificación Eficiente de Tareas de Largo Horizonte para Colaboración Multi-Agente</h3>
                    <p class="paper-summary">📝 Presenta un framework que utiliza Cadenas de Acción como primitivas de planificación para colaboración multi-agente. Logra tasas de éxito comparables consumiendo solo 24% de los tokens de métodos state-of-the-art.</p>
                    <div class="paper-points">• Planificación multi-agente
•  eficiencia computacional
•  cadenas de acción
•  validación proactiva</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24230" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">💭 Aprendiendo a Reflexionar: Razonamiento Adaptativo en Espacio Latente</h3>
                    <p class="paper-summary">📝 Introduce FR-Ponder, un framework que asigna computación de razonamiento adaptativa mediante direccionamiento latente. Permite a los modelos adaptar su profundidad de razonamiento a la complejidad de cada entrada sin modificar pesos base.</p>
                    <div class="paper-points">• Razonamiento adaptativo
•  computación en tiempo de prueba
•  direccionamiento latente
•  optimización GRPO</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24238" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Leyes de Escalado en Fusión de Modelos para Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Identifica una ley de potencia compacta que predice el rendimiento al fusionar modelos de lenguaje. La ley explica cómo disminuyen los retornos al añadir más expertos y permite planificar eficientemente la composición de modelos especializados como alternativa al entrenamiento multitarea.</p>
                    <div class="paper-points">• Ley de escalado predictiva
•  Fusión de modelos especializados
•  Eficiencia computacional
•  Alternativa a entrenamiento multitarea</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24244" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">SpecExit: Aceleración de Modelos de Razonamiento mediante Salida Especulativa</h3>
                    <p class="paper-summary">📝 Propone SpecExit, un framework que predice tokens futuros y señales de salida temprana desde un modelo ligero, reduciendo la longitud de generación en 66% y logrando 2.5x de aceleración sin comprometer la precisión en modelos de razonamiento.</p>
                    <div class="paper-points">• Reducción de sobrepensamiento
•  Aceleración de latencia
•  Salida temprana especulativa
•  Sin overhead de detección</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24248" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Síntesis de Programas Interactivos para Modelar Actividades Físicas Colaborativas</h3>
                    <p class="paper-summary">📝 Enmarca el aprendizaje de tareas colaborativas como un problema de síntesis de programas, usando demostraciones narradas para enseñar, inspeccionar y corregir la lógica del sistema sin requerir que los usuarios vean o escriban código.</p>
                    <div class="paper-points">• Programas editables
•  Enseñanza multimodal
•  Actividades colaborativas
•  Interfaz interpretable</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24250" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Repensando y Evaluando Modelos de Lenguaje para Razonamiento en Grafos</h3>
                    <p class="paper-summary">📝 Critica benchmarks existentes y propone GraphAlgorithm, un benchmark más desafiante con 239 problemas. Introduce Simple-RTC, un baseline que guía a los LLMs a diseñar algoritmos primero y luego codificar, logrando precisión casi perfecta.</p>
                    <div class="paper-points">• Benchmark GraphAlgorithm
•  Baseline Simple-RTC
•  Diseño de algoritmos
•  Evaluación rigurosa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24260" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">RL Sensible al Riesgo para Aliviar Dilemas de Exploración en LLMs</h3>
                    <p class="paper-summary">📝 Introduce RS-GRPO, un algoritmo de aprendizaje por refuerzo sensible al riesgo que mejora la diversidad de soluciones (pass@k) manteniendo la precisión de solución única (pass@1), superando limitaciones de exploración en LLMs pre-entrenados.</p>
                    <div class="paper-points">• Exploración profunda
•  Diversidad de soluciones
•  Objetivo risk-seeking
•  Mejora pass@k</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24261" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">PAME-AI: Creación y Optimización de Mensajes a Pacientes usando IA Agéntica</h3>
                    <p class="paper-summary">📝 Desarrolla un sistema de agentes IA especializados que transforma datos experimentales en estrategias de mensajería efectiva, logrando 68.76% de engagement vs 61.27% baseline en 444,691 encuentros con pacientes.</p>
                    <div class="paper-points">• Arquitectura agéntica
•  Optimización de mensajes
•  Jerarquía DIKW
•  Mejora engagement 12.2%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24263" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">AdvChain: Sintonización Adversarial de Cadena de Pensamiento para Alineación Segura</h3>
                    <p class="paper-summary">📝 Propone AdvChain, un paradigma de alineación que enseña a los modelos a autocorregirse mediante sintonización adversarial de CoT, mejorando robustez contra jailbreaks y reduciendo sobre-rechazo en prompts benignos.</p>
                    <div class="paper-points">• Autocorrección dinámica
•  Robustez seguridad
•  Balance seguridad-utilidad
•  Mitigación efecto bola de nieve</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24269" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">G-reasoner: Modelos Fundacionales para Razonamiento Unificado sobre Conocimiento en Grafos</h3>
                    <p class="paper-summary">📝 Presenta un framework unificado que integra modelos de grafos y lenguaje para razonamiento sobre conocimiento estructurado, con QuadGraph como abstracción estandarizada y un modelo fundacional de grafos de 34M parámetros.</p>
                    <div class="paper-points">• Abstracción QuadGraph
•  Modelo fundacional de grafos
•  Razonamiento unificado
•  Escalabilidad distribuida</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24276" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">SCI-Verifier: Verificador Científico con Razonamiento</h3>
                    <p class="paper-summary">📝 Introduce SCI-VerifyBench, un benchmark multidisciplinario, y SCI-Verifier, un verificador aumentado con razonamiento para dominios científicos que demuestra fuertes capacidades de juicio de equivalencia y razonamiento lógico.</p>
                    <div class="paper-points">• Benchmark multidisciplinario
•  Verificación con razonamiento
•  Juicio de equivalencia
•  Evaluación sistemática</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24285" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚚 Documento de Experiencia: Adopción de Reconocimiento de Actividad en Entrega de Comida</h3>
                    <p class="paper-summary">📝 Describe el primer despliegue nacional de reconocimiento de actividad humana en entrega de comida, adaptando LIMU-BERT e involucrando 500,000 repartidores en 367 ciudades de China, mostrando beneficios operativos y económicos significativos.</p>
                    <div class="paper-points">• Despliegue a gran escala
•  Modelo LIMU-BERT
•  500
• 000 repartidores
•  Beneficios operativos demostrados</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24303" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">MedMMV: Un Marco Multimodal Multi-Agente Controlable para Razonamiento Clínico Confiable y Verificable</h3>
                    <p class="paper-summary">📝 Marco multi-agente que estabiliza el razonamiento clínico mediante rollouts diversificados, detecta alucinaciones y utiliza un puntuador de incertidumbre combinado. Mejora la precisión diagnóstica hasta 12.7% y aumenta la veracidad del razonamiento según evaluaciones médicas ciegas.</p>
                    <div class="paper-points">• Controla la inestabilidad en interpretación de evidencia médica
•  detector de alucinaciones
•  gráfico de evidencia estructurado
•  evaluación por médicos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24314" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">humancompatible.detect: Un Kit de Herramientas Python para Detectar Sesgo en Modelos de IA</h3>
                    <p class="paper-summary">📝 Toolkit que aborda desafíos de escalabilidad y computabilidad en detección de sesgos mediante discrepancia máxima de subgrupo y distancias muestreadas. Cumple con regulaciones como el AI Act para sistemas de IA de alto riesgo.</p>
                    <div class="paper-points">• Detección de sesgos en IA
•  métodos MSD y distancias ℓ∞
•  API fácil de usar
•  compatible con regulaciones europeas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24340" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧮</span>
                    <h3 class="paper-title">De Estático a Dinámico: Búsqueda Monte Carlo Adaptativa para Supervisión de Procesos Matemáticos</h3>
                    <p class="paper-summary">📝 Marco AMCS que transforma la generación de datos de búsqueda estática a adaptativa, asignando más muestras a pasos inciertos y mejorando la expansión de rutas. Logra 76.2% de precisión en MATH500 y supera modelos más grandes.</p>
                    <div class="paper-points">• Búsqueda Monte Carlo adaptativa
•  dataset MathSearch-200K
•  modelos PRM
•  generalización en problemas fuera de distribución</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24351" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Planificar antes de Resolver: Enrutamiento de Estrategia Consciente del Problema para Razonamiento Matemático con LLMs</h3>
                    <p class="paper-summary">📝 Framework PRISM que desacopla el razonamiento matemático en planificación de estrategia y ejecución dirigida. Usa un Adaptador de Estrategia liviano y enrutamiento adaptativo que mejora resultados entre 0.9%-7.6% en cinco benchmarks.</p>
                    <div class="paper-points">• Dataset MathStrat
•  enrutamiento adaptativo
•  múltiples estrategias de razonamiento
•  verificación dual-estrategia
•  ejecución multi-estrategia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24377" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Hacia un Razonamiento Seguro en Modelos de Razonamiento Grande mediante Intervención Correctiva</h3>
                    <p class="paper-summary">📝 Método IPO que alinea la seguridad del razonamiento sustituyendo pasos de cumplimiento con desencadenantes de seguridad. Reduce la nocividad en más del 30% manteniendo el rendimiento en tareas de razonamiento diversas.</p>
                    <div class="paper-points">• Optimización de preferencia intervenida
•  alineación de razonamiento
•  supervisión de procesos
•  desencadenantes de seguridad
•  reducción de contenido dañino</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24393" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏭</span>
                    <h3 class="paper-title">Revisión Sistemática de Mantenimiento Predictivo con Gemelos Digitales en Ingeniería Industrial: Taxonomía y Direcciones Futuras</h3>
                    <p class="paper-summary">📝 Análisis retrospectivo de la evolución de gemelos digitales en mantenimiento predictivo industrial. Proporciona arquitectura por capas, taxonomía de aplicaciones y algoritmos de IA para ecosistemas industriales confiables.</p>
                    <div class="paper-points">• Gemelos digitales
•  mantenimiento predictivo
•  arquitectura por capas
•  taxonomía de aplicaciones
•  IoT y análisis en tiempo real</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24443" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 ContextPRM: Aprovechando la Coherencia Contextual para Escalado Multi-dominio en Tiempo de Prueba</h3>
                    <p class="paper-summary">📝 Modelo que cambia el objetivo de aprendizaje de verificar conocimiento específico de dominio a modelar flujo lógico independiente del dominio. Mejora 6.5% en precisión promedio en dominios no matemáticos como derecho e historia.</p>
                    <div class="paper-points">• Coherencia contextual
•  generalización multi-dominio
•  votación mayoritaria ponderada
•  mejora en MMLU-Pro
•  flujo lógico agnóstico al dominio</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24460" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Superando el Sobreajuste en Adquisición de Restricciones mediante Refinamiento Interactivo Guiado por Consultas</h3>
                    <p class="paper-summary">📝 Marco híbrido que combina aprendizaje pasivo con refinamiento interactivo guiado por consultas para abordar el sobreajuste en adquisición de restricciones. Logra alta cobertura del modelo objetivo con complejidad de consulta manejable.</p>
                    <div class="paper-points">• Adquisición de restricciones
•  refinamiento interactivo
•  puntuaciones de confianza probabilísticas
•  exploración de subconjuntos
•  aprendizaje activo final</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24489" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Red Neuroplástica Dinámica para Pronóstico de Demanda Multi-tarea</h3>
                    <p class="paper-summary">📝 NMT-Net permite adaptabilidad estructural del grafo computacional durante el entrenamiento, inspirada en neuroplasticidad biológica. Logra menor RMSE y desviación estándar en pronósticos de demanda multi-tarea.</p>
                    <div class="paper-points">• Redes neuronales dinámicas
•  neuroplasticidad artificial
•  identificación de tareas por similitud
•  cabezales ANN selectivos
•  aprendizaje continuo en series de tiempo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24495" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Co-evolución reflexiva guiada por experiencia de prompts y heurísticas para diseño automático de algoritmos</h3>
                    <p class="paper-summary">📝 Propone EvoPH, un marco que co-evoluciona prompts y algoritmos heurísticos usando modelos de lenguaje grandes para diseñar automáticamente algoritmos de optimización combinatoria. Combina el modelo de migración de islas con selección de élites para evitar óptimos locales. Evalúa en problemas del Viajante y Empaquetamiento de Bin, logrando el menor error relativo.</p>
                    <div class="paper-points">• Co-evolución de prompts y heurísticas
•  Framework EvoPH
•  Aplicación en problemas de optimización combinatoria
•  Superación de estancamiento en óptimos locales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24509" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Entrenando agentes dentro de modelos mundiales escalables</h3>
                    <p class="paper-summary">📝 Presenta Dreamer 4, un agente que aprende resolviendo tareas mediante aprendizaje por refuerzo dentro de un modelo mundial preciso y rápido. En Minecraft, predice interacciones de objetos con alta precisión y es el primer agente en obtener diamantes usando solo datos offline, sin interacción con el entorno.</p>
                    <div class="paper-points">• Modelos mundiales escalables
•  Aprendizaje por refuerzo en imaginación
•  Aplicación en Minecraft
•  Entrenamiento completamente offline</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24527" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Asistente BPMN: Un enfoque basado en LLM para modelado de procesos de negocio</h3>
                    <p class="paper-summary">📝 Introduce BPMN Assistant, una herramienta que utiliza LLMs para crear y editar diagramas BPMN mediante lenguaje natural. Emplea una representación JSON especializada que ofrece mayor confiabilidad y tasas de éxito más altas en edición compared to XML tradicional.</p>
                    <div class="paper-points">• Generación de diagramas BPMN con LLM
•  Representación JSON vs XML
•  Evaluación con Graph Edit Distance
•  Mayor confiabilidad en modificaciones</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24592" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Bolt: Aprendizaje rápido de fórmulas en Lógica Temporal Lineal</h3>
                    <p class="paper-summary">📝 Presenta Bolt, una herramienta que aprende fórmulas LTLf de trazas finitas más de 100x más rápido que el estado del arte en 70% de los benchmarks. Su clave es aprovechar el problema Boolean Set Cover para combinar fórmulas existentes usando conectivos booleanos.</p>
                    <div class="paper-points">• Aprendizaje acelerado de LTLf
•  Boolean Set Cover como subrutina
•  Fórmulas más pequeñas o iguales en 98% de casos
•  Mejor equilibrio eficiencia-tamaño</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24616" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">&#x27;¡Deja de reemplazar sal con azúcar!&#x27;: Hacia la enseñanza intuitiva humano-agente</h3>
                    <p class="paper-summary">📝 Propone una arquitectura de enseñanza intuitiva donde humanos pueden enseñar tareas subjetivas a agentes mediante demostraciones. El agente aprende incrementalmente de pocos ejemplos usando conocimiento de dominio externo y selección estratégica de ejemplos representativos.</p>
                    <div class="paper-points">• Enseñanza intuitiva humano-agente
•  Aprendizaje incremental de tareas subjetivas
•  Sustitución de ingredientes en recetas
•  Eficiencia con pocos ejemplos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24651" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤝</span>
                    <h3 class="paper-title">Malentendidos exitosos: Aprendiendo a coordinar sin ser comprendido</h3>
                    <p class="paper-summary">📝 Investiga cómo agentes pueden coordinar exitosamente desarrollando vocabularios de señales sin entendimiento mutuo. Los agentes convergen a &#x27;malentendidos exitosos&#x27; donde coordinan pero interpretan señales diferente, requiriendo al menos 3 agentes para emergencia de interpretaciones compartidas.</p>
                    <div class="paper-points">• Coordinación sin entendimiento mutuo
•  Malentendidos exitosos
•  Emergencia de comunicación
•  Poblaciones híbridas humano-agente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24660" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Sobre la autoconciencia de los límites de capacidad de los grandes modelos de razonamiento</h3>
                    <p class="paper-summary">📝 Investiga si los LRMs poseen autoconciencia de sus límites de capacidad. Encuentra que la confianza en el razonamiento revela señales de límites, y propone estrategias de monitoreo que reducen el uso de tokens hasta 93.6% evitando razonamiento improductivo.</p>
                    <div class="paper-points">• Autoconciencia de límites de capacidad
•  Monitoreo de confianza en razonamiento
•  Reducción de tokens improductivos
•  Estados ocultos como predictores</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24711" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Transformador con conciencia espacial-funcional y aprendizaje contrastivo de arquetipos para decodificar representaciones neurales visuales de EEG</h3>
                    <p class="paper-summary">📝 Propone SFTG, un framework que mejora la decodificación visual de señales EEG usando EEG Graph Transformer para codificar conectividad cerebral espacial y dinámicas neurales temporales, con aprendizaje contrastivo de arquetipos para reducir variabilidad intra-sujeto.</p>
                    <div class="paper-points">• Decodificación visual de EEG
•  Transformador de grafos cerebrales
•  Aprendizaje contrastivo de arquetipos
•  Reducción de variabilidad intra-sujeto</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24761" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">De la ambigüedad al veredicto: Un agente multi-perspectiva basado en semiótica para razonamiento lógico en LLMs</h3>
                    <p class="paper-summary">📝 Presenta LogicAgent, un framework guiado por cuadrado semiótico que aborda conjuntamente complejidad lógica y semántica. Realiza deducción multi-perspectiva en lógica de primer orden e introduce RepublicQA, un benchmark de nivel universitario para evaluación.</p>
                    <div class="paper-points">• Razonamiento lógico-semántico integrado
•  Framework semiótico
•  Deducción multi-perspectiva
•  Benchmark RepublicQA de alta dificultad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24765" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⏰ TimeOmni-1: Incentivando razonamiento complejo con series temporales en grandes modelos de lenguaje</h3>
                    <p class="paper-summary">📝 Introduce TSR-Suite, el primer conjunto integral de tareas de razonamiento con series temporales que formaliza cuatro tareas atómicas, y TimeOmni-1, el primer modelo unificado de razonamiento para problemas del mundo real que requieren comprensión de series temporales.</p>
                    <div class="paper-points">• Razonamiento con series temporales
•  TSR-Suite con 23K muestras
•  Modelo unificado TimeOmni-1
•  Generalización fuera de distribución</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24803" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Circuitos de Consulta: Explicando Cómo los Modelos de Lenguaje Responden a Prompts de Usuario</h3>
                    <p class="paper-summary">📝 Introduce los circuitos de consulta para rastrear el flujo de información específico que mapea una entrada particular a la salida en modelos de lenguaje. Propone métricas de fidelidad y métodos de muestreo para identificar circuitos escasos que recuperan gran parte del rendimiento del modelo en consultas individuales.</p>
                    <div class="paper-points">• Explicaciones locales y específicas por entrada
•  circuitos que cubren solo 1.3% de conexiones recuperan 60% de rendimiento
•  métrica NDF para evaluar fidelidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24808" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Llevando los LLMs a su Límite de Razonamiento Lógico: El Rol de la Intensidad de Razonamiento en Datos</h3>
                    <p class="paper-summary">📝 Propone la Intensidad de Razonamiento de Datos (DRI) como métrica para cuantificar la complejidad lógica latente en muestras de entrenamiento. Introduce estrategias de re-cognización que optimizan muestras existentes para alinearse mejor con los límites de razonamiento de los LLMs.</p>
                    <div class="paper-points">• Métrica DRI para complejidad lógica
•  optimización de intensidad de razonamiento vs volumen de datos
•  mejoras significativas en generalización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24836" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">PhysicsMinions: Ganando Medallas de Oro en las Últimas Olimpiadas de Física con un Sistema Multi-Agente Coevolutivo Multimodal</h3>
                    <p class="paper-summary">📝 Presenta PhysicsMinions, sistema multi-agente con tres estudios sinérgicos para interpretar diagramas, formular soluciones y verificar respuestas en Olimpiadas de Física. Logra medallas de oro con modelos open-source y supera el rendimiento de modelos individuales.</p>
                    <div class="paper-points">• Sistema coevolutivo multi-agente
•  primera medalla de oro open-source en IPhO
•  mejora sustancial en benchmarks HiPhO</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24855" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">El Surgimiento de la Ciencia Social de los Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Revisión sistemática de 270 estudios sobre cómo los LLMs evocan atribuciones mentales, interactúan entre sí y transforman actividades humanas. Identifica tres dominios: LLM como Mentes Sociales, Sociedades LLM e Interacciones LLM-Humanos.</p>
                    <div class="paper-points">• Taxonomía computacional de tres dominios
•  atribuciones de cognición y moralidad
•  interacciones multi-agente y transformación institucional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24877" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">RealUnify: ¿Los Modelos Unificados Realmente se Benefician de la Unificación? Un Benchmark Integral</h3>
                    <p class="paper-summary">📝 Benchmark con 1,000 instancias para evaluar sinergia bidireccional entre comprensión y generación en modelos multimodales unificados. Evalúa si la comprensión mejora la generación y viceversa, encontrando que la unificación arquitectónica actual es insuficiente.</p>
                    <div class="paper-points">• Evaluación de sinergia bidireccional
•  protocolo dual de evaluación
•  12 modelos unificados evaluados
•  necesidad de nuevas estrategias de entrenamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24897" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Los Embeddings de Redes Neuronales Recuperan Dimensiones de Valor de Ítems Psicométricos al Nivel de Datos Humanos</h3>
                    <p class="paper-summary">📝 Introduce SQuID, método que permite a embeddings de LLMs recuperar dimensiones latentes de cuestionarios psicométricos. Explica 55% de varianza en similitudes dimensionales comparado con datos humanos, ofreciendo ventajas en costo y escalabilidad.</p>
                    <div class="paper-points">• Método SQuID para embeddings psicométricos
•  recuperación de estructura de valores humanos
•  sin necesidad de fine-tuning específico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24906" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Meta-Aprendizaje de Sesgos Inductivos Informados por Teoría usando Procesos Gaussianos con Kernel Profundo</h3>
                    <p class="paper-summary">📝 Marco de meta-aprendizaje bayesiano que convierte predicciones teóricas normativas en modelos probabilísticos tractables. Aplicado al sistema visual temprano, mejora precisión predictiva en registros retinales con estimaciones de incertidumbre calibradas.</p>
                    <div class="paper-points">• Kernel Informado por Teoría
•  mejora en predicción de respuestas retinales
•  selección bayesiana de modelos
•  integración teoría-datos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24919" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚖️ MASLegalBench: Evaluación de Sistemas Multi-Agente en Razonamiento Legal Deductivo</h3>
                    <p class="paper-summary">📝 Benchmark legal para sistemas multi-agente usando GDPR como escenario, cubriendo procesos de razonamiento complejos que reflejan situaciones legales reales. Evalúa arquitecturas MAS con diferentes LLMs, identificando fortalezas y limitaciones.</p>
                    <div class="paper-points">• Benchmark para razonamiento legal deductivo
•  escenario GDPR
•  evaluación de especialización de agentes y descomposición de tareas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24922" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚗 Cuando el Vehículo Autónomo Encuentra la Percepción Cooperativa V2X: ¿Qué Tan Lejos Estamos?</h3>
                    <p class="paper-summary">📝 Estudio empírico de percepción cooperativa V2X, identificando seis patrones de error comunes. Evalúa configuraciones LiDAR, comunicación V2I/V2V y robustez contra interferencias, revelando vulnerabilidades en componentes críticos.</p>
                    <div class="paper-points">• Análisis de 6 patrones de error
•  cooperación LiDAR de mayor rendimiento
•  vulnerabilidades en comunicación
•  impacto en violaciones de conducción</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24927" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">KIRETT - Dispositivo Vestible para Apoyar Operaciones de Rescate usando IA para Mejorar Primeros Auxilios</h3>
                    <p class="paper-summary">📝 Presenta dispositivo vestible con IA para reconocimiento de situaciones durante rescates, proporcionando recomendaciones contextuales a personal de rescate. Busca minimizar daños por tratamiento incorrecto y aumentar probabilidad de supervivencia.</p>
                    <div class="paper-points">• Dispositivo vestible con IA
•  reconocimiento de situaciones en rescates
•  recomendaciones para primeros auxilios
•  mejora en probabilidad de supervivencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24934" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Exploración Agéntica de Modelos Físicos</h3>
                    <p class="paper-summary">📝 Se presenta SciExplorer, un agente que utiliza capacidades de herramientas de modelos de lenguaje grande para explorar libremente sistemas físicos desconocidos. El sistema recupera ecuaciones de movimiento a partir de dinámicas observadas e infiere hamiltonianos de valores esperados. Funciona con un conjunto mínimo de herramientas basadas en ejecución de código.</p>
                    <div class="paper-points">• Exploración automática de sistemas físicos
•  recuperación de ecuaciones de movimiento
•  sin necesidad de ajustes específicos por tarea</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24978" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">CLPO: Aprendizaje Curricular se Encuentra con Optimización de Políticas para Razonamiento LLM</h3>
                    <p class="paper-summary">📝 CLPO introduce un algoritmo que crea un bucle de retroalimentación pedagógica dinámica en la optimización de políticas. Evalúa la dificultad en tiempo real y construye un currículo en línea que guía la reestructuración adaptativa de problemas. Mejora el rendimiento en benchmarks matemáticos y de razonamiento general.</p>
                    <div class="paper-points">• Currículo dinámico basado en evaluación de dificultad
•  reestructuración adaptativa de problemas
•  mejora del 6.96% en rendimiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25004" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Escalado de Generación de Tareas Sintéticas para Agentes mediante Exploración</h3>
                    <p class="paper-summary">📝 AutoPlay es una pipeline escalable para generación de tareas que explora entornos interactivos para descubrir interacciones posibles y sintetizar tareas fundamentadas. Opera en dos fases: exploración y generación de tareas, generando 20k tareas para aplicaciones Android y 10k para Ubuntu.</p>
                    <div class="paper-points">• Generación escalable de tareas
•  exploración sistemática de entornos
•  mejora de tasas de éxito hasta 20%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25047" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Cogito, Ergo Ludo: Un Agente que Aprende a Jugar Razonando y Planificando</h3>
                    <p class="paper-summary">📝 CEL es una arquitectura de agente que utiliza LLM para construir un entendimiento explícito basado en lenguaje de la mecánica del entorno y su propia estrategia. Opera mediante ciclos de interacción y reflexión, induciendo reglas y resumiendo estrategias a partir de experiencias.</p>
                    <div class="paper-points">• Aprendizaje mediante razonamiento explícito
•  inducción de reglas del entorno
•  desarrollo de playbooks estratégicos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25052" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌡️ HeDA: Sistema Agente Inteligente para Descubrimiento de Riesgos de Olas de Calor</h3>
                    <p class="paper-summary">📝 HeDA es un sistema multi-agente para descubrimiento científico automatizado mediante construcción de grafos de conocimiento y análisis de propagación de riesgos multi-capa. Procesa 10,247 papers académicos y descubre cadenas de riesgo previamente no identificadas con 78.9% de precisión.</p>
                    <div class="paper-points">• Construcción automatizada de grafos de conocimiento
•  análisis de propagación de riesgos
•  descubrimiento de 5 cadenas de riesgo nuevas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25112" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">¿Qué Aprenden Realmente los LLM con RL? Evidencia de Habilidades Genuinamente Nuevas</h3>
                    <p class="paper-summary">📝 Investigación que demuestra que los LLM pueden adquirir habilidades genuinamente nuevas durante el RL mediante la composición de habilidades existentes. Los experimentos muestran que el RL permite aprender composiciones no vistas de funciones y que esta capacidad se transfiere a tareas diferentes.</p>
                    <div class="paper-points">• Adquisición de habilidades composicionales
•  transferencia entre tareas
•  cambio fundamental en comportamientos de razonamiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25123" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">💬 La Era de la Interacción Humana en el Mundo Real: RL desde Conversaciones de Usuarios</h3>
                    <p class="paper-summary">📝 Se introduce RLHI, un paradigma que aprende directamente de conversaciones de usuarios en entornos naturales. Incluye dos métodos: reescrituras guiadas por usuarios y recompensas basadas en usuarios, vinculando personas de usuarios a preferencias a nivel de turno.</p>
                    <div class="paper-points">• Aprendizaje de interacciones humanas naturales
•  personalización basada en historial
•  optimización de preferencias condicionada por persona</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25137" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🧭 Navegación Visión-Lenguaje con Descripciones Textuales Analógicas en LLMs</h3>
                    <p class="paper-summary">📝 Mejora de agentes de navegación mediante la incorporación de descripciones textuales desde múltiples perspectivas que facilitan el razonamiento analógico entre imágenes. El enfoque mejora la comprensión contextual global y el razonamiento espacial para decisiones más precisas.</p>
                    <div class="paper-points">• Razonamiento analógico basado en texto
•  comprensión contextual mejorada
•  mejoras significativas en rendimiento de navegación</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25139" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏦</span>
                    <h3 class="paper-title">ReasoningBank: Escalado de Auto-Evolución de Agentes con Memoria de Razonamiento</h3>
                    <p class="paper-summary">📝 ReasoningBank es un framework de memoria que destila estrategias de razonamiento generalizables de experiencias exitosas y fallidas de un agente. Combina memoria consciente con escalado en tiempo de prueba para acelerar el proceso de aprendizaje y permitir auto-evolución.</p>
                    <div class="paper-points">• Memoria de razonamiento generalizable
•  escalado consciente de memoria
•  auto-evolución mediante experiencias diversificadas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25140" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👁️ Déficits de Procesamiento Serial Visual Explícan Divergencias en Razonamiento Humano y VLM</h3>
                    <p class="paper-summary">📝 Investigación que identifica limitaciones en el procesamiento serial con base visual como factor crucial que distingue a los VLMs actuales de los humanos. La precisión disminuida de VLMs se correlaciona fuertemente con mayor tiempo de reacción humano en tareas que requieren procesamiento serial demandante.</p>
                    <div class="paper-points">• Limitaciones en procesamiento serial visual
•  correlación tiempo-rendimiento
•  brecha VLM-humano en razonamiento complejo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25142" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">UniAPL: Un Marco Unificado de Aprendizaje de Preferencias Adversariales para Seguimiento de Instrucciones</h3>
                    <p class="paper-summary">📝 Propone UniAPL, un framework que unifica el aprendizaje por preferencias demostradas y comparativas en la alineación de LLMs. Resuelve el desajuste distribucional entre SFT y RL mediante entrenamiento conjunto en una sola etapa. Los experimentos muestran mejor rendimiento que los baselines GRPO y mejor alineación conductual.</p>
                    <div class="paper-points">• Unificación de SFT y RL en objetivo único
•  Eliminación de desajuste distribucional
•  Mejora rendimiento y alineación conductual</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25148" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">¿Quién es tu Juez? Sobre la Detectabilidad de Juicios Generados por LLM</h3>
                    <p class="paper-summary">📝 Introduce la detección de juicios generados por LLMs basándose solo en puntuaciones y candidatos. Propone J-Detector, un detector ligero que captura interacciones entre puntuaciones y contenido. Evalúa factores de detectabilidad y cuantifica sesgos en jueces LLM.</p>
                    <div class="paper-points">• Detección sin retroalimentación textual
•  J-Detector con características lingüísticas y de LLM
•  Cuantificación de sesgos en juicios</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25154" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Machine Learning">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Machine Learning</h2>
                <span class="category-count">70</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Evaluación Alineada con la Predictibilidad para Pronóstico de Series de Tiempo</h3>
                    <p class="paper-summary">📝 Propone un marco de evaluación que separa el rendimiento del modelo de la impredecibilidad intrínseca de los datos mediante Coherencia Espectral Predictible (SCP) y Ratio de Utilización Lineal (LUR). Revela la &#x27;deriva de predictibilidad&#x27; y muestra que modelos complejos son superiores en datos de baja predictibilidad, mientras los lineales son efectivos en tareas más predecibles.</p>
                    <div class="paper-points">• Marco de evaluación basado en coherencia espectral
•  Evidencia sistemática de deriva de predictibilidad
•  Trade-off arquitectónico entre modelos lineales y complejos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23074" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">CLAD-Net: Reconocimiento Continuo de Actividades en Sistemas Wearable Multi-Sensor</h3>
                    <p class="paper-summary">📝 Framework de aprendizaje continuo que combina transformadores auto-supervisados como memoria a largo plazo con CNN supervisadas mediante destilación de conocimiento. Permite actualizar modelos de sensores wearable sin sacrificar rendimiento en tareas anteriores, manejando eficazmente cambios de distribución entre sujetos.</p>
                    <div class="paper-points">• Combina transformers auto-supervisados con CNN supervisadas
•  Reduce el olvido catastrófico en aprendizaje continuo
•  Funciona bien con datos semi-etiquetados (10-20%)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23077" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Inicialización de Pesos que Preserva Señales para Activaciones Sigmoideas Impares</h3>
                    <p class="paper-summary">📝 Introduce un método de inicialización de pesos específico para funciones de activación sigmoideas impares que evita saturación y colapso de varianza. Permite entrenar redes sin capas de normalización y mejora la eficiencia de datos y convergencia para activaciones donde métodos estándar fallan.</p>
                    <div class="paper-points">• Método de inicialización para sigmoides impares
•  Evita saturación y colapso de varianza
•  Entrena sin capas de normalización</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23085" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Liberación de Políticas de Flujo con Críticos Distribucionales</h3>
                    <p class="paper-summary">📝 Presenta el Crítico de Flujo Distribucional (DFC) que modela la distribución completa de retornos en lugar de valores escalares. Mejora el aprendizaje de políticas de flujo expresivas proporcionando señales más ricas y estables, logrando alto rendimiento en tareas que requieren distribuciones multimodales.</p>
                    <div class="paper-points">• Crítico que modela distribución completa de retornos
•  Flow matching para distribuciones complejas
•  Excelente rendimiento en tareas multimodales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23087" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Desmitificando Modelos Fundacionales de Red</h3>
                    <p class="paper-summary">📝 Investigación sistemática del conocimiento latente en Modelos Fundacionales de Red mediante análisis geométrico de embeddings, alineación métrica y pruebas de sensibilidad causal. Identifica anisotropía, patrones inconsistentes y dependencia de payload, mostrando que abordar estas limitaciones mejora el rendimiento.</p>
                    <div class="paper-points">• Análisis tridimensional de representaciones latentes
•  Identifica anisotropía y limitaciones consistentes
•  Mejoras de hasta +0.35 F1-score</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23089" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Análisis de Sensibilidad para Modelos de Difusión</h3>
                    <p class="paper-summary">📝 Desarrolla un procedimiento de forma cerrada para calcular derivadas direccionales que predicen cómo cambian las muestras del modelo bajo perturbaciones del conjunto de entrenamiento. Método robusto a errores numéricos que correlaciona con cambios reales después de reentrenamiento.</p>
                    <div class="paper-points">• Calcula sensibilidad sin reentrenamiento
•  Predice cambios en muestras bajo perturbaciones
•  Runtime comparable a sampling estándar</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23092" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Optimización de Políticas de Refuerzo Mejorada Causalmente</h3>
                    <p class="paper-summary">📝 Framework CE-PO que aumenta la optimización de políticas con un proxy diferenciable de coherencia causal a lo largo de la generación. Combina sensibilidades jacobianas con feedback de precisión, reduciendo reward hacking y mejorando robustez frente a perturbaciones causales.</p>
                    <div class="paper-points">• Proxy de coherencia causal diferenciable
•  Sensibilidades jacobianas para influencia interna
•  Mejora robustez y reduce reasoning no fiel</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23095" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Detección de Fraude en Blockchain Lista para Cuántica mediante Redes Neuronales de Grafo Ensemble</h3>
                    <p class="paper-summary">📝 Framework ensemble que integra GCN, GAT y GIN para detección de transacciones ilícitas en blockchain. Logra alta recall con baja tasa de falsos positivos, incorporando diseño preparado para futura integración cuántica para seguridad financiera escalable.</p>
                    <div class="paper-points">• Ensemble de GNNs para detección de fraude
•  Alta recall con &lt
• 1% falsos positivos
•  Arquitectura preparada para computación cuántica</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23101" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💾</span>
                    <h3 class="paper-title">Cuantificación Efectiva de Estados del Optimizador Muon</h3>
                    <p class="paper-summary">📝 Introduce cuantificación de 8-bits para el optimizador Muon usando esquemas lineales y dinámicos, reduciendo la huella de memoria en ~74% mientras mantiene rendimiento comparable. Supera a AdamW y sus variantes cuantificadas en pre-entrenamiento de LLMs.</p>
                    <div class="paper-points">• Cuantificación de 8-bits para Muon
•  74% reducción de memoria
•  Mantiene rendimiento vs versión completa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23106" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🧭 RHYTHM: Razonamiento con Tokenización Temporal Jerárquica para Movilidad Humana</h3>
                    <p class="paper-summary">📝 Framework que utiliza LLMs como predictores espacio-temporales mediante tokenización temporal jerárquica que captura dependencias diarias y semanales. Congela el backbone del LLM para reducir complejidad, logrando mejor precisión general y especialmente en fines de semana con menor tiempo de entrenamiento.</p>
                    <div class="paper-points">• Tokenización temporal jerárquica
•  LLMs congelados para eficiencia
•  +5.0% precisión en fines de semana</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23115" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Impute-MACFM: Imputación basada en Emparejamiento de Flujo Consciente de Máscaras</h3>
                    <p class="paper-summary">📝 Propone un framework de imputación para datos tabulares con valores faltantes que utiliza emparejamiento de flujo condicional. Incluye penalizaciones de estabilidad, regularización de consistencia e inyección de ruido. Supera métodos existentes en calidad y eficiencia de imputación.</p>
                    <div class="paper-points">• Framework para datos tabulares
•  maneja diferentes mecanismos de valores faltantes
•  combinación de técnicas de estabilización
•  integración ODE para inferencia</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23126" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">C²GSPG: Calibración de Confianza para Políticas de Secuencia Grupal</h3>
                    <p class="paper-summary">📝 Introduce un método de calibración de confianza para modelos de razonamiento que combina gradientes de política a nivel de secuencia con regularización de entropía cruzada. Mejora precisión en razonamiento lógico y matemático mientras reduce sobreconfianza.</p>
                    <div class="paper-points">• Calibración de confianza
•  eliminación de sesgo a nivel de token
•  regularización de entropía cruzada
•  aplicable a recompensas binarias y no binarias</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23129" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Optimización de Recompensa de Región de Confianza y Algoritmo PIRO</h3>
                    <p class="paper-summary">📝 Presenta un framework no adversarial para aprendizaje por refuerzo inverso que garantiza mejora monótona mediante procesos de Minorización-Maximización. PIRO ofrece entrenamiento estable y alta eficiencia muestral.</p>
                    <div class="paper-points">• Aprendizaje por refuerzo inverso no adversarial
•  garantías de mejora monótona
•  algoritmo PIRO práctico
•  aplicaciones en robótica y comportamiento animal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23135" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Más Allá de Heurísticas: Configuración Global Óptima de Representaciones Neuronales Implícitas</h3>
                    <p class="paper-summary">📝 OptiINR es el primer framework que formula la configuración de INRs como problema de optimización riguroso. Utiliza optimización bayesiana para explorar espacios de activaciones y parámetros de inicialización.</p>
                    <div class="paper-points">• Configuración óptima de INRs
•  optimización bayesiana unificada
•  reemplaza tuning manual
•  máximo rendimiento en aplicaciones de procesamiento de señales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23139" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">TimeExpert: Mejorando Pronósticos de Series Temporales Largas con Mezcla Temporal de Expertos</h3>
                    <p class="paper-summary">📝 Propone Mezcla Temporal de Expertos (TMOE), mecanismo de atención que trata pares clave-valor como expertos locales especializados en contextos temporales distintos. Supera métodos state-of-the-art en pronósticos a largo plazo.</p>
                    <div class="paper-points">• Mecanismo TMOE
•  expertos locales y globales
•  manejo de efectos de lag y segmentos anómalos
•  mejora frameworks existentes como PatchTST</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23145" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Criticar para Verificar: Escalado Precuro y Honesto en Tiempo de Prueba con Verificadores Entrenados por RL</h3>
                    <p class="paper-summary">📝 Mirror-Critique entrena verificadores con señales de crítica informativas contrastando soluciones generadas con soluciones ground-truth. Mejora precisión y honestidad en modelos de lenguaje grandes.</p>
                    <div class="paper-points">• Entrenamiento con críticas informativas
•  síntesis de datos de alta calidad
•  mejor precisión que votación mayoritaria
•  abstinencia consciente de capacidades</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23152" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">CrystalGym: Nuevo Benchmark para Descubrimiento de Materiales Usando Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">📝 Ambiente RL de código abierto para diseño de materiales cristalinos que utiliza señales DFT directas como retroalimentación. Evalúa algoritmos RL optimizando propiedades como band gap y módulo bulk.</p>
                    <div class="paper-points">• Ambiente RL para materiales
•  señales DFT directas
•  benchmark de algoritmos
•  aplicaciones prácticas en diseño de materiales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23156" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📱 Detección de Deterioro Cognitivo Basada en Deep Learning con Sensores Pasivos de Smartphone</h3>
                    <p class="paper-summary">📝 Modelo LSTM para detectar deterioro cognitivo usando datos de sensores smartphone. Incluye aumento de datos consciente de rutinas y personalización demográfica para mejorar generalización.</p>
                    <div class="paper-points">• Monitoreo cognitivo pasivo
•  aumento de datos rutinario
•  personalización demográfica
•  mejora significativa en métricas de evaluación</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23158" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⏰ ProtoTS: Aprendizaje de Prototipos Jerárquicos para Pronósticos de Series Temporales Explicables</h3>
                    <p class="paper-summary">📝 Framework interpretable que modela patrones temporales prototípicos organizados jerárquicamente. Logra alta precisión y transparencia en decisiones de pronóstico.</p>
                    <div class="paper-points">• Prototipos jerárquicos
•  interpretabilidad multinivel
•  representación desruidosa
•  steering experto
•  supera métodos existentes en precisión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23159" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Memoria Asociativa Densa en el Espacio Bures-Wasserstein</h3>
                    <p class="paper-summary">📝 Extiende memorias asociativas densas de vectores a distribuciones de probabilidad usando distancia Wasserstein. Puntos estacionarios corresponden a baricentros de Wasserstein auto-consistentes.</p>
                    <div class="paper-points">• DAM para distribuciones
•  distancia 2-Wasserstein
•  capacidad exponencial de almacenamiento
•  puente entre DAM clásicas y modelado generativo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23162" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Aprendizaje Profundo para Regresión de Subespacios</h3>
                    <p class="paper-summary">📝 Propone usar redes neuronales para predecir subespacios lineales en problemas paramétricos complejos, relajando la interpolación a regresión. Introduce redundancia predictiva mejorando precisión y aplica el método a ecuaciones diferenciales paramétricas y control óptimo.</p>
                    <div class="paper-points">• Regresión de subespacios con redes neuronales
•  redundancia predictiva para mayor precisión
•  aplicaciones en problemas elípticos y PDEs paramétricas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23249" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">NanoFlux: Evaluación y Destilación Adversarial con Doble LLM para Razonamiento Multi-Dominio</h3>
                    <p class="paper-summary">📝 Framework adversarial donde modelos alternan como Atacante y Defensor para generar datos de entrenamiento específicos. Con solo 200 ejemplos supera fine-tuning convencional, mejorando razonamiento matemático, científico y médico con reducción computacional 3-14x.</p>
                    <div class="paper-points">• Framework adversarial dinámico
•  datasets pequeños pero precisos
•  mejoras multi-dominio con eficiencia computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23252" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">ABConformer: Atención Deslizante Inspirada en Física para Predicción de Interfaces Anticuerpo-Antígeno</h3>
                    <p class="paper-summary">📝 Modelo basado en Conformer que predice interfaces anticuerpo-antígeno solo con secuencias. Usa atención deslizante inspirada en física para recuperar contactos a nivel de residuo, logrando state-of-the-art en dataset SARS-CoV-2.</p>
                    <div class="paper-points">• Predicción de paratopos y epitopos desde secuencias
•  atención deslizante física
•  alto rendimiento sin datos estructurales 3D</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23254" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎨</span>
                    <h3 class="paper-title">CREPE: Control de Difusión con Intercambio de Réplicas</h3>
                    <p class="paper-summary">📝 Método flexible para control de modelos de difusión en inferencia usando intercambio de réplicas. Genera partículas secuencialmente manteniendo diversidad, aplicable a annealing, composición de modelos y corrección de sesgos.</p>
                    <div class="paper-points">• Control en inferencia sin reentrenamiento
•  algoritmo de intercambio de réplicas
•  versatilidad en tareas de control</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23265" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">Transfer Learning y Machine Learning para Modelos Pronósticos de Supervivencia a 5 Años en Cáncer de Mama Temprano</h3>
                    <p class="paper-summary">📝 Compara transfer learning desde PREDICT v3 con ML nuevo e integración ensemble para pronóstico de cáncer de mama. Mejora calibración y maneja datos faltantes, validado externamente en cohortes SEER y TEAM.</p>
                    <div class="paper-points">• Transfer learning aplicado a pronóstico médico
•  manejo de datos faltantes
•  validación externa robusta</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23268" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">💹 Reinforcement Learning en Tiempo Continuo para Gestión de Activos y Pasivos</h3>
                    <p class="paper-summary">📝 Enfoque de RL en tiempo continuo para ALM con formulación lineal-cuadrática. Algoritmo model-free con exploración adaptativa que supera estrategias financieras tradicionales en 200 escenarios de mercado.</p>
                    <div class="paper-points">• RL en tiempo continuo para finanzas
•  exploración adaptativa
•  sincronización dinámica activo-pasivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23280" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">✈️ Enfoque de ODE Neuronal para Modelado de Dinámica de Vuelo de Aeronaves</h3>
                    <p class="paper-summary">📝 NODE-FDM combina relaciones cinemáticas analíticas con componentes data-driven para predicción de trayectorias. Supera modelos BADA en fase de descenso usando datos de Quick Access Recorder.</p>
                    <div class="paper-points">• ODEs neuronales para dinámica de vuelo
•  combinación física-data
•  alta precisión en trayectorias</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23307" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">ASTGI: Interacciones Gráficas Espacio-Temporales Adaptativas para Pronóstico de Series Temporales Multivariadas Irregulares</h3>
                    <p class="paper-summary">📝 Framework para series temporales irregulares que construye grafos causales adaptativos en espacio-tiempo. Codifica observaciones discretas como puntos y propaga información dinámicamente, superando métodos state-of-the-art.</p>
                    <div class="paper-points">• Grafos espacio-temporales adaptativos
•  representación de puntos discretos
•  propagación dinámica de información</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23313" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Dinámicas Latentes a Dos Escalas para Transformers de Profundidad Recurrente</h3>
                    <p class="paper-summary">📝 Analiza geometría de iteraciones en transformers recurrentes, revelando dinámicas a dos escalas: refinamientos locales y deriva global. Propone mecanismo de salida temprana basado en diferencias de segundo orden.</p>
                    <div class="paper-points">• Dinámicas a dos escalas
•  análisis geométrico de iteraciones
•  salida temprana eficiente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23314" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 MELCOT: Arquitectura Híbrida con Preservación Marginal para Regresión Matricial</h3>
                    <p class="paper-summary">📝 Modelo híbrido que combina estimación marginal clásica con transporte óptimo de coste aprendible para regresión matricial. Preserva estructura espacial y aprende características globales, superando líneas base eficientemente.</p>
                    <div class="paper-points">• Arquitectura híbrida clásica-DL
•  preservación de estructura espacial
•  eficiencia en regresión matricial</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23315" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Red Hypergráfica Multi-Escala Espacio-Temporal con Estructuras Lead-Lag para Pronóstico de Series Temporales de Acciones</h3>
                    <p class="paper-summary">📝 Propone el framework Hermes para mejorar la precisión en pronósticos de series temporales de acciones capturando correlaciones industriales. Supera limitaciones de métodos existentes mediante módulos de agregación móvil y fusión multi-escala. Los resultados experimentales muestran mejor rendimiento en eficiencia y precisión frente a métodos state-of-the-art.</p>
                    <div class="paper-points">• Captura relaciones lead-lag entre industrias
•  Modela información multi-escala
•  Framework Hermes con hipergráficos dinámicos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23668" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Redes Neuronales de Gráficos con Selección de Vecinos Consciente de la Diversidad y Fusión Dinámica Multi-Escala</h3>
                    <p class="paper-summary">📝 Presenta DIMIGNN, un método que aborda la diversidad de información entre vecinos en redes neuronales de gráficos para series temporales multivariadas. Introduce mecanismos de selección de vecinos y fusión dinámica multi-escala. Experimentos en datasets reales demuestran superioridad sobre métodos previos.</p>
                    <div class="paper-points">• Selección de vecinos consciente de diversidad
•  Fusión dinámica multi-escala
•  Mejora en pronósticos de series temporales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23671" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia una Ley de Escalado Integral para Mezcla de Expertos</h3>
                    <p class="paper-summary">📝 Investiga leyes de escalado específicas para modelos Mixture-of-Experts (MoE), identificando cinco factores clave que afectan el rendimiento. Realiza 446 experimentos controlados para caracterizar efectos marginales. Deriva configuraciones óptimas teóricas y prácticas para diseño de modelos MoE.</p>
                    <div class="paper-points">• Leyes de escalado para MoE
•  Cinco factores clave de rendimiento
•  Configuraciones óptimas teórico-prácticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23678" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Cooperación Dinámica Descentralizada de Modelos Personalizados para Aprendizaje Continuo Federado</h3>
                    <p class="paper-summary">📝 Propone un framework descentralizado para aprendizaje continuo federado donde clientes forman coaliciones dinámicas de cooperación. Balancea adquisición de nuevo conocimiento con retención de aprendizaje previo. Utiliza teoría de juegos coalicionales para simular relaciones entre clientes.</p>
                    <div class="paper-points">• Coaliciones dinámicas de aprendizaje
•  Modelos personalizados por cliente
•  Teoría de juegos coalicionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23683" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Neuronas Hedónicas: Mapeo Mecanicista de Coaliciones Latentes en MLPs de Transformers</h3>
                    <p class="paper-summary">📝 Introduce un framework de interpretabilidad mecanicista basado en teoría de juegos coalicionales para analizar neuronas en modelos de lenguaje. Identifica coaliciones estables de neuronas con efectos no aditivos. Revela estructura de alto orden en representaciones de modelos fine-tuned.</p>
                    <div class="paper-points">• Teoría de juegos coalicionales
•  Interpretabilidad mecanicista
•  Coaliciones de neuronas sinérgicas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23684" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">FedDAPL: Hacia Generalización Privada del Cliente en Aprendizaje Federado</h3>
                    <p class="paper-summary">📝 Integra Redes Neuronales Adversariales de Dominio (DANN) en aprendizaje federado para mejorar generalización cruz-sitio. Propone regularización proximal para estabilizar entrenamiento adversarial. Experimentos en imágenes cerebrales MRIs muestran mejor generalización preservando privacidad.</p>
                    <div class="paper-points">• Privacidad de datos médicos
•  Generalización cruz-sitio
•  Entrenamiento adversarial federado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23688" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Fusión de Modelos Ahora, Arrepentimiento Después: El Costo Oculto es la Transferibilidad Adversarial</h3>
                    <p class="paper-summary">📝 Estudia el impacto de la fusión de modelos en la transferibilidad de ejemplos adversariales. Evaluaciones exhaustivas muestran que métodos más fuertes de fusión aumentan vulnerabilidad a ataques de transferencia. Revela tres insights clave para diseño robusto de sistemas.</p>
                    <div class="paper-points">• Vulnerabilidad en fusión de modelos
•  Transferibilidad adversarial
•  Análisis de seguridad en ML</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23689" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Estimación de Transferibilidad de Modelos Fundación de Series Temporales via Aprendizaje en Contexto</h3>
                    <p class="paper-summary">📝 Presenta TimeTic, framework que estima transferibilidad de modelos fundación de series temporales usando aprendizaje en contexto. Organiza relaciones modelo-dataset como información contextual. Logra alta correlación con rendimiento real post fine-tuning.</p>
                    <div class="paper-points">• Estimación de transferibilidad
•  Aprendizaje en contexto
•  Modelos fundación de series temporales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23695" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Uniendo RL Discreto y Continuo: Gradiente de Política Determinística Estable con Caracterización de Martingala</h3>
                    <p class="paper-summary">📝 Deriva fórmula de gradiente de política para reinforcement learning en tiempo continuo basada en funciones de ventaja. Establece caracterización de martingala como fundamento teórico. Propone algoritmo CT-DDPG con mejor estabilidad y convergencia.</p>
                    <div class="paper-points">• RL en tiempo continuo
•  Gradientes de política determinística
•  Caracterización de martingala</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23711" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">FraudTransformer: GPT con Conciencia Temporal para Detección de Fraude en Transacciones</h3>
                    <p class="paper-summary">📝 Introduce FraudTransformer, modelo basado en GPT para detección de fraude que incorpora codificadores de tiempo y posición. Supera métodos clásicos y variantes de transformer en dataset industrial masivo. Logra最高 AUROC y PRAUC en pruebas.</p>
                    <div class="paper-points">• Detección de fraude en tiempo real
•  Arquitectura GPT modificada
•  Codificación de tiempo y posición</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23712" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">ChessArena: Un banco de pruebas de ajedrez para evaluar capacidades de razonamiento estratégico en modelos de lenguaje grandes</h3>
                    <p class="paper-summary">📝 ChessArena es un marco competitivo donde LLMs juegan ajedrez entre sí para evaluar su razonamiento estratégico. Los resultados muestran que ningún modelo actual puede vencer a un motor de ajedrez de nivel amateur humano. Se presenta un modelo fine-tuned que mejora significativamente el rendimiento.</p>
                    <div class="paper-points">• Evaluación de razonamiento estratégico en LLMs
•  4 modos de juego diferentes
•  ranking y leaderboard
•  más de 800 juegos evaluados
•  fine-tuning mejora rendimiento</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24239" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Modelos Fundacionales de Grafos: Uniendo Paradigmas de Modelos de Lenguaje y Optimización de Grafos</h3>
                    <p class="paper-summary">📝 Se introduce GFM, el primer marco capaz de resolver todos los problemas de optimización basados en distancia en estructuras de grafos. Combina pre-entrenamiento auto-supervisado similar a LLMs con heurísticas generativas simples para desafíos de optimización.</p>
                    <div class="paper-points">• Primer modelo fundacional para grafos
•  pre-entrenamiento con caminos aleatorios
•  resuelve problemas de optimización basados en distancia
•  rendimiento competitivo con solvers especializados</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24256" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Marco de Aprendizaje por Refuerzo Adversario para Simulación de Tramposos ESP</h3>
                    <p class="paper-summary">📝 Propone un marco de simulación para modelar tramposos ESP que revelan información oculta en juegos. Formula la interacción entre tramposos y detectores como un juego adversarial donde ambos co-adaptan su comportamiento.</p>
                    <div class="paper-points">• Simulación de trampas ESP
•  modelo de tramposos que cambia dinámicamente entre comportamientos
•  juego adversarial tramposo-detector
•  plataforma controlable para desarrollo anti-trampas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24274" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">ELASTIQ: Alineación EEG-Lenguaje con Instrucción de Tarea Semántica y Consulta</h3>
                    <p class="paper-summary">📝 ELASTIQ es un modelo fundacional que alinea señales EEG con lenguaje mediante instrucciones semánticas. Integra guía semántica consciente de la tarea para producir embeddings EEG estructurados y lingüísticamente alineados.</p>
                    <div class="paper-points">• Alineación EEG-lenguaje
•  módulo de reconstrucción espectral-temporal
•  transformer de atención cruzada basado en consultas
•  estado del arte en 14 de 20 datasets</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24302" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Agregación Asíncrona de Políticas de Gradiente para Aprendizaje por Refuerzo Distribuido Eficiente</h3>
                    <p class="paper-summary">📝 Introduce dos algoritmos para RL distribuido que implementan agregación asíncrona de gradientes de políticas. Mejoran la complejidad computacional y de comunicación manejando entornos heterogéneos.</p>
                    <div class="paper-points">• Algoritmos asíncronos para RL distribuido
•  manejo de computación heterogénea
•  mejoras en complejidad computacional
•  soporte para operación AllReduce</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24305" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌱 Estudio de Enfoques de EDO Universales para Predecir Carbono Orgánico del Suelo</h3>
                    <p class="paper-summary">📝 Explora un framework de SciML basado en Ecuaciones Diferenciales Universales para predecir dinámicas de carbono orgánico del suelo. Evalúa seis casos experimentales desde benchmarks limpios hasta pruebas con ruido severo.</p>
                    <div class="paper-points">• UDEs para modelado de carbono orgánico
•  combinación de física mecanística con redes neuronales
•  evaluación sistemática con ruido
•  robustez en configuraciones moderadas de ruido</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24306" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🎥 Repensando JEPA: SSL de Video Eficiente en Cómputo con Maestros Congelados</h3>
                    <p class="paper-summary">📝 Propone SALT, un esquema de dos etapas sin regularización que utiliza maestros congelados para aprendizaje de representación de video. Decopla la optimización en reconstrucción de píxeles y predicción de latentes enmascarados.</p>
                    <div class="paper-points">• Maestros congelados para SSL de video
•  método SALT de dos etapas
•  eficiencia computacional mejorada
•  estudiantes robustos a calidad del maestro</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24317" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">AuON: Una Alternativa en Tiempo Lineal a Actualizaciones de Momento Semi-Ortogonales</h3>
                    <p class="paper-summary">📝 Presenta AuON, un optimizador de tiempo lineal que logra rendimiento fuerte sin construir matrices semi-ortogonales. Combina transformaciones de escalado RMS con coseno hiperbólico y normalización.</p>
                    <div class="paper-points">• Optimizador de tiempo lineal
•  evita ortogonalización explícita
•  preserva alineación estructural
•  rendimiento comparable con AdamW y Muon</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24320" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">H+: Agregación Consciente de Similitud Eficiente para Aprendizaje Federado Resiliente a Bizantinos</h3>
                    <p class="paper-summary">📝 Propone H+, un enfoque de agregación consciente de similitud que identifica clientes honestos en FL mediante segmentos aleatorios de parámetros. Funciona tanto con como sin datos limpios disponibles.</p>
                    <div class="paper-points">• Resiliencia a ataques bizantinos
•  bajo costo computacional
•  funciona sin datos limpios
•  selección aleatoria de segmentos de parámetros</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24330" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🌊</span>
                    <h3 class="paper-title">Hacia Pronóstico Generalizable de Dinámicas de EDP mediante Aprendizaje de Invarianza Guiado por Física</h3>
                    <p class="paper-summary">📝 Propone iMOOE, un método que captura la invariancia fundamental en sistemas de EDP mediante una arquitectura de mezcla de operadores expertos y objetivo de aprendizaje enriquecido en frecuencia.</p>
                    <div class="paper-points">• Generalización cero-shot en EDP
•  principio de invariancia de dos niveles
•  arquitectura de mezcla de operadores
•  validación en benchmarks simulados y aplicaciones reales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24332" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🎵</span>
                    <h3 class="paper-title">Más Allá del Gancho: Predicción de Inclusión en las Listas Billboard Hot 100 con Aprendizaje Automático</h3>
                    <p class="paper-summary">📝 Este estudio utiliza machine learning para predecir qué canciones entrarán en las listas Billboard Hot 100, analizando popularidad en streaming, atributos de audio y características perceptuales. La popularidad resultó ser el predictor más decisivo, seguido de instrumentalidad, valencia y duración. Los modelos lograron precisiones superiores al 90%.</p>
                    <div class="paper-points">• Predicción de éxito musical
•  Popularidad como factor principal
•  Múltiples algoritmos comparados (Logistic Regression
•  Random Forest
•  XGBoost)
•  Alta precisión (90.4%)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24856" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">DRIFT-Net: Un Operador Neural Acoplado Espectralmente para Aprendizaje de PDEs</h3>
                    <p class="paper-summary">📝 DRIFT-Net propone una arquitectura de dos ramas para resolver ecuaciones diferenciales: una rama espectral captura información global de baja frecuencia y otra rama de imagen maneja detalles locales. Supera a métodos basados en atención con menor error y mayor eficiencia computacional.</p>
                    <div class="paper-points">• Resolución de PDEs
•  Diseño dual (espectral + imagen)
•  Mejor rendimiento que attention
•  Reducción de error 7%-54%
•  Menos parámetros</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24868" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🌱 Colaboración Guiada por Incertidumbre entre Expertos e IA para Anotación Eficiente de Horizontes de Suelo</h3>
                    <p class="paper-summary">📝 Aplica predicción conformal a SoilNet para cuantificar incertidumbre en la descripción de perfiles de suelo. Diseña un sistema humano-en-el-loop donde los expertos intervienen cuando la incertidumbre del modelo es alta, logrando anotaciones más eficientes con presupuesto limitado.</p>
                    <div class="paper-points">• Colaboración humano-IA
•  Predicción conformal
•  Anotación eficiente de suelos
•  Sistema HIL (Human-in-the-Loop)
•  Multimodal y multitarea</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24873" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Leyes de Escalado y Espectros de Redes Neuronales Superficiales en Régimen de Aprendizaje de Características</h3>
                    <p class="paper-summary">📝 Analiza teóricamente las leyes de escalado en redes neuronales cuadráticas y diagonales durante el aprendizaje de características. Deriva diagramas de fase para el riesgo excesivo y conecta regímenes de escalado con propiedades espectrales de los pesos entrenados.</p>
                    <div class="paper-points">• Leyes de escalado neural
•  Análisis teórico
•  Regímenes de aprendizaje
•  Propiedades espectrales
•  Conexión con compresión matricial</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24882" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Canonicalización Adaptativa con Aplicación a Redes Geométricas Anisotrópicas Invariantes</h3>
                    <p class="paper-summary">📝 Introduce canonicalización adaptativa, un marco donde la forma canónica depende tanto de la entrada como de la red neuronal. Resuelve problemas de discontinuidad en métodos equivariantes y supera a data augmentation, canonicalización estándar y arquitecturas equivariantes.</p>
                    <div class="paper-points">• Aprendizaje equivariante
•  Canonicalización adaptativa
•  Maximización de confianza
•  Aplicaciones en GNNs y nubes de puntos
•  Propiedades de aproximación universal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24886" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Hacia la Comprensión de la Forma de Representaciones en Modelos de Lenguaje de Proteínas</h3>
                    <p class="paper-summary">📝 Investiga cómo los PLMs transforman el espacio de secuencias proteicas usando representaciones SRV y filtraciones de grafos. Encuentra que los modelos codifican preferentemente relaciones locales entre residuos y que la codificación más estructural ocurre cerca de las capas finales.</p>
                    <div class="paper-points">• Interpretabilidad de PLMs
•  Representaciones SRV
•  Filtraciones de grafos
•  Estructura proteica
•  Codificación de relaciones locales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24895" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🎰 Cuando Gana la Codicia: Sesgo Emergente de Explotación en Entrenamiento de LLMs Meta-Bandit</h3>
                    <p class="paper-summary">📝 Investiga cómo SFT y RL moldean estrategias de exploración en LLMs para el problema multi-armed bandit. Los agentes entrenados muestran mayor explotación pero son propensos a fallos catastróficos por abandonar prematuramente la exploración.</p>
                    <div class="paper-points">• Bandit multi-brazo
•  LLMs como agentes
•  Fine-tuning supervisado
•  Aprendizaje por refuerzo
•  Generalización robusta</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24923" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">¿Es la Información de Secuencia Todo lo que Necesitas para Optimización Bayesiana de Anticuerpos?</h3>
                    <p class="paper-summary">📝 Explora la incorporación de información estructural en la optimización bayesiana de anticuerpos para afinidad de unión y estabilidad. Encuentra que métodos basados solo en secuencia pueden igualar el rendimiento de métodos estructurales con restricciones de modelo de lenguaje proteico.</p>
                    <div class="paper-points">• Optimización bayesiana
•  Diseño de anticuerpos
•  Modelos de lenguaje proteico
•  Restricciones suaves
•  Eficiencia en datos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24933" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">OAT-FM: Transporte de Aceleración Óptima para Mejorar Flow Matching</h3>
                    <p class="paper-summary">📝 Conecta Flow Matching con la teoría de Optimal Acceleration Transport, desarrollando OAT-FM que optimiza el transporte de aceleración en lugar de velocidad constante. Propone un paradigma de dos fases que mejora consistentemente el rendimiento en tareas generativas.</p>
                    <div class="paper-points">• Modelado generativo
•  Flow Matching
•  Transporte óptimo
•  Enderezamiento de flujos
•  Fine-tuning eficiente</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24936" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Aprendizaje de Representaciones Distinguibles en Deep Q-Networks para Transferencia Lineal</h3>
                    <p class="paper-summary">📝 Propone un enfoque de Q-learning con regularización para reducir correlaciones entre representaciones de características, permitiendo el uso efectivo de aproximación lineal en transfer learning. Demuestra mejor rendimiento y reducción de costos computacionales.</p>
                    <div class="paper-points">• Transfer learning
•  Deep Q-learning
•  Regularización de características
•  Aproximación lineal
•  Reducción de correlaciones</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24947" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Orquestación de ramas intra-solicitud para razonamiento eficiente en LLM</h3>
                    <p class="paper-summary">📝 DUCHESS es un sistema de servicio para LLM que reduce costos y latencia sin sacrificar precisión mediante orquestación de ramas guiada por predicciones. Utiliza un modelo liviano para estimar la corrección de ramas y decide terminarlas, duplicarlas o continuarlas. Reduce uso de tokens en 42-63% y latencias en 52-85% comparado con auto-consistencia.</p>
                    <div class="paper-points">• Orquestación intra-solicitud
•  predicción de corrección de ramas
•  reducción de latencia y tokens
•  mantiene precisión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24957" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Regularización Adaptativa al Solapamiento para Estimación del Efecto Promedio del Tratamiento Condicional</h3>
                    <p class="paper-summary">📝 Introduce Regularización Adaptativa al Solapamiento (OAR) que mejora estimadores CATE en regiones de bajo solapamiento. Regulariza modelos proporcionalmente a pesos de solapamiento, siendo más fuerte en zonas con pocos datos. Funciona con modelos paramétricos y no paramétricos, preservando ortogonalidad de Neyman.</p>
                    <div class="paper-points">• Regularización adaptativa
•  mejora estimación CATE
•  bajo solapamiento
•  versiones insesgadas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24962" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Doble Descenso como Lente para Eficiencia Muestral en Modelos Autoregresivos vs. Difusión Discreta</h3>
                    <p class="paper-summary">📝 Compara eficiencia muestral entre difusión discreta y modelos autoregresivos usando fenómeno de doble descenso. Los modelos de difusión requieren mayor capacidad y épocas para alcanzar el umbral de interpolación. Los autoregresivos son más eficientes en datasets pequeños.</p>
                    <div class="paper-points">• Comparación eficiencia muestral
•  doble descenso
•  difusión discreta vs autoregresivo
•  requerimientos de capacidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24974" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">La Valoración de Política Aleatoria es Suficiente para Razonamiento en LLM con Recompensas Verificables</h3>
                    <p class="paper-summary">📝 Propone ROVER, algoritmo minimalista para razonamiento matemático en LLM que utiliza la función Q de una política uniformemente aleatoria. Evita iteración de política generalizada y sus problemas de inestabilidad. Mejora calidad (+8.2 pass@1) y diversidad (+17.6%) manteniendo exploración.</p>
                    <div class="paper-points">• Política aleatoria uniforme
•  evitación de PPO/GRPO
•  mejora diversidad
•  razonamiento matemático</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24981" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Complejidad Muestral de TD y PPO en RKHS</h3>
                    <p class="paper-summary">📝 Analiza PPO desde perspectiva de espacio de funciones en RKHS. Desacopla evaluación y mejora de políticas usando crítico TD kernelizado y paso proximal con gradiente natural. Proporciona garantías no-asintóticas y regla de muestreo para convergencia óptima k^{-1/2}.</p>
                    <div class="paper-points">• Análisis RKHS
•  TD kernelizado
•  garantías no-asintóticas
•  convergencia óptima
•  mejora estabilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24991" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Inferencia de Membresía Basada en Score en Modelos de Difusión</h3>
                    <p class="paper-summary">📝 Estudia ataques de inferencia de membresía (MIA) en modelos de difusión basados en vectores de ruido predichos. Propone SimA, ataque de consulta única que usa norma del desruidor para revelar membresía. Modelos de difusión latente son menos vulnerables debido al cuello de botella informativo.</p>
                    <div class="paper-points">• Ataques membresía
•  difusión
•  consulta única
•  vulnerabilidad reducida en modelos latentes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25003" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🌊</span>
                    <h3 class="paper-title">Aprendizaje Profundo Consciente de Incertidumbre para Pronóstico de Peligro de Incendios Forestales</h3>
                    <p class="paper-summary">📝 Presenta framework DL que captura incertidumbre epistémica y aleatoria para pronóstico de incendios. Mejora F1 Score en 2.3% y reduce error de calibración en 2.1%. Genera mapas de peligro con capas de incertidumbre para soporte de decisiones.</p>
                    <div class="paper-points">• Incertidumbre epistémica/aleatoria
•  pronóstico incendios
•  calibración mejorada
•  mapas de incertidumbre</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25017" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">MARCOS: Pensamiento Profundo mediante Cadena de Markov de Pensamientos Continuos</h3>
                    <p class="paper-summary">📝 Propone nuevo paradigma de razonamiento como cadena de Markov de pensamientos continuos en lugar de tokens discretos. Entrenamiento variacional en dos fases. Logra rendimiento comparable a CoT con 15.7x aceleración en inferencia y supera GSM8K en 4.7%.</p>
                    <div class="paper-points">• Pensamientos continuos
•  cadena de Markov
•  aceleración inferencia
•  control granular de aleatoriedad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25020" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏗</span>
                    <h3 class="paper-title">️ Surrogados Bayesianos para Pre-evaluación de Portafolios de Puentes Envejecidos</h3>
                    <p class="paper-summary">📝 Propone redes neuronales bayesianas como surrogados para pre-evaluación rápida de puentes. Entrenadas en base de datos de análisis de elementos finitos, predicen factores de cumplimiento con incertidumbre calibrada. Permite triaje eficiente en portafolios de infraestructura.</p>
                    <div class="paper-points">• Surrogados Bayesianos
•  evaluación puentes
•  incertidumbre epistémica
•  reducción costos y emisiones</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25031" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Análisis Multiescala de Transformers de Campo Medio en Régimen de Interacción Moderada</h3>
                    <p class="paper-summary">📝 Estudia evolución de tokens en transformers encoder-only modelados como sistema de partículas en campo medio. En régimen de interacción moderada, identifica tres fases: colapso rápido en espacio dimensional bajo, formación de clusters y fusión secuencial.</p>
                    <div class="paper-points">• Dinámica de campo medio
•  régimen moderado
•  comportamiento multiescala
•  colapso dimensional
•  fusión de clusters</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25040" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ingeniería de Software">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Ingeniería de Software</h2>
                <span class="category-count">35</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Punto de referencia para vericodificación: síntesis de programas formalmente verificados</h3>
                    <p class="paper-summary">📝 Presenta el mayor benchmark para vericodificación (generación de código verificado formalmente) con 12,504 especificaciones. Los LLMs logran tasas de éxito del 27% en Lean, 44% en Verus/Rust y 82% en Dafny. Las descripciones en lenguaje natural no mejoran significativamente el rendimiento.</p>
                    <div class="paper-points">• 12
• 504 especificaciones formales
•  6
• 174 problemas nuevos
•  Mejora del 68% al 96% en verificación Dafny</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22908" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Hacia explicaciones interpretables en detección de clones de código usando explicadores post-hoc basados en LLM</h3>
                    <p class="paper-summary">📝 Propone usar LLMs como explicadores post-hoc para interpretar predicciones de detectores de clones de código. ChatGPT-4 explica correctamente hasta el 98% de los resultados de GraphCodeBERT, ofreciendo buenas explicaciones el 95% del tiempo.</p>
                    <div class="paper-points">• Explicaciones correctas hasta 98%
•  Temperatura cero mejora precisión
•  Útil para tareas de ingeniería de software</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.22978" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">El Efecto Mateo de los asistentes de programación con IA: Un sesgo oculto en la evolución del software</h3>
                    <p class="paper-summary">📝 Revela un &#x27;Efecto Mateo&#x27; donde los LLMs tienen mayor tasa de éxito generando código para lenguajes y frameworks más populares. Esto puede reforzar jerarquías existentes y reducir la diversidad en ecosistemas de programación.</p>
                    <div class="paper-points">• Los lenguajes populares tienen mayor éxito
•  Refuerza jerarquías existentes
•  Impacto en diversidad e innovación</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23261" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Arcadas de Código: Visualización 3D de clases, dependencias y métricas de software</h3>
                    <p class="paper-summary">📝 Introduce un sistema de visualización 3D interactivo para código que permite agrupamiento configurable, combinación de métricas granulares y ajuste dinámico de atributos de renderizado para mejorar la comprensión de sistemas a gran escala.</p>
                    <div class="paper-points">• Agrupamiento configurable
•  Métricas multi-nivel
•  Motor de visualización interactivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23297" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🧩 Métodos para evaluar la accesibilidad del software</h3>
                    <p class="paper-summary">📝 Desarrolla métodos detallados para evaluar la accesibilidad de software, incluyendo un modelo matemático y clasificación. Aplica la metodología al sitio web de una universidad, proporcionando recomendaciones para mejorar la inclusividad.</p>
                    <div class="paper-points">• Cumplimiento de estándares ISO/WCAG
•  Modelo matemático para accesibilidad
•  Análisis de sitio web universitario</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23469" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Mejorando la eficiencia de sistemas agentes LLM mediante reducción de trayectorias</h3>
                    <p class="paper-summary">📝 Presenta AgentDiet, un enfoque para reducir costos computacionales en agentes LLM eliminando información inútil, redundante y expirada de las trayectorias. Reduce tokens de entrada en 39.9%-59.7% manteniendo el mismo rendimiento.</p>
                    <div class="paper-points">• Reducción de 39.9%-59.7% en tokens
•  Mantiene rendimiento del agente
•  Enfoque en eficiencia computacional</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23586" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">Evaluación basada en similitud de la reproducibilidad computacional en Jupyter Notebooks</h3>
                    <p class="paper-summary">📝 Introduce el Índice de Reproducibilidad basado en Similitud (SRI) para evaluar cuantitativamente la reproducibilidad en Jupyter Notebooks. Emplea métricas de similitud específicas para diferentes tipos de objetos Python.</p>
                    <div class="paper-points">• Métrica SRI cuantitativa [0
• 1]
•  Compara salidas originales vs rerun
•  Caso de estudio con notebooks reales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23645" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">PAT-Agent: Autoformalización para verificación de modelos</h3>
                    <p class="paper-summary">📝 Framework end-to-end que combina LLMs con verificación formal para automatizar la construcción de modelos verificables. Incluye planificación, generación de código y bucle de reparación usando contreejemplos.</p>
                    <div class="paper-points">• Planificación LLM + generación código
•  Verificación con PAT model checker
•  Bucle de reparación iterativo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23675" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Satellite: Detección y análisis de vulnerabilidades en contratos inteligentes causadas por mal uso de subcontratos</h3>
                    <p class="paper-summary">📝 Framework de análisis estático a nivel de bytecode que detecta vulnerabilidades por mal uso de subcontratos (SMV). Usa transfer learning para recuperar métodos heredados y logra 84.68% de precisión y 92.11% de recall.</p>
                    <div class="paper-points">• 84.68% precisión
•  92.11% recall
•  Detecta 14 nuevas vulnerabilidades en contratos reales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23679" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Pruebas concólicas guiadas por influencia para robustez de Transformers</h3>
                    <p class="paper-summary">📝 Presenta un tester concólico guiado por influencia (SHAP) para clasificadores Transformer. Desarrolla semántica compatible con solucionadores SMT para atención multi-cabeza y heurísticas de programación prácticas.</p>
                    <div class="paper-points">• Guiado por influencia SHAP
•  Semántica compatible con SMT
•  Más eficiente que línea base FIFO</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23806" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Navegando el Laberinto: Generación de Pruebas Unitarias Sensibles a Rutas con Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Presenta JUnitGenie, un framework sensible a rutas que combina conocimiento del código con capacidades semánticas de LLMs para generar pruebas unitarias. Evalúa 2,258 métodos complejos en proyectos Java reales, mejorando la cobertura en 29-31% sobre métodos basales y detectando bugs reales confirmados por desarrolladores.</p>
                    <div class="paper-points">• Framework path-sensitive
•  Combina código y LLMs
•  Mejora cobertura 29-31%
•  Detecta bugs reales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23812" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">SolContractEval: Un Benchmark para Evaluación de Generación de Código Solidity a Nivel de Contrato</h3>
                    <p class="paper-summary">📝 Primer benchmark a nivel de contrato para generación de código Solidity, con 124 tareas de contratos reales en cadena. Evalúa 6 LLMs principales, encontrando que Claude-3.7-Sonnet tiene mejor rendimiento pero los modelos luchan con lógica compleja y dependencias entre contratos.</p>
                    <div class="paper-points">• Primer benchmark contract-level
•  124 tareas reales
•  Evaluación dinámica
•  LLMs luchan con lógica compleja</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23824" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">HFuzzer: Pruebas de Modelos de Lenguaje Grandes para Alucinaciones de Paquetes mediante Fuzzing Basado en Frases</h3>
                    <p class="paper-summary">📝 Framework HFUZZER que usa fuzzing basado en frases para probar LLMs en alucinaciones de paquetes (recomendar paquetes inexistentes). Identifica 2.60x más paquetes alucinados únicos que métodos mutacionales y encuentra 46 paquetes alucinados en GPT-4o.</p>
                    <div class="paper-points">• Detección alucinaciones paquetes
•  Fuzzing basado en frases
•  2.60x más detecciones
•  Vulnerabilidad cadena suministro</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23835" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Pruebas Basadas en Aprendizaje para Aprendizaje Profundo: Mejorando la Robustez del Modelo con Priorización de Entradas Adversarias</h3>
                    <p class="paper-summary">📝 Método que integra pruebas basadas en aprendizaje con testing de hipótesis y mutación para priorizar casos de prueba adversarios en DNNs. Supera enfoques basales en detección de fallos y preserva diversidad de entradas para mejorar robustez en aplicaciones críticas.</p>
                    <div class="paper-points">• Priorización entradas adversarias
•  Testing basado aprendizaje
•  Mejora detección fallos
•  Aplicaciones críticas</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23961" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">SandCell: Sandboxing en Rust Más Allá del Código Inseguro</h3>
                    <p class="paper-summary">📝 Sistema SandCell para aislamiento flexible y liviano en Rust que aprovecha límites sintácticos existentes. Permite a programadores especificar componentes a sandboxear con anotaciones mínimas y técnicas novedosas para minimizar overhead en transferencia de datos.</p>
                    <div class="paper-points">• Sandboxing flexible Rust
•  Mínimas anotaciones
•  Bajo overhead
•  Previene vulnerabilidades</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24032" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">PerfBench: ¿Pueden los Agentes Resolver Errores de Rendimiento del Mundo Real?</h3>
                    <p class="paper-summary">📝 Benchmark con 81 tareas reales de corrección de errores de rendimiento de repositorios .NET. Los agentes actuales tienen solo ~3% de éxito, mientras que OpenHands-Perf-Agent con herramientas conscientes del rendimiento alcanza ~20%, mostrando mejora significativa pero espacio para mejoras.</p>
                    <div class="paper-points">• Benchmark rendimiento real
•  81 tareas
•  3% vs 20% éxito
•  Herramientas performance-aware</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24091" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">TENET: Aprovechando Pruebas Más Allá de la Validación para Generación de Código</h3>
                    <p class="paper-summary">📝 Agente LLM TENET para generación de funciones en repositorios complejos bajo desarrollo guiado por pruebas. Logra 69-81% Pass@1 en benchmarks, superando agentes basales. Incluye harness de pruebas, herramientas de depuración y refinamiento iterativo basado en reflexión.</p>
                    <div class="paper-points">• Desarrollo guiado por pruebas
•  69-81% Pass@1
•  Refinamiento iterativo
•  Contexto nivel repositorio</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24148" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Pruebas Metamórficas para Software de Moderación de Contenido de Audio</h3>
                    <p class="paper-summary">📝 Framework MTAM que aplica 14 relaciones metamórficas en dos categorías de perturbación para probar software de moderación de audio. Logra hasta 51.1% de tasa de detección de errores en software comercial y 45.7% en modelos académicos contra contenido tóxico modificado.</p>
                    <div class="paper-points">• Testing metamórfico audio
•  14 relaciones
•  Hasta 51.1% detección errores
•  Contenido tóxico evasivo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24215" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Comparación de LLMs Open-Source y Comerciales para Análisis y Reportes Específicos de Dominio: Retos y Compromisos de Diseño</h3>
                    <p class="paper-summary">📝 Estudio de LLMs para análisis de reportes financieros, comparando modelos open-source locales vs GPT-4o comercial. Los modelos en nube ofrecen mejor fluidez pero problemas de privacidad, mientras los locales requieren más esfuerzo de ingeniería pero mejor control de datos.</p>
                    <div class="paper-points">• LLMs financieros
•  Open-source vs comercial
•  Privacidad vs usabilidad
•  Retos integración dominio-específico</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24344" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧬</span>
                    <h3 class="paper-title">Identificación Eficiente de Descomposición de Autómatas Finitos Deterministas a partir de Ejemplos</h3>
                    <p class="paper-summary">📝 Avanza investigación en descomposición de DFAs reemplazando APTAs redundantes con representación compacta 3DFA. Logra ganancias significativas de eficiencia para problemas de identificación de descomposición óptima Pareto y óptima en estados mediante encoding SAT mejorado.</p>
                    <div class="paper-points">• Descomposición DFA
•  3DFA vs APTA
•  Encoding SAT mejorado
•  Eficiencia escalable</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24347" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔬</span>
                    <h3 class="paper-title">¿Realmente es Confiable? Evaluando la Fidelidad de Sistemas de Mantenimiento de Confiabilidad de Software Basados en Logs</h3>
                    <p class="paper-summary">📝 Los sistemas de mantenimiento de confiabilidad basados en logs son cruciales pero representan una caja negra para los proveedores. Se define una métrica de confiabilidad (fidelidad diagnóstica) y se propone FaithLog, que logra alta fidelidad mediante mecanismos de atención guiados por causalidad y aprendizaje de consistencia adversarial.</p>
                    <div class="paper-points">• Métrica de fidelidad diagnóstica
•  evaluación de métodos existentes
•  propuesta de FaithLog con atención causal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24352" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤝</span>
                    <h3 class="paper-title">Diagnóstico de Fallos Basado en Logs mediante Aprendizaje Multi-Tarea Interactivo</h3>
                    <p class="paper-summary">📝 Se propone Chimera, un método de diagnóstico de fallos de extremo a extremo que supera las limitaciones de los enfoques independientes. Utiliza aprendizaje multi-tarea interactivo para transferir conocimiento entre detección de anomalías y localización de causas raíz.</p>
                    <div class="paper-points">• Enfoque end-to-end
•  aprendizaje multi-tarea interactivo
•  mejora en detección (2.92-5.00%) y localización (19.01-37.09%)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24364" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Computación de Servicios Agénticos</h3>
                    <p class="paper-summary">📝 Se introduce la Computación de Servicios Agénticos (ASC), un nuevo paradigma que reimagina los servicios como entidades inteligentes y autoadaptativas. Presenta un framework basado en ciclo de vida con cuatro fases: Diseño, Despliegue, Operación y Evolución.</p>
                    <div class="paper-points">• Nuevo paradigma ASC
•  framework de ciclo de vida
•  cuatro dimensiones de investigación
•  servicios orquestados inteligentes</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24380" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧪</span>
                    <h3 class="paper-title">Actualización Automatizada de Tests Unitarios mediante LLMs</h3>
                    <p class="paper-summary">📝 TESTUPDATER es un enfoque basado en LLMs para actualizar tests unitarios automáticamente. Combina análisis de cambios de código, recolección de contexto y refinamiento iterativo consciente del tipo de error, logrando altas tasas de compilación (94.4%) y paso de tests (86.7%).</p>
                    <div class="paper-points">• Actualización automática de tests
•  uso de LLMs
•  refinamiento iterativo
•  benchmark UPDATES4J</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24419" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚀 Hacia el Shift-Up: Actividades de Alto Valor en Desarrollo Nativo con GenAI</h3>
                    <p class="paper-summary">📝 Se propone un framework llamado &#x27;shift-up&#x27; para desarrollo nativo con GenAI que permite a los equipos enfocarse en trabajo de alto valor mientras son apoyados por IA generativa. Incluye un estudio preliminar y futuras direcciones de investigación.</p>
                    <div class="paper-points">• Framework shift-up
•  desarrollo nativo con GenAI
•  enfoque en actividades de alto valor
•  estudio preliminar</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24485" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">JSProtect: Framework de Ofuscación Escalable para Mini-Juegos en WeChat</h3>
                    <p class="paper-summary">📝 JSProtect es un framework de ofuscación de alto rendimiento para JavaScript que aborda problemas de escalabilidad en mini-juegos de WeChat. Utiliza análisis de alcance paralelo (PASA) para procesar código rápidamente manteniendo bajo crecimiento de tamaño.</p>
                    <div class="paper-points">• Ofuscación escalable
•  algoritmo PASA
•  procesamiento paralelo
•  control de inflación de código (20% vs 1000%)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24498" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">SemGuard: Corrección en Tiempo Real de Código Generado por LLMs</h3>
                    <p class="paper-summary">📝 SemGuard es un framework que supervisa semánticamente el código generado por LLMs en tiempo real. Interviene durante la decodificación para detectar y corregir errores semánticos sin necesidad de ejecutar tests, reduciendo errores en 19.86%.</p>
                    <div class="paper-points">• Supervisión semántica en tiempo real
•  dataset SemDiff
•  corrección durante decodificación
•  mejora Pass@1 en 48.92%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24507" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Generador Agéntico de Especificaciones para Programas Move</h3>
                    <p class="paper-summary">📝 MSG es una herramienta automatizada para generar especificaciones de contratos inteligentes en Move. Demuestra que los LLMs pueden comprender lenguajes no mainstream y genera especificaciones verificables para 84% de las funciones probadas.</p>
                    <div class="paper-points">• Generación de especificaciones para Move
•  diseño agéntico modular
•  84% de funciones cubiertas
•  mejora del 57% en cláusulas verificables</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24515" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Completado de Código Consciente de Instrucciones mediante Paradigma IFIM</h3>
                    <p class="paper-summary">📝 Se introduce IFIM, un método de fine-tuning que mejora la capacidad de los LLMs para seguir instrucciones en completado de código. Extiende el paradigma FIM tradicional incorporando secciones de instrucción explícitas.</p>
                    <div class="paper-points">• Paradigma IFIM
•  completado de código con instrucciones
•  mejora Pass@1 de 84.6% a 93.6%
•  preserva capacidades FIM originales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24637" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">⚙️ CoTune: Sintonización de Configuraciones mediante Co-evolución</h3>
                    <p class="paper-summary">📝 CoTune es una herramienta que optimiza configuraciones de sistemas considerando requisitos de rendimiento complejos mediante co-evolución. Crea requisitos auxiliares que guían la optimización siendo robustos a requisitos mal definidos.</p>
                    <div class="paper-points">• Sintonización co-evolutiva
•  manejo de requisitos complejos
•  mejor eficiencia
•  mejor rendimiento en 90% de casos (hasta 2.9x)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24694" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Modelos de lenguaje grandes para modelado conductual: Una revisión bibliográfica</h3>
                    <p class="paper-summary">📝 Revisión de investigaciones sobre el uso de LLMs para modelado conductual, especialmente diagramas de casos de uso y secuencia. Analiza 14 estudios que muestran resultados prometedores en generación automática. Identifica falta de evaluaciones expertas y predominio de modelos GPT.</p>
                    <div class="paper-points">• 14 estudios analizados
•  enfoque en diagramas UML
•  resultados prometedores pero limitaciones en evaluación
•  necesidad de más variedad de LLMs</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24782" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Evaluación de SAP Joule para Generación de Código</h3>
                    <p class="paper-summary">📝 Evaluación comparativa de SAP Joule contra 29 modelos en generación de código JavaScript usando el benchmark HumanEval-X. Joule alcanza 80.49% de precisión, posicionándose como quinto mejor modelo. Primera evaluación comparativa pública de SAP Joule.</p>
                    <div class="paper-points">• Comparación con 29 modelos
•  80.49% precisión en JavaScript
•  quinto lugar en ranking
•  primera evaluación pública</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24828" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">DiffTester: Aceleración de Generación de Pruebas Unitarias para LLMs de Difusión mediante Patrones Repetitivos</h3>
                    <p class="paper-summary">📝 Framework que acelera la generación de pruebas unitarias usando LLMs de difusión. Identifica patrones estructurales repetitivos mediante análisis de árboles sintácticos para generar múltiples tokens simultáneamente. Mantiene cobertura mientras mejora eficiencia.</p>
                    <div class="paper-points">• Aceleración de generación de pruebas
•  uso de patrones AST
•  extensión de TestEval a Java y C++
•  preservación de cobertura</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24975" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Modelos de Lenguaje Grandes para Pruebas de Software: Una Hoja de Ruta de Investigación</h3>
                    <p class="paper-summary">📝 Revisión semi-sistemática que mapea el estado actual y tendencias en pruebas de software basadas en LLMs. Agrupa contribuciones en categorías, identifica desafíos y direcciones futuras. Analiza impacto a largo plazo en el campo de testing.</p>
                    <div class="paper-points">• Revisión literatura LLM en testing
•  categorización contribuciones
•  identificación desafíos abiertos
•  análisis impacto futuro</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25043" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔧</span>
                    <h3 class="paper-title">Hacia la Generación Confiable de Flujos de Trabajo Ejecutables por Modelos Fundacionales</h3>
                    <p class="paper-summary">📝 Framework que usa análisis estático para detectar y reparar defectos en flujos de trabajo generados por FMs. Taxonomía de 18 tipos de defectos, con 87.27% de instancias conteniendo al menos un defecto. Timon (analizador) y Pumbaa (reparador) mejoran confiabilidad.</p>
                    <div class="paper-points">• 18 tipos de defectos identificados
•  87.27% instancias con defectos
•  framework detección/reparación
•  mejora confiabilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.25117" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ingeniería Computacional, Finanzas y Ciencia">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Ingeniería Computacional, Finanzas y Ciencia</h2>
                <span class="category-count">4</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Aprendizaje de Representaciones por Canal, Tendencia y Periodicidad para Pronóstico de Series de Tiempo Multivariadas a Largo Plazo</h3>
                    <p class="paper-summary">📝 Propuesta de CTPNet, framework que aprende representaciones desde tres perspectivas: dependencias entre canales, variaciones de tendencia intra-subsecuencia y patrones periódicos globales. Mecanismo de atención multi-cabeza basado en consultas temporales.</p>
                    <div class="paper-points">• Tres perspectivas de aprendizaje
•  atención multi-cabeza temporal
•  captura patrones periódicos
•  experimentos extensivos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23583" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🏗</span>
                    <h3 class="paper-title">️ Generación de Texto a Código para Diseños de Edificios Modulares en Modelado de Información de Construcción</h3>
                    <p class="paper-summary">📝 Text2MBL genera código BIM ejecutable desde descripciones textuales de diseños modulares. Estructura jerárquica de tres niveles: módulos, unidades y habitaciones. Fine-tuning de LLMs para secuencias de acciones en formato código. Dataset de proyectos reales.</p>
                    <div class="paper-points">• Generación código BIM paramétrico
•  estructura tres niveles
•  fine-tuning LLMs
•  evaluación métricas múltiples</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23713" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🔒</span>
                    <h3 class="paper-title">Framework Híbrido DNN-Transformer-AE para Supervisión de Riesgo Fiscal Corporativo y Evaluación de Niveles</h3>
                    <p class="paper-summary">📝 Framework híbrido que combina DNN (atributos estáticos), Transformer (dependencias temporales) y Autoencoder (detección anomalías) para riesgo fiscal. Fusión genera puntaje de riesgo mapeado a niveles alto/medio/bajo. 91% accuracy en dataset real.</p>
                    <div class="paper-points">• Tres módulos complementarios
•  91% accuracy
•  0.88 F1-score
•  aplicación práctica regulación fiscal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23862" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🚇</span>
                    <h3 class="paper-title">Identificación de la Jerarquía Multimodal de Sistemas de Tránsito Público Usando Datos de Cadenas de Viaje</h3>
                    <p class="paper-summary">📝 Introduce concepto de jerarquía multimodal macroscópica donde viajes siguen orden &#x27;ascendente-descendente&#x27;. Metodología usando datos de tarjetas inteligentes multimodales. Demostración con datos de Seúl y área metropolitana coreana.</p>
                    <div class="paper-points">• Jerarquía ascendente-descendente
•  análisis multimodal
•  datos tarjetas inteligentes
•  caso estudio Seúl</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24220" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje por Refuerzo">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje por Refuerzo</h2>
                <span class="category-count">3</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">STAIR: Abordando el Desalineamiento de Etapas mediante Aprendizaje por Refuerzo de Preferencias Temporalmente Alineadas</h3>
                    <p class="paper-summary">📝 Propone STAIR para resolver el problema de desalineamiento de etapas en tareas multi-etapa del aprendizaje por refuerzo basado en preferencias. Utiliza distancia temporal aprendida mediante contraste para agrupar estados en etapas coherentes y prioriza comparaciones dentro de la misma etapa, mejorando significativamente el aprendizaje de políticas.</p>
                    <div class="paper-points">• Desalineamiento de etapas en PbRL
•  Aprendizaje de distancia temporal por contraste
•  Agrupamiento temporal sin conocimiento previo
•  Mejor rendimiento en tareas multi-etapa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23802" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Más Allá del Compromiso Exploración-Explotación: Un Enfoque de Estado Oculto para el Razonamiento de LLM en RLVR</h3>
                    <p class="paper-summary">📝 Propone VERL, un método que desacopla exploración y explotación en el espacio de estados ocultos usando Effective Rank y sus derivadas. Logra mejoras de hasta 21.4% en precisión al optimizar simultáneamente ambas capacidades sin forzar un compromiso.</p>
                    <div class="paper-points">• Desacoplamiento exploración-explotación
•  Effective Rank y derivadas
•  VERL con ventaja dual
•  21.4% mejora en Gaokao 2024</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23808" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">🤖</span>
                    <h3 class="paper-title">Entrenamiento RL Decoplado Eficiente para Agentes GUI mediante Entrenamiento Desacoplado y Curación Adaptativa de Datos</h3>
                    <p class="paper-summary">📝 Propone DART, un framework de entrenamiento RL desacoplado para agentes GUI que mejora significativamente la eficiencia del sistema mediante módulos asíncronos. Incluye un esquema de curación adaptativa de datos que ajusta dinámicamente las trayectorias según la dificultad de la tarea. Logra un 42.13% de éxito en OSWorld, superando el estado del arte en 7.34%.</p>
                    <div class="paper-points">• Arquitectura desacoplada asíncrona
•  Curación adaptativa de datos
•  5.5x mejor utilización del entorno
•  14.61% de mejora sobre el modelo base</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23866" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje Federado">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje Federado</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🏥</span>
                    <h3 class="paper-title">FedAgentBench: Hacia la Automatización del Análisis de Imágenes Médicas Federadas con Agentes LLM Servidor-Cliente</h3>
                    <p class="paper-summary">📝 Introduce un marco basado en agentes LLM para automatizar el aprendizaje federado en entornos médicos, abordando desafíos operativos como selección de clientes, preprocesamiento y armonización de datos. Incluye 40 algoritmos FL y evalúa 24 modelos LLM en 201 conjuntos de datos médicos.</p>
                    <div class="paper-points">• Automatización de FL médico
•  Agentes LLM servidor-cliente
•  40 algoritmos FL
•  201 datasets médicos
•  Evaluación de 24 modelos LLM</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23803" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Optimización de Modelos">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Optimización de Modelos</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">💻</span>
                    <h3 class="paper-title">Tequila: Cuantización Ternaria sin Atrapamiento para Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">📝 Presenta Tequila, un método de cuantización ternaria que evita el atrapamiento en zona muerta mediante la reconversión de pesos atrapados como sesgos dinámicos. Logra un 3.0x de aceleración con menos del 1% de pérdida de precisión respecto a modelos de precisión completa.</p>
                    <div class="paper-points">• Cuantización ternaria {-1
• 0
• 1}
•  Solución a atrapamiento en zona muerta
•  Sesgos dinámicos
•  3.0x aceleración
•  &lt
• 1% gap de precisión</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23809" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Series Temporales">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Series Temporales</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">IndexNet: Modelado Consciente de Marcas de Tiempo y Variables para Pronóstico de Series Temporales</h3>
                    <p class="paper-summary">📝 Propone IndexNet, un framework MLP que incorpora información contextual mediante embeddings de marcas de tiempo y variables. Captura patrones periódicos complejos y distingue entre variables heterogéneas, mejorando la generalización e interpretabilidad en pronósticos multivariados.</p>
                    <div class="paper-points">• Embeddings de timestamp y variables
•  Arquitectura MLP ligera
•  Captura de patrones periódicos
•  Mejor generalización e interpretabilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23813" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Redes Neuronales de Grafos">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Redes Neuronales de Grafos</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Evaluación de Modelos GNN en Tiempo de Prueba para Grafos Dinámicos</h3>
                    <p class="paper-summary">📝 Introduce DyGEval, un evaluador para redes neuronales de grafos dinámicos que estima el rendimiento en grafos de prueba no vistos. Utiliza un marco de dos etapas que simula diferencias distribucionales y entrena un evaluador para predecir el desempeño del modelo.</p>
                    <div class="paper-points">• Evaluación de DGNNs en test-time
•  Simulación de diferencias distribucionales
•  Marco de dos etapas
•  Robustez ante cambios distribucionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23816" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Generación de Estructuras">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Generación de Estructuras</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🧊 Space Group Conditional Flow Matching</h3>
                    <p class="paper-summary">📝 Propone un framework generativo para cristales que condiciona en grupos espaciales y posiciones de Wyckoff, garantizando simetrías cristalográficas. Logra state-of-the-art en predicción y generación de estructuras cristalinas con overhead computacional negligible.</p>
                    <div class="paper-points">• Generación de cristales simétricos
•  Condicionamiento en grupos espaciales
•  Posiciones de Wyckoff
•  Equivariancia eficiente
•  State-of-the-art en benchmarks</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23822" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Generación de Datos">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Generación de Datos</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">⚡</span>
                    <h3 class="paper-title">Generación de Datos Discretos mediante Corrientes Eléctricas</h3>
                    <p class="paper-summary">📝 Presenta ECD²G, un método novedoso que analogiza el flujo de corriente eléctrica con la transferencia de masa probabilística entre distribuciones. Usa redes neuronales para aprender corrientes que representan flujos de probabilidad y garantiza transferencia entre distribuciones.</p>
                    <div class="paper-points">• Analogía con circuitos eléctricos
•  Flujo de probabilidad como corriente
•  Transferencia garantizada entre distribuciones
•  Experimentos proof-of-concept</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23825" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Incertidumbre en LLMs">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Incertidumbre en LLMs</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Mezcla Bayesiana de Expertos: Haciendo que los LLM Sepan lo que No Saben</h3>
                    <p class="paper-summary">📝 Propone un framework bayesiano para el routing en Mixture-of-Experts que modela distribuciones de probabilidad sobre decisiones de routing. Mejora significativamente la calibración, detección fuera de distribución y estabilidad del routing en modelos MoE.</p>
                    <div class="paper-points">• Routing bayesiano en MoE
•  Mejora de calibración y detección OoD
•  Tres familias de métodos
•  Mayor conciencia de incertidumbre</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23830" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="RL Robusto">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">RL Robusto</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🛡️ Difusión Adversaria para Aprendizaje por Refuerzo Robusto</h3>
                    <p class="paper-summary">📝 Introduce AD-RRL, que utiliza modelos de difusión para entrenar políticas RL robustas generando trayectorias de peor caso durante el entrenamiento. Optimiza el CVaR del retorno acumulado y supera métodos existentes en robustez y rendimiento.</p>
                    <div class="paper-points">• Modelos de difusión para RL robusto
•  Generación de trayectorias adversarias
•  Optimización de CVaR
•  Superior a métodos existentes
•  Mitiga errores de modelado</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23846" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje Automático Teórico">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje Automático Teórico</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🧠</span>
                    <h3 class="paper-title">Hacia la Comprensión del Aprendizaje Subliminal: Cuándo y Cómo se Transfieren los Sesgos Ocultos</h3>
                    <p class="paper-summary">📝 Investiga cómo los modelos de lenguaje transfieren sesgos ocultos durante la destilación, incluso con datos numéricos. Identifica que los &#x27;tokens de divergencia&#x27; son clave para esta transferencia subliminal. Demuestra que el aprendizaje subliminal es frágil y puede suprimirse con pequeñas modificaciones como parafrasear prompts.</p>
                    <div class="paper-points">• Transferencia de sesgos en destilación
•  Tokens de divergencia críticos
•  Capas tempranas suficientes
•  Fragilidad del aprendizaje subliminal</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23886" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Teoría del Aprendizaje Profundo">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Teoría del Aprendizaje Profundo</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📊</span>
                    <h3 class="paper-title">Garantía de Convergencia del Flujo de Gradiente para Arquitecturas Generales de Redes Neuronales</h3>
                    <p class="paper-summary">📝 Presenta una prueba unificada de convergencia lineal del descenso de gradiente continuo para cualquier red neuronal con activaciones polinomiales por partes o ReLU/sigmoid. El teorema general cubre arquitecturas previamente no estudiadas y consolida resultados existentes bajo suposiciones más débiles.</p>
                    <div class="paper-points">• Teorema unificado de convergencia
•  Activaciones polinomiales y ReLU/sigmoid
•  Resultados empíricos consistentes
•  Suposiciones más débiles</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23887" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje Continuo">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje Continuo</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🔄 Fine-tuning Continuo Ortogonal Dinámico para Mitigar el Olvido Catastrófico</h3>
                    <p class="paper-summary">📝 Propone DOC fine-tuning, un método que rastrea la deriva de direcciones funcionales durante el fine-tuning secuencial de LLMs. Ajusta los gradientes para que sean ortogonales a las direcciones históricas, reduciendo la interferencia entre tareas. Supera métodos anteriores en benchmarks de aprendizaje continuo.</p>
                    <div class="paper-points">• Seguimiento de deriva funcional
•  Ortogonalidad de gradientes
•  Reducción de interferencia
•  Efectivo en aprendizaje continuo a largo plazo</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23893" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Optimización de Redes Neuronales">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Optimización de Redes Neuronales</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🎯</span>
                    <h3 class="paper-title">Esparsidad Diferenciable mediante Compuertas DD</h3>
                    <p class="paper-summary">📝 Introduce DD-Gating, un método completamente diferenciable para esparsidad estructurada que divide los pesos en vectores principales y factores de compuerta. Demuestra equivalencia teórica con la penalización L_{2,2/D} y convergencia exponencial. Supera métodos de poda convencionales en múltiples tareas.</p>
                    <div class="paper-points">• Esparsidad estructurada diferenciable
•  Equivalencia con penalización L_{2
• 2/D}
•  Convergencia exponencial
•  Mejor equilibrio rendimiento-esparsidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23898" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje por Refuerzo Multi-Agente">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje por Refuerzo Multi-Agente</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🚁 Comunicación y Control Integrados para Enjambres de UAV Eficientes: Enfoque de Aprendizaje por Refuerzo Multi-Agente</h3>
                    <p class="paper-summary">📝 Propone un mecanismo co-diseñado de comunicación y control para enjambres de UAV en entornos complejos. Formula el problema como MDP y desarrolla MAHPPO-AM para optimizar políticas con espacios de acción híbridos. Logra 0.99 de equidad y reduce 25% el consumo energético.</p>
                    <div class="paper-points">• Co-diseño comunicación-control
•  Algoritmo MAHPPO-AM
•  Enmascaramiento de acciones
•  25% ahorro energético con alta equidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23905" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Aprendizaje en Grafos">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Aprendizaje en Grafos</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">📈 Redes Aditivas de Mezcla de Grafos</h3>
                    <p class="paper-summary">📝 Presenta GMAN, un framework interpretable y expresivo que extiende GNANs para aprender de series temporales escasas. Representa trayectorias como grafos dirigidos y ofrece interpretabilidad a múltiples niveles. Supera modelos black-box en predicción de mortalidad y detección de fake news.</p>
                    <div class="paper-points">• Framework interpretable para series temporales
•  Representación gráfica de trayectorias
•  Control trade-off interpretabilidad-expresividad
•  Explicaciones accionables</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23923" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Optimización de Inferencia">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Optimización de Inferencia</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">👁️ Ocultando Tokens Visuales del Drafter para Decodificación Especulativa en Modelos Visión-Lenguaje</h3>
                    <p class="paper-summary">📝 Introduce HiViS, un framework que elimina tokens visuales del input del drafter en VLMs, reutilizando estados ocultos del modelo objetivo. Reduce la longitud de prefill a 0.7%-1.3% y mantiene calidad sin pérdidas. Logra hasta 2.65x de aceleración en inferencia.</p>
                    <div class="paper-points">• Eliminación de tokens visuales del drafter
•  Reutilización de estados ocultos
•  Entrenamiento con auto-retroalimentación
•  2.65x aceleración sin pérdida de calidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23928" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Análisis de Arquitecturas">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Análisis de Arquitecturas</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">🔍</span>
                    <h3 class="paper-title">Más Allá de los Benchmarks: Entendiendo Modelos Mixture-of-Experts mediante Mecanismos Internos</h3>
                    <p class="paper-summary">📝 Investiga mecanismos internos de modelos MoE mediante métricas de utilización. Descubre que la utilización de neuronas disminuye con modelos más evolucionados, el entrenamiento sigue trayectorias dinámicas, y las tareas emergen de colaboración entre expertos. MUI revela insights más profundos que benchmarks.</p>
                    <div class="paper-points">• Métrica MUI para análisis interno
•  Disminución de utilización en modelos evolucionados
•  Colaboración entre expertos
•  Patrones de activación como proxy de diversidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23933" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Teoría de Modelos de Difusión">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Teoría de Modelos de Difusión</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🎰 Los Modelos de Difusión son Apostadores de Kelly</h3>
                    <p class="paper-summary">📝 Establece conexión entre modelos de difusión y el criterio de Kelly para maximizar retornos en apuestas. Los modelos almacenan información mutua entre X e Y, y la guía classifier-free aumenta esta información mutua durante el muestreo. Relaciona la pérdida de desruido con la Regla de Oro de Fermi.</p>
                    <div class="paper-points">• Conexión con criterio de Kelly
•  Información mutua X-Y
•  Guía classifier-free aumenta información mutua
•  Relación con Regla de Oro de Fermi</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.23937" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ciencia de Datos">
            <div class="category-header">
                <span style="font-size: 1.5rem;">📄</span>
                <h2 class="category-title">Ciencia de Datos</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">📄</span>
                    <h3 class="paper-title">🐟 AQUAIR: Dataset de Alta Resolución de Calidad Ambiental Interior para Acuicultura Inteligente</h3>
                    <p class="paper-summary">📝 Presenta dataset público que registra seis variables de calidad ambiental interior en instalación acuícola, con más de 23,000 observaciones cada 5 minutos. Incluye pipeline de procesamiento y estadísticas exploratorias.</p>
                    <div class="paper-points">• Dataset público para acuicultura
•  6 variables de calidad ambiental
•  Pipeline de procesamiento abierto</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2509.24069" class="paper-link" target="_blank" rel="noopener">
                            📖 Leer Paper
                        </a>
                        <span class="paper-date">2025-09-30</span>
                    </div>
                </article>

            </div>
        </section>

    </main>

    <footer class="footer">
        <p>🔬 Portal generado automáticamente desde arXiv • 30 de September de 2025</p>
        <p>Procesado por TagUI + DeepSeek AI</p>
    </footer>

    <button class="scroll-top" onclick="scrollToTop()">↑</button>

    <script>
        // Mostrar botón de scroll to top
        window.addEventListener('scroll', function() {
            const scrollTop = document.querySelector('.scroll-top');
            if (window.pageYOffset > 300) {
                scrollTop.classList.add('visible');
            } else {
                scrollTop.classList.remove('visible');
            }
        });

        // Función para scroll to top
        function scrollToTop() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        }

        // Animación de entrada para las tarjetas
        const observer = new IntersectionObserver((entries) => {
            entries.forEach((entry) => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        });

        document.querySelectorAll('.paper-card').forEach((card) => {
            card.style.opacity = '0';
            card.style.transform = 'translateY(20px)';
            card.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(card);
        });

        // Dropdown functionality
        const dropdown = document.getElementById('categoryDropdown');
        const dropdownToggle = dropdown.querySelector('.dropdown-toggle');
        const categories = document.querySelectorAll('.category');
        const papersCount = document.getElementById('papersCount');
        
        dropdownToggle.addEventListener('click', function() {
            dropdown.classList.toggle('open');
        });

        function filterByCategory(category) {
            const dropdownItems = document.querySelectorAll('.dropdown-item');
            dropdownItems.forEach(item => item.classList.remove('active'));
            event.target.classList.add('active');
            
            if (category === 'all') {
                categories.forEach(cat => cat.style.display = 'block');
                dropdownToggle.textContent = 'Filtrar por categoría';
                papersCount.textContent = `Mostrando 464 papers en 24 categorías`;
            } else {
                let visiblePapers = 0;
                categories.forEach(cat => {
                    if (cat.dataset.category === category) {
                        cat.style.display = 'block';
                        visiblePapers += cat.querySelectorAll('.paper-card').length;
                    } else {
                        cat.style.display = 'none';
                    }
                });
                dropdownToggle.textContent = category;
                papersCount.textContent = `Mostrando ${visiblePapers} papers en 1 categoría`;
            }
            dropdown.classList.remove('open');
        }

        // Close dropdown when clicking outside
        document.addEventListener('click', function(e) {
            if (!dropdown.contains(e.target)) {
                dropdown.classList.remove('open');
            }
        });
    </script>
</body>
</html>
