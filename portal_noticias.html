<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papper news</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0f0f0f 0%, #1a1a1a 100%);
            color: #ffffff;
            line-height: 1.6;
            min-height: 100vh;
        }
        
        .header {
            background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%);
            padding: 2rem 0;
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
            border-bottom: 2px solid #333;
        }
        
        .header-content {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            text-align: center;
        }
        
        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
            background-size: 400% 400%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: gradientShift 3s ease-in-out infinite;
            margin-bottom: 0.5rem;
        }
        
        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }
        
        .subtitle {
            font-size: 1.1rem;
            color: #b3b3b3;
            font-weight: 300;
        }
        
        .stats {
            margin: 1.5rem 0;
            display: flex;
            gap: 2rem;
            justify-content: center;
            flex-wrap: wrap;
        }
        
        .stat-item {
            background: rgba(255,255,255,0.1);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        .category {
            margin-bottom: 3rem;
        }
        
        .category-header {
            display: flex;
            align-items: center;
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #333;
        }
        
        .category-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #ffffff;
            margin-left: 0.5rem;
        }
        
        .category-count {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            padding: 0.25rem 0.75rem;
            border-radius: 15px;
            font-size: 0.9rem;
            font-weight: 600;
            margin-left: auto;
        }
        
        .papers-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 1.5rem;
        }
        
        .paper-card {
            background: linear-gradient(135deg, #1e1e1e 0%, #2a2a2a 100%);
            border-radius: 12px;
            padding: 1.5rem;
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            border: 1px solid rgba(255,255,255,0.1);
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        
        .paper-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
            background-size: 400% 400%;
            animation: gradientShift 3s ease-in-out infinite;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(0,0,0,0.4);
            border-color: rgba(255,255,255,0.2);
        }
        
        .paper-emoji {
            font-size: 2rem;
            margin-bottom: 1rem;
            display: block;
        }
        
        .paper-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: #ffffff;
            margin-bottom: 1rem;
            line-height: 1.4;
        }
        
        .paper-summary {
            color: #b3b3b3;
            margin-bottom: 1rem;
            font-size: 0.95rem;
            line-height: 1.5;
        }
        
        .paper-points {
            color: #d4d4d4;
            margin-bottom: 1.5rem;
            font-size: 0.9rem;
            background: rgba(0,0,0,0.3);
            padding: 1rem;
            border-radius: 8px;
            border-left: 3px solid #4ecdc4;
        }
        
        .paper-footer {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: auto;
        }
        
        .paper-link {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            text-decoration: none;
            padding: 0.6rem 1.2rem;
            border-radius: 25px;
            font-weight: 600;
            font-size: 0.9rem;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .paper-link:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(255,107,107,0.3);
        }
        
        .paper-date {
            color: #888;
            font-size: 0.8rem;
        }
        
        .footer {
            background: #1e1e1e;
            padding: 2rem;
            text-align: center;
            margin-top: 3rem;
            border-top: 2px solid #333;
        }
        
        .footer p {
            color: #b3b3b3;
        }
        
        /* Filter Section Layout */
        .filter-section {
            max-width: 1200px;
            margin: 0 auto;
            padding: 1rem 2rem;
        }
        
        /* Filter Dropdown Styles */
        .dropdown {
            position: relative;
            display: inline-block;
        }
        
        .dropdown-toggle {
            background: #2a2a2a;
            color: #ffffff;
            border: 1px solid #404040;
            padding: 8px 16px;
            font-size: 0.9rem;
            font-weight: 500;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .dropdown-toggle:hover {
            background: #3a3a3a;
            border-color: #505050;
        }
        
        .dropdown-toggle::after {
            content: "‚ñº";
            margin-left: 8px;
            font-size: 0.7rem;
            transition: transform 0.2s ease;
        }
        
        .dropdown.open .dropdown-toggle::after {
            transform: rotate(180deg);
        }
        
        .dropdown-menu {
            position: absolute;
            top: 100%;
            left: 0;
            min-width: 200px;
            background: #2a2a2a;
            border: 1px solid #404040;
            border-radius: 6px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.4);
            z-index: 1000;
            opacity: 0;
            visibility: hidden;
            transform: translateY(-8px);
            transition: all 0.2s ease;
            max-height: 250px;
            overflow-y: auto;
        }
        
        .dropdown.open .dropdown-menu {
            opacity: 1;
            visibility: visible;
            transform: translateY(0);
        }
        
        .dropdown-item {
            display: block;
            padding: 8px 12px;
            color: #ffffff;
            text-decoration: none;
            transition: background-color 0.2s ease;
            border: none;
            background: none;
            width: 100%;
            text-align: left;
            cursor: pointer;
            font-size: 0.9rem;
        }
        
        .dropdown-item:hover {
            background: #3a3a3a;
        }
        
        .dropdown-item.active {
            background: #3a3a3a;
            color: #ffffff;
        }
        
        .papers-count {
            margin: 0.5rem 0;
            color: #b3b3b3;
            font-size: 0.85rem;
            text-align: center;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .filter-section {
                text-align: center;
                padding: 1rem;
            }
            
            .stats {
                gap: 1rem;
                flex-wrap: wrap;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .papers-grid {
                grid-template-columns: 1fr;
            }
        }
        
        .scroll-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            font-size: 1.2rem;
            cursor: pointer;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            transition: all 0.3s ease;
            opacity: 0;
            visibility: hidden;
        }
        
        .scroll-top.visible {
            opacity: 1;
            visibility: visible;
        }
        
        .scroll-top:hover {
            transform: scale(1.1);
        }
    </style>
</head>
<body>
    <header class="header">
        <div class="header-content">
            <h1>üî¨ ArXiv Daily Portal</h1>
            <p class="subtitle">Portal de Noticias Cient√≠ficas - √öltimas Investigaciones</p>
            <div class="stats">
                <div class="stat-item">üìä 239 Papers</div>
                <div class="stat-item">üìÖ 09 de December de 2025</div>
                <div class="stat-item">üè∑Ô∏è 7 Categor√≠as</div>
            </div>

        </div>
    </header>

    <section class="filter-section">
        <div class="dropdown" id="categoryDropdown">
            <button class="dropdown-toggle">
                Filtrar por categor√≠a
            </button>
            <div class="dropdown-menu">
                <button class="dropdown-item" onclick="filterByCategory('all')">Mostrar todas</button>
                <button class="dropdown-item" onclick="filterByCategory('Aprendizaje Autom√°tico')">Aprendizaje Autom√°tico</button>
                <button class="dropdown-item" onclick="filterByCategory('Inteligencia Artificial')">Inteligencia Artificial</button>
                <button class="dropdown-item" onclick="filterByCategory('Ingenier√≠a de Software')">Ingenier√≠a de Software</button>
                <button class="dropdown-item" onclick="filterByCategory('Computadoras y Sociedad')">Computadoras y Sociedad</button>
                <button class="dropdown-item" onclick="filterByCategory('Ingenier√≠a Computacional, Finanzas y Ciencia')">Ingenier√≠a Computacional, Finanzas y Ciencia</button>
                <button class="dropdown-item" onclick="filterByCategory('Computaci√≥n Neuronal y Evolutiva')">Computaci√≥n Neuronal y Evolutiva</button>
                <button class="dropdown-item" onclick="filterByCategory('Ingenier√≠a del Software')">Ingenier√≠a del Software</button>
            </div>
        </div>
    </section>

    <main class="container">

        <section class="category" data-category="Aprendizaje Autom√°tico">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Aprendizaje Autom√°tico</h2>
                <span class="category-count">145</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Un laboratorio aut√≥nomo para pel√≠culas delgadas electrocr√≥micas procesadas en soluci√≥n</h3>
                    <p class="paper-summary">üìù Este estudio utiliza un laboratorio aut√≥nomo (self-driving lab) que combina automatizaci√≥n y aprendizaje autom√°tico para acelerar el desarrollo de recubrimientos electrocr√≥micos. El sistema integra adquisici√≥n autom√°tica de datos, procesamiento de im√°genes, an√°lisis espectral y optimizaci√≥n bayesiana para explorar eficientemente los par√°metros de procesado. Este enfoque aumenta el rendimiento y permite una b√∫squeda dirigida de par√°metros √≥ptimos, aplicable a diversos materiales procesados en soluci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Laboratorio aut√≥nomo para desarrollo acelerado. Combinaci√≥n de automatizaci√≥n y aprendizaje autom√°tico (optimizaci√≥n bayesiana). Aplicaci√≥n en materiales electrocr√≥micos para ventanas inteligentes y pantallas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05989" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Inferencia Amortizada en Memoria: Una Unificaci√≥n Topol√≥gica de B√∫squeda, Clausura y Estructura</h3>
                    <p class="paper-summary">üìù Se propone un marco te√≥rico (Inferencia Amortizada en Memoria) que unifica el aprendizaje y la memoria como transiciones de fase de un sustrato geom√©trico √∫nico, basado en topolog√≠a algebraica. El principio central es la dicotom√≠a homol√≥gica: la homolog√≠a par (H_even) instancia Contenido estable, y la impar (H_odd) instancia Contexto din√°mico. El marco modela la cognici√≥n como una transformaci√≥n trinitaria: B√∫squeda -&gt; Clausura -&gt; Estructura, explicando la emergencia del pensamiento r√°pido (intuici√≥n) desde el lento (razonamiento).</p>
                    <div class="paper-points">‚Ä¢ Marco te√≥rico unificador basado en topolog√≠a algebraica. Principio de Paridad Homol√≥gica para contenido/contexto. Explicaci√≥n de la cognici√≥n como transici√≥n de b√∫squeda compleja a consulta simple.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05990" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Reconocimiento y an√°lisis de Compuestos Org√°nicos Vol√°tiles mediante aprendizaje profundo basado en espectros de absorci√≥n infrarroja experimentales y sint√©ticos</h3>
                    <p class="paper-summary">üìù Se aborda la detecci√≥n de Compuestos Org√°nicos Vol√°tiles (COVs) peligrosos para la salud mediante espectroscop√≠a IR y redes neuronales profundas. Se crea un conjunto de datos experimental con espectros de absorci√≥n IR de nueve clases de COVs. Para mejorar el entrenamiento, se aumenta el dataset con espectros sint√©ticos generados por redes neuronales generativas condicionales. Las redes discriminativas entrenadas logran identificar los COVs y predecir sus concentraciones con precisi√≥n, siendo aptas para integrarse en dispositivos de detecci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Detecci√≥n de COVs usando espectroscop√≠a IR y aprendizaje profundo. Aumento de datos con espectros sint√©ticos generados por redes generativas. Redes neuronales capaces de identificar compuestos y predecir concentraciones.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06059" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Cuando lo Privado no es Sint√©tico: Filtraci√≥n Ocultada de Datos en Modelos Generativos de IA</h3>
                    <p class="paper-summary">üìù Se demuestra que los datos sint√©ticos generados para preservar la privacidad pueden filtrar informaci√≥n sobre los datos de entrenamiento originales, debido a superposiciones estructurales en el manifold de datos. Se propone un ataque de inferencia de membres√≠a en caja negra que explota esta vulnerabilidad mediante consultas repetidas al modelo, clustering no supervisado y an√°lisis de vecindarios de alta densidad. El ataque es efectivo incluso con mecanismos de privacidad diferencial, revelando una superficie de ataque subexplorada en la publicaci√≥n de datos sint√©ticos.</p>
                    <div class="paper-points">‚Ä¢ Ataque de inferencia de membres√≠a contra datos sint√©ticos generativos. Explota la superposici√≥n estructural en la distribuci√≥n de datos
‚Ä¢  no solo la memorizaci√≥n. Funciona incluso con privacidad diferencial
‚Ä¢  exigiendo garant√≠as m√°s fuertes.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06062" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üî• JaxWildfire: Un Simulador de Incendios Forestales Acelerado por GPU para Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">üìù Se presenta JaxWildfire, un simulador de propagaci√≥n de incendios forestales basado en un modelo probabil√≠stico de aut√≥matas celulares, implementado en JAX para aprovechar la vectorizaci√≥n y ejecuci√≥n en GPUs. El simulador logra una aceleraci√≥n de 6-35x sobre software existente y permite la optimizaci√≥n basada en gradientes de sus par√°metros. Se demuestra su utilidad para entrenar agentes de Aprendizaje por Refuerzo en la b√∫squeda de pol√≠ticas de supresi√≥n de incendios, facilitando avances en la gesti√≥n de riesgos naturales.</p>
                    <div class="paper-points">‚Ä¢ Simulador de incendios r√°pido (6-35x) gracias a JAX y GPUs. Basado en un modelo de aut√≥matas celulares probabil√≠stico. Habilita el entrenamiento eficiente de agentes de Aprendizaje por Refuerzo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06102" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üß© ARC-AGI Sin Preentrenamiento</h3>
                    <p class="paper-summary">üìù Se presenta CompressARC, un modelo de s√≥lo 76K par√°metros sin preentrenamiento que resuelve el 20% de los rompecabezas visuales del benchmark ARC-AGI. Su capacidad surge de minimizar la longitud de descripci√≥n (MDL) del rompecabezas objetivo exclusivamente durante la inferencia, entren√°ndose solo en ese mismo rompecabezas (con la soluci√≥n oculta). Este enfoque de m√°xima compresi√≥n otorga capacidades de generalizaci√≥n extremas, desafiando la creencia de que se requiere preentrenamiento masivo para este tipo de tareas de razonamiento abstracto.</p>
                    <div class="paper-points">‚Ä¢ Modelo peque√±o (76K params) que resuelve rompecabezas ARC-AGI sin preentrenamiento. Utiliza el principio de Minimizaci√≥n de la Longitud de Descripci√≥n (MDL) durante la inferencia. Entrenamiento extremadamente limitado (solo en el puzzle objetivo)
‚Ä¢  mostrando una v√≠a alternativa a la IA.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06104" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üöó Un Marco Prescriptivo para Determinar los D√≠as √ìptimos para Conteos de Tr√°fico de Corta Duraci√≥n</h3>
                    <p class="paper-summary">üìù Se propone un marco de aprendizaje autom√°tico para identificar los d√≠as m√°s representativos (√≥ptimos) para realizar conteos de tr√°fico de corta duraci√≥n, con el fin de mejorar la precisi√≥n en la estimaci√≥n del Promedio Anual de Tr√°fico Diario (AADT). Utilizando datos de Texas, el m√©todo supera a la pr√°ctica habitual al seleccionar iterativamente los d√≠as m√°s informativos. El mejor d√≠a identificado reduce significativamente los errores (RMSE, MAE, MAPE) y aumenta el R¬≤ en la predicci√≥n del AADT, ofreciendo a los departamentos de transporte una herramienta para reducir costos y mejorar la precisi√≥n.</p>
                    <div class="paper-points">‚Ä¢ Marco de ML para seleccionar d√≠as √≥ptimos para conteos cortos de tr√°fico. Mejora la estimaci√≥n del Promedio Anual de Tr√°fico Diario (AADT). Reduce errores de predicci√≥n y costos operativos para agencias de transporte.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06111" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">M√°quina Neural Koopman Informada por la F√≠sica para el Pron√≥stico Longitudinal Personalizado e Interpretable de la Enfermedad de Alzheimer</h3>
                    <p class="paper-summary">üìù Se presenta la M√°quina Neural Koopman (NKM), una arquitectura inspirada en sistemas din√°micos, para pronosticar de manera interpretable el deterioro cognitivo en Alzheimer usando datos multimodales (gen√©ticos, de neuroimagen, prote√≥micos). NKM transforma trayectorias no lineales complejas en representaciones lineales interpretables mediante el operador de Koopman y mecanismos de atenci√≥n jer√°rquica guiados por conocimiento anal√≠tico y biol√≥gico. Aplicado al dataset ADNI, NKM supera a otros m√©todos en la predicci√≥n de m√∫ltiples puntuaciones cognitivas e identifica biomarcadores y regiones cerebrales predictivas clave.</p>
                    <div class="paper-points">‚Ä¢ Modelo interpretable para pron√≥stico personalizado de Alzheimer usando datos multimodales. Combina el operador de Koopman con atenci√≥n jer√°rquica guiada por conocimiento. Identifica biomarcadores y regiones cerebrales relevantes para el deterioro cognitivo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06134" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">gp2Scale: Una Clase de Kernels no Estacionarios de Soporte Compacto y Computaci√≥n Distribuida para Procesos Gaussianos Exactos en 10 Millones de Puntos de Datos</h3>
                    <p class="paper-summary">üìù Se propone gp2Scale, una metodolog√≠a para escalar Procesos Gaussianos (GP) exactos a m√°s de 10 millones de puntos de datos sin usar aproximaciones basadas en puntos inductivos o interpolaci√≥n. El m√©todo explota el dise√±o del kernel: utiliza kernels no estacionarios de soporte compacto y alta flexibilidad para inducir una estructura de covarianza naturalmente dispersa. Esta estructura es aprovechada para c√°lculos eficientes, manteniendo la exactitud y permitiendo total personalizaci√≥n del GP (kernel, funci√≥n de media, ruido), lo que lo hace ideal para aplicaciones modernas.</p>
                    <div class="paper-points">‚Ä¢ Escala GPs exactos a &gt
‚Ä¢ 10M puntos sin aproximaciones inductivas. Utiliza kernels no estacionarios de soporte compacto para inducir esparcidad natural. Mantiene la flexibilidad y personalizaci√≥n total del modelo de GP.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06143" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ Aprendizaje de Representaciones de Grafos Invariantes a trav√©s de Informaci√≥n Redundante</h3>
                    <p class="paper-summary">üìù Para mejorar la generalizaci√≥n fuera de distribuci√≥n (OOD) en grafos, se introduce un marco que utiliza la Descomposici√≥n de Informaci√≥n Parcial (PID), una herramienta de teor√≠a de la informaci√≥n. Este marco, llamado Aprendizaje de Grafos Invariantes Guiado por Redundancia (RIG), identifica y maximiza la informaci√≥n redundante sobre la etiqueta compartida entre subgrafos causales y espurios, mientras los a√≠sla. A trav√©s de una optimizaci√≥n multi-nivel, RIG aprende representaciones invariantes que generalizan mejor bajo diversos cambios de distribuci√≥n en datos sint√©ticos y del mundo real.</p>
                    <div class="paper-points">‚Ä¢ Utiliza Descomposici√≥n de Informaci√≥n Parcial (PID) para aprendizaje invariante en grafos. Marco RIG maximiza informaci√≥n redundante y a√≠sla componentes causales/espurios. Mejora la generalizaci√≥n fuera de distribuci√≥n (OOD) en tareas con grafos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06154" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üöó PMA-Difusi√≥n: Un Marco de Difusi√≥n Consciente de M√°scaras y Guiado por F√≠sica para TSE a partir de Observaciones Dispersas</h3>
                    <p class="paper-summary">üìù Se propone un marco de difusi√≥n guiado por f√≠sica para reconstruir campos de velocidad de tr√°fico en autopistas a partir de observaciones dispersas y ruidosas. El m√©todo entrena un modelo de difusi√≥n directamente sobre campos observados de forma discontinua, utilizando estrategias conscientes de m√°scaras. Un muestreador posterior guiado por f√≠sica reconstruye los datos faltantes mediante suavizado anisotr√≥pico adaptativo.</p>
                    <div class="paper-points">‚Ä¢ Reconstrucci√≥n de estados de tr√°fico bajo alta dispersi√≥n (5% de visibilidad). Combina un modelo de difusi√≥n consciente de m√°scaras con un muestreador posterior basado en f√≠sica. Supera a otros m√©todos en m√©tricas de error de reconstrucci√≥n en el conjunto de datos I-24 MOTION.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06183" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîç</span>
                    <h3 class="paper-title">¬øC√≥mo Deber√≠amos Evaluar la Eliminaci√≥n de Datos en √çndices ANN Basados en Grafos?</h3>
                    <p class="paper-summary">üìù Propone un marco experimental y m√©tricas exhaustivas para evaluar la eficiencia de la eliminaci√≥n de datos en √≠ndices de B√∫squeda de Vecinos Aproximados (ANNS) basados en grafos. Categoriza los m√©todos de eliminaci√≥n en tres enfoques y los formaliza matem√°ticamente. El rendimiento se eval√∫a en precisi√≥n, velocidad de consulta y m√©tricas relevantes.</p>
                    <div class="paper-points">‚Ä¢ Primer marco integral para evaluar eliminaci√≥n de datos en ANNS din√°micos. Formalizaci√≥n matem√°tica de tres enfoques de eliminaci√≥n. Introduce &#x27
‚Ä¢ Deletion Control&#x27
‚Ä¢ 
‚Ä¢  un m√©todo para seleccionar din√°micamente la t√©cnica de eliminaci√≥n seg√∫n la precisi√≥n requerida.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06200" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">K2-V2: Un LLM Abierto de 360¬∞ y Mejorado para Razonamiento</h3>
                    <p class="paper-summary">üìù Se presenta K2-V2, un modelo de lenguaje grande (LLM) de c√≥digo abierto construido desde cero, dise√±ado como una base superior para tareas de razonamiento, conversaci√≥n y recuperaci√≥n de conocimiento. Activamente infunde conocimiento de dominio, razonamiento, contexto largo y uso de herramientas durante el entrenamiento. Se liberan los pesos, datos de entrenamiento e historial completo.</p>
                    <div class="paper-points">‚Ä¢ Modelo 100% abierto y transparente
‚Ä¢  rivaliza con l√≠deres de su clase (ej. Qwen2.5-72B). Entrenamiento expl√≠citamente preparado para razonamiento complejo. Liberaci√≥n completa de artefactos (LLM360) para facilitar la investigaci√≥n y el entrenamiento continuo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06201" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Cuantificaci√≥n del Uso de la Memoria en Aprendizaje por Refuerzo con Rango Temporal</h3>
                    <p class="paper-summary">üìù Introduce &#x27;Rango Temporal&#x27;, una m√©trica independiente del modelo que cuantifica cu√°nto usa una pol√≠tica de RL sus observaciones pasadas. Se calcula mediante diferenciaci√≥n autom√°tica inversa sobre la sensibilidad de las salidas a las entradas en una ventana temporal. El rango se correlaciona con la ventana de historia m√≠nima necesaria para un rendimiento √≥ptimo.</p>
                    <div class="paper-points">‚Ä¢ M√©trica nueva y pr√°ctica para medir la dependencia de la memoria en agentes de RL. Se caracteriza axiom√°ticamente en entornos lineales. Funciona en diversas arquitecturas (MLP
‚Ä¢  RNN
‚Ä¢  SSM) y tareas (POPGym
‚Ä¢  Copy-k).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06204" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üìà Aprendizaje por Refuerzo de Recompensa Promedio en Procesos de Decisi√≥n Semi-Markov mediante Iteraci√≥n de Valor Relativo</h3>
                    <p class="paper-summary">üìù Aplica resultados recientes de aproximaci√≥n estoc√°stica as√≠ncrona al aprendizaje por refuerzo en Procesos de Decisi√≥n Semi-Markov (SMDPs) de recompensa promedio. Establece la convergencia de una versi√≥n as√≠ncrona del algoritmo RVI Q-learning (Iteraci√≥n de Valor Relativo). Introduce condiciones de monotonicidad para estimar la tasa de recompensa √≥ptima.</p>
                    <div class="paper-points">‚Ä¢ Demuestra convergencia casi segura a un conjunto de soluciones de la ecuaci√≥n de optimalidad de recompensa promedio. Ampl√≠a el marco algor√≠tmico previo con nuevas condiciones de monotonicidad. An√°lisis para SMDPs de espacios finitos y d√©bilmente comunicantes.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06218" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ De Vuelta a la Consola del Autor: Empoderando GNNs para Adaptaci√≥n de Dominio mediante Desruido del Grafo Objetivo</h3>
                    <p class="paper-summary">üìù Explora la clasificaci√≥n de nodos en adaptaci√≥n de dominio de grafos. Propone GraphDeT, un marco que mejora la generalizaci√≥n de Redes Neuronales de Grafos (GNNs) en grafos objetivo mediante una tarea auxiliar de desruido de bordes. El an√°lisis te√≥rico conecta esta tarea con un l√≠mite de generalizaci√≥n basado en la distancia -.</p>
                    <div class="paper-points">‚Ä¢ Tarea auxiliar simple de desruido de bordes mejora dr√°sticamente el rendimiento en el dominio objetivo. El marco maneja cambios de dominio temporales y regionales. Supera a los m√©todos baselines existentes en experimentos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06236" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîì Puntos Ciegos de la Cuantizaci√≥n: C√≥mo la Compresi√≥n de Modelos Rompe las Defensas Contra Puertas Traseras</h3>
                    <p class="paper-summary">üìù Estudia emp√≠ricamente c√≥mo se comportan las defensas contra puertas traseras (backdoors) tras la cuantizaci√≥n post-entrenamiento, pr√°ctica est√°ndar en despliegues reales. La cuantizaci√≥n a INT8 reduce la tasa de detecci√≥n de 5 defensas evaluadas a 0%, mientras que el √©xito del ataque se mantiene &gt;99%. Expone una desconexi√≥n cr√≠tica entre la evaluaci√≥n (FP32) y el despliegue (modelos cuantizados).</p>
                    <div class="paper-points">‚Ä¢ La cuantizaci√≥n INT8 neutraliza completamente las defensas evaluadas. Los backdoors sobreviven a la cuantizaci√≥n con alta efectividad. La robustez a la cuantizaci√≥n debe ser un eje crucial en el dise√±o futuro de defensas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06243" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üß≠ Auto-exploraci√≥n para Aprendizaje por Refuerzo en L√≠nea</h3>
                    <p class="paper-summary">üìù Introduce m√©todos de &#x27;auto-exploraci√≥n&#x27; que exploran autom√°ticamente los espacios de estado y acci√≥n sin conocimiento previo de par√°metros dependientes del problema. Presenta variantes para entornos tabulares y con aproximaci√≥n lineal. Logran una complejidad muestral O(Œµ‚Åª¬≤) sin par√°metros arbitrariamente grandes.</p>
                    <div class="paper-points">‚Ä¢ M√©todos libres de par√°metros que no requieren conocimiento a priori. Logran complejidades muestrales novedosas sin par√°metros dependientes del algoritmo. Innovaciones incluyen un tiempo de mezcla din√°mico y un estimador de gradiente robusto.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06244" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">ü§î Aprendiendo Cu√°ndo Cambiar: Selecci√≥n de Pol√≠ticas Adaptativa mediante Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">üìù Introduce una t√©cnica de RL para aprender umbrales de cambio entre dos pol√≠ticas de navegaci√≥n ortogonales: exploraci√≥n sistem√°tica y b√∫squeda de caminos dirigida a un objetivo. Usa Q-learning para adaptar din√°micamente el comportamiento de cambio bas√°ndose en la cobertura y distancia al objetivo, sin conocimiento previo de la estructura del laberinto.</p>
                    <div class="paper-points">‚Ä¢ El agente adaptativo supera a agentes de estrategia √∫nica y umbrales fijos. Mejoras del 23-55% en tiempo de finalizaci√≥n y 83% en reducci√≥n de varianza. La generalizaci√≥n del comportamiento aprendido se mantiene en configuraciones de laberinto no vistas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06250" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprendizaje Sin Reinicios de Encarnaci√≥n Basados en Tiempo en Soft-Actor Critic</h3>
                    <p class="paper-summary">üìù Explora los desaf√≠os de aprender sin terminaci√≥n de episodios y sin reinicios de la encarnaci√≥n del robot usando SAC. Presenta una versi√≥n continua de SAC que iguala o supera a la versi√≥n epis√≥dica. Identifica que los reinicios ayudan a la exploraci√≥n y propone aumentar la entrop√≠a de la pol√≠tica para mitigar su ausencia.</p>
                    <div class="paper-points">‚Ä¢ Versi√≥n continua de SAC con modificaciones simples en la funci√≥n de recompensa. Los reinicios de encarnaci√≥n son cr√≠ticos para una exploraci√≥n efectiva en SAC. Aumentar la entrop√≠a de la pol√≠tica recupera el rendimiento perdido al no usar reinicios.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06252" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">M√∫ltiples Bandidos Inquietos en Red con Aprendizaje por Refuerzo</h3>
                    <p class="paper-summary">üìù Introduce M√∫ltiples Bandidos Inquietos en Red (Networked RMAB), un nuevo marco que integra el modelo RMAB con el modelo de cascada independiente para capturar interacciones entre &#x27;brazos&#x27; en entornos en red. Se aborda el desaf√≠o computacional del espacio exponencial de estados/acciones mediante la submodularidad de la ecuaci√≥n de Bellman y un algoritmo de escalada que garantiza una aproximaci√≥n 1-1/e. Se desarrolla y valida un algoritmo eficiente de Q-learning que supera a los enfoques ciegos a la red.</p>
                    <div class="paper-points">‚Ä¢ Nuevo marco Networked RMAB que modela interacciones entre individuos. Demostraci√≥n de submodularidad para aproximaci√≥n garantizada. Algoritmo de Q-learning supera enfoques que ignoran la red.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06274" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">L√≠mites de Compresi√≥n Te√≥rica para Perceptrones Multicapa Anch√≥s</h3>
                    <p class="paper-summary">üìù Proporciona justificaci√≥n te√≥rica para el √©xito emp√≠rico de la poda y cuantizaci√≥n en redes neuronales anchas. Demuestra rigurosamente la existencia de subredes podadas/cuantizadas con rendimiento competitivo en Perceptrones Multicapa (MLPs). El an√°lisis se extiende a la poda estructurada de MLPs y CNNs, mostrando una compensaci√≥n entre compresibilidad y anchura de la red.</p>
                    <div class="paper-points">‚Ä¢ Justificaci√≥n te√≥rica para la poda y cuantizaci√≥n post-entrenamiento. Demuestra existencia de subredes comprimidas de alto rendimiento. An√°lisis unificado libre de supuestos sobre los datos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06288" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Modelado de Temas Consciente de la Importancia para Descubrir Riesgos en el Transporte P√∫blico desde Redes Sociales Ruidosas</h3>
                    <p class="paper-summary">üìù Propone un marco para extraer se√±ales de riesgo (congesti√≥n, retrasos) de flujos ruidosos de redes sociales, modelando conjuntamente interacciones ling√º√≠sticas e influencia del usuario. El n√∫cleo es una Factorizaci√≥n de Deconvoluci√≥n de Poisson (PDF) que descompone un grafo ponderado por influencia en una estructura tem√°tica de bajo rango. El modelo logra alta coherencia y diversidad tem√°tica en flujos de datos a gran escala.</p>
                    <div class="paper-points">‚Ä¢ Detecci√≥n de riesgos en transporte p√∫blico desde redes sociales ruidosas. Modelo PDF que combina grafo de co-ocurrencia e influencia del usuario. Logra estado del arte en coherencia y diversidad de temas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06293" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Confinamiento Entr√≥pico y Conectividad de Modos en Redes Neuronales Sobreparametrizadas</h3>
                    <p class="paper-summary">üìù Resuelve la paradoja de que las cuencas de atracci√≥n en el paisaje de p√©rdida est√°n conectadas por caminos de bajo error, pero la din√°mica de optimizaci√≥n rara vez los explora. Identifica barreras entr√≥picas que surgen de la interacci√≥n entre variaciones de curvatura a lo largo de esos caminos y el ruido en la din√°mica de optimizaci√≥n. Estas fuerzas sesgan la din√°mica de vuelta hacia los m√≠nimos, confinando las soluciones.</p>
                    <div class="paper-points">‚Ä¢ Explica el confinamiento en cuencas a pesar de la conectividad del paisaje. Identifica barreras entr√≥picas por curvatura y ruido. Las fuerzas inducidas por curvatura gobiernan la localizaci√≥n de soluciones.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06297" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Modelo de Lenguaje Integrado Qu√≠mico usando Representaci√≥n Molecular Jer√°rquica para Inform√°tica de Pol√≠meros</h3>
                    <p class="paper-summary">üìù Presenta CI-LLM, un marco que combina representaciones jer√°rquicas de pol√≠meros (HAPPY) con descriptores num√©ricos para superar la escasez de datos. Para predicci√≥n, el codificador De¬≥BERTa logra inferencia 3.5x m√°s r√°pida y mayor precisi√≥n que modelos basados en SMILES. Para dise√±o inverso, el generador basado en GPT produce pol√≠meros con propiedades objetivo, optimizando m√∫ltiples objetivos incluso correlacionados negativamente.</p>
                    <div class="paper-points">‚Ä¢ Marco CI-LLM para inform√°tica de pol√≠meros (predicci√≥n y dise√±o inverso). Representaci√≥n HAPPY para superar escasez de datos. Alto rendimiento en predicci√≥n (mayor R¬≤) y dise√±o (100% retenci√≥n de andamiaje).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06301" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Redes Neuronales de Grafos Multimodales para Modelado Pron√≥stico de la Reorganizaci√≥n de Redes Cerebrales</h3>
                    <p class="paper-summary">üìù Propone un marco de Red Neuronal de Grafos Multimodal que integra MRI estructural, de difusi√≥n y funcional para modelar la reorganizaci√≥n espacio-temporal de redes cerebrales. Captura la evoluci√≥n temporal mediante operadores diferenciales estoc√°sticos y redes recurrentes basadas en grafos. Genera biomarcadores interpretables (entrop√≠a de energ√≠a, curvatura) que se combinan en un √≠ndice pron√≥stico compuesto para riesgo de deterioro cognitivo.</p>
                    <div class="paper-points">‚Ä¢ Modelado de reorganizaci√≥n din√°mica de redes cerebrales con grafos multimodales. Operadores diferenciales estoc√°sticos para dependencias a largo plazo. Generaci√≥n de biomarcadores interpretables para pron√≥stico cl√≠nico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06303" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Eficiencia Interpretativa: Fundamentos Informaci√≥n-Geom√©tricos de la Utilidad de los Datos</h3>
                    <p class="paper-summary">üìù Propone la Eficiencia Interpretativa, una medida axiom√°tica y normalizada que cuantifica la fracci√≥n de informaci√≥n relevante para la tarea transmitida a trav√©s de un canal interpretativo. Se fundamenta en cinco axiomas (acotaci√≥n, monotonicidad, etc.) y se relaciona con informaci√≥n mutua. Los experimentos muestran que recupera ordenamientos te√≥ricos, expone redundancia y correlaciona con robustez, sirviendo como diagn√≥stico para dise√±o de representaciones.</p>
                    <div class="paper-points">‚Ä¢ Nueva medida para cuantificar cu√°n bien los datos soportan una representaci√≥n interpretativa. Fundada en axiomas y geometr√≠a de informaci√≥n (expansi√≥n de Fisher). Diagn√≥stico pr√°ctico para dise√±o de representaciones.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06341" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Cuando la Distrae la Distancia: Sesgo de Distancia de Representaci√≥n en la P√©rdida BT para Modelos de Recompensa</h3>
                    <p class="paper-summary">üìù Analiza la p√©rdida de Bradley-Terry (BT) usada en modelos de recompensa para alineaci√≥n de LLMs, mostrando que la magnitud del gradiente escala con la distancia de representaci√≥n entre respuestas, no solo con el error de predicci√≥n. Esto causa que pares con gran distancia dominen el aprendizaje, mientras que distinciones finas en pares similares se ignoren. Propone NormBT, un esquema de normalizaci√≥n por pares que mitiga el sesgo y mejora el rendimiento, especialmente en tareas de razonamiento.</p>
                    <div class="paper-points">‚Ä¢ Identifica sesgo en la p√©rdida BT por distancia de representaci√≥n. Pares similares reciben actualizaciones d√©biles incluso si est√°n mal rankeados. Propone NormBT
‚Ä¢  una correcci√≥n simple que mejora el rendimiento (+5% en Reasoning).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06343" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Teorema de Error de Generalizaci√≥n Cero para Interpoladores Aleatorios v√≠a Geometr√≠a Algebraica</h3>
                    <p class="paper-summary">üìù Demuestra te√≥ricamente que el error de generalizaci√≥n de interpoladores (modelos con error de entrenamiento cero) en configuraciones maestro-estudiante se vuelve 0 una vez que el n√∫mero de muestras de entrenamiento supera un umbral. Utiliza herramientas de geometr√≠a algebraica para caracterizar la estructura geom√©trica del conjunto de interpoladores en el espacio de par√°metros. El resultado atribuye la alta capacidad de generalizaci√≥n a propiedades del modelo mismo, no solo al sesgo impl√≠cito del optimizador.</p>
                    <div class="paper-points">‚Ä¢ Teorema: error de generalizaci√≥n cero para interpoladores aleatorios tras umbral de datos. Usa geometr√≠a algebraica para caracterizar la estructura del conjunto de soluciones. Atribuye generalizaci√≥n a propiedades del modelo
‚Ä¢  no solo al optimizador.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06347" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo en Grafos Mejorado con LLM para Programaci√≥n de Trabajos Consciente del Carbono en Fabricaci√≥n Inteligente</h3>
                    <p class="paper-summary">üìù Presenta Luca, un marco que integra un LLM con una Red Neuronal de Grafos y Aprendizaje por Refuerzo para programaci√≥n din√°mica y sostenible en talleres de trabajo flexibles. Crea un embedding fusionado que captura caracter√≠sticas estructurales y sem√°nticas del estado de programaci√≥n. La pol√≠tica de RL optimiza simult√°neamente el makespan y las emisiones de carbono. Experimentos muestran que Luca supera a otros algoritmos, reduciendo el makespan hasta un 12.2% manteniendo emisiones.</p>
                    <div class="paper-points">‚Ä¢ Marco Luca: LLM + GNN + RL para programaci√≥n sostenible en fabricaci√≥n. Embedding fusionado que combina estructura de grafo y sem√°ntica del LLM. Supera algoritmos de comparaci√≥n en makespan y emisiones de carbono.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06351" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">DDFI: Imputaci√≥n Diversa y Consciente de la Distribuci√≥n de Caracter√≠sticas Faltantes mediante Reconstrucci√≥n en Dos Pasos</h3>
                    <p class="paper-summary">üìù Propone un m√©todo para imputar caracter√≠sticas faltantes en grafos, combinando propagaci√≥n de caracter√≠sticas con un Autoencoder Enmascarado. Introduce un algoritmo de enlace por etiquetas para mejorar la conectividad y un proceso de reconstrucci√≥n en dos pasos para reducir el cambio de distribuci√≥n en tasks inductivas. Eval√∫a el m√©todo en seis conjuntos p√∫blicos y en un nuevo dataset con caracter√≠sticas naturalmente ausentes.</p>
                    <div class="paper-points">‚Ä¢ Combina propagaci√≥n de caracter√≠sticas y Autoencoder Enmascarado. Algoritmo Co-Label Linking para grafos con m√∫ltiples componentes. Proceso de inferencia en dos pasos para diversidad y adaptaci√≥n a tareas inductivas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06356" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üíß Booster PID para Predicci√≥n de Series Temporales basada en Redes Neuronales: Caso de Predicci√≥n de Demanda de Agua</h3>
                    <p class="paper-summary">üìù Investiga un m√©todo inspirado en control PID para mejorar la precisi√≥n de predicci√≥n multi-paso de redes neuronales en series temporales peri√≥dicas. Se aplica a cada paso de tiempo para acercar el valor predicho al real. Valida el m√©todo en predicci√≥n de demanda de agua y consumo energ√©tico horario, mostrando mejoras en precisi√≥n sin aumentar significativamente la complejidad.</p>
                    <div class="paper-points">‚Ä¢ M√©todo booster inspirado en controladores PID. Mejora predicciones multi-paso de series temporales peri√≥dicas. Aplicaci√≥n en demanda de agua y consumo energ√©tico con impacto m√≠nimo en complejidad.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06357" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öôÔ∏è Optimizando Optimizadores para Aprendizaje R√°pido Basado en Gradientes</h3>
                    <p class="paper-summary">üìù Establece una base te√≥rica para automatizar el dise√±o de optimizadores en aprendizaje basado en gradientes. Formula el problema como maximizar la reducci√≥n instant√°nea de la p√©rdida, tratando al optimizador como una funci√≥n que traduce gradientes en movimientos de par√°metros. Resuelve problemas de optimizaci√≥n convexa para recuperar optimizadores populares y ajustar sus hiperpar√°metros de forma sistem√°tica y din√°mica.</p>
                    <div class="paper-points">‚Ä¢ Automatizaci√≥n del dise√±o de optimizadores mediante optimizaci√≥n convexa. Recupera optimizadores populares como soluciones de forma cerrada. Permite el ajuste din√°mico de hiperpar√°metros basado en estad√≠sticas de gradientes.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06370" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">RLAX: Aprendizaje por Refuerzo a Gran Escala y Distribuido para Modelos de Lenguaje Grandes en TPUs</h3>
                    <p class="paper-summary">üìù Presenta RLAX, un marco de aprendizaje por refuerzo escalable en TPUs con arquitectura de servidor de par√°metros. Incluye t√©cnicas del sistema para RL preemptible y escalable, y nuevas t√©cnicas de curaci√≥n y alineaci√≥n de datos. En evaluaciones a gran escala, mejora significativamente la precisi√≥n de un modelo grande de lenguaje en menos de 13 horas, siendo robusto a interrupciones.</p>
                    <div class="paper-points">‚Ä¢ Marco de RL escalable en TPUs con arquitectura cliente-servidor. T√©cnicas para entrenamiento preemptible y acelerar la convergencia. Logra mejoras de precisi√≥n significativas en tiempos reducidos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06392" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üåä</span>
                    <h3 class="paper-title">Hankel-FNO: Cartograf√≠a Ac√∫stica Submarina R√°pida mediante Operador de Fourier Neuronal Codificado por F√≠sica</h3>
                    <p class="paper-summary">üìù Propone Hankel-FNO, un modelo basado en Operadores de Fourier Neuronales para cartograf√≠a ac√∫stica submarina eficiente y precisa. Incorpora conocimiento de propagaci√≥n del sonido y batimetr√≠a. Supera a solucionadores num√©ricos tradicionales en velocidad y a alternativas basadas √∫nicamente en datos en precisi√≥n, especialmente en predicciones de largo alcance, mostrando adaptabilidad con poco ajuste.</p>
                    <div class="paper-points">‚Ä¢ Modelo FNO para cartograf√≠a ac√∫stica submarina r√°pida y precisa. Incorpora f√≠sica de propagaci√≥n del sonido. Alta adaptabilidad a diferentes entornos y configuraciones de fuentes sonoras.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06417" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üìà Una Nueva Inicializaci√≥n para Controlar Gradientes en Redes Neuronales Sinusoidales</h3>
                    <p class="paper-summary">üìù Propone una nueva estrategia de inicializaci√≥n para redes con funciones de activaci√≥n sinusoidales (como SIREN), enfocada en controlar gradientes y su escalado con la profundidad. Deriva una expresi√≥n de forma cerrada para los par√°metros iniciales, diferente al esquema original de SIREN. Esta inicializaci√≥n mejora la generalizaci√≥n y el rendimiento en tareas de ajuste de funciones y reconstrucci√≥n de im√°genes.</p>
                    <div class="paper-points">‚Ä¢ Nueva inicializaci√≥n para redes con activaciones sinusoidales. Controla gradientes y previene la explosi√≥n/desvanecimiento. Supera a m√©todos state-of-the-art en reconstrucci√≥n
‚Ä¢  incluyendo PINNs.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06427" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚úÇÔ∏è Expresividad Neuronal para Compresi√≥n de Modelos m√°s All√° de la Importancia</h3>
                    <p class="paper-summary">üìù Introduce &#x27;Expresividad&#x27; como un nuevo criterio para compresi√≥n de modelos, enfocado en la capacidad de una neurona para redistribuir recursos informativos bas√°ndose en la superposici√≥n de activaciones. Es independiente del estado de aprendizaje y se puede aproximar con datos arbitrarios. Combina complementariamente con criterios basados en importancia, logrando altas tasas de compresi√≥n con m√≠nima degradaci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Criterio de &#x27
‚Ä¢ Expresividad&#x27
‚Ä¢  para poda
‚Ä¢  basado en redistribuci√≥n de recursos. Estrategias independientes del estado de aprendizaje y de datos. Logra alta compresi√≥n con degradaci√≥n m√≠nima
‚Ä¢  incluso mejorando m√©tricas en algunos casos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06440" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚ö°</span>
                    <h3 class="paper-title">BitStopper: Un Acelerador Eficiente de Atenci√≥n para Transformadores mediante Fusi√≥n de Etapas y Terminaci√≥n Temprana</h3>
                    <p class="paper-summary">üìù Propone BitStopper, un co-dise√±o algoritmo-arquitectura de grano fino para acelerar la atenci√≥n en LLMs sin un predictor de dispersi√≥n. Incluye fusi√≥n de etapas de habilitaci√≥n en serie de bits, una estrategia liviana de selecci√≥n de tokens y procesamiento as√≠ncrono a nivel de bit. Logra mejoras significativas en velocidad y eficiencia energ√©tica sobre aceleradores de Transformers state-of-the-art.</p>
                    <div class="paper-points">‚Ä¢ Co-dise√±o para acelerar atenci√≥n sin predictor de dispersi√≥n. Fusi√≥n de etapas y terminaci√≥n temprana a nivel de bit. Mejoras de m√°s de 2x en velocidad y eficiencia energ√©tica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06457" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üéØ</span>
                    <h3 class="paper-title">Por Qu√© Funciona el Aprendizaje por Refuerzo Condicionado por Objetivos: Relaci√≥n con el Control Dual</h3>
                    <p class="paper-summary">üìù Analiza el aprendizaje por refuerzo condicionado por objetivos desde la perspectiva del control √≥ptimo. Deriva una brecha de optimalidad entre objetivos cl√°sicos (cuadr√°ticos) y la recompensa de objetivo, explicando el √©xito de este enfoque. Conecta la estimaci√≥n de estado con la recompensa probabil√≠stica, haci√©ndola adecuada para problemas de control dual. Valida las ventajas en entornos no lineales e inciertos.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis te√≥rico que conecta RL condicionado por objetivos con control √≥ptimo. Explica por qu√© las recompensas &#x27
‚Ä¢ densas&#x27
‚Ä¢  cl√°sicas pueden fallar. Muestra idoneidad para problemas de control dual con observaci√≥n parcial.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06471" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üì± Optimizando LLMs usando Cuantizaci√≥n para Ejecuci√≥n M√≥vil</h3>
                    <p class="paper-summary">üìù Investiga la Cuantizaci√≥n Post-Entrenamiento (PTQ) para comprimir LLMs y ejecutarlos en dispositivos m√≥viles. Aplica PTQ de 4 bits al modelo Llama 3.2 3B, reduciendo su tama√±o en un 68.66%. Convierte el modelo al formato GGUF optimizado para m√≥viles y demuestra su ejecuci√≥n exitosa en un dispositivo Android mediante Termux y Ollama, mostrando un equilibrio pr√°ctico entre tama√±o y rendimiento.</p>
                    <div class="paper-points">‚Ä¢ Cuantizaci√≥n Post-Entrenamiento de 4 bits para compresi√≥n de LLMs. Reducci√≥n del 68.66% en tama√±o del modelo (Llama 3.2 3B). Ejecuci√≥n exitosa en dispositivo Android con formatos optimizados (GGUF).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06490" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Predicci√≥n de mortalidad basada en diagn√≥stico para pacientes de cuidados intensivos mediante aprendizaje por transferencia</h3>
                    <p class="paper-summary">üìù Se eval√∫an enfoques de aprendizaje por transferencia para predecir la mortalidad espec√≠fica por diagn√≥stico en la UCI. Estos modelos superan a los entrenados solo con datos de un diagn√≥stico espec√≠fico y al score APACHE IVa. El estudio sugiere que el punto de corte de Youden es m√°s apropiado que el umbral convencional de 0.5.</p>
                    <div class="paper-points">‚Ä¢ Aprendizaje por transferencia
‚Ä¢  predicci√≥n de mortalidad
‚Ä¢  diagn√≥stico espec√≠fico
‚Ä¢  calibraci√≥n mejorada
‚Ä¢  punto de corte de Youden.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06511" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Aprendizaje profundo geom√©trico jer√°rquico permite el an√°lisis escalable de din√°mica molecular</h3>
                    <p class="paper-summary">üìù Se presenta un m√©todo que agrega informaci√≥n local para reducir los requisitos de memoria y tiempo de ejecuci√≥n en el an√°lisis de simulaciones de din√°mica molecular con GNNs. Esto permite analizar complejos prote√≠na-√°cido nucleico de miles de residuos en minutos con una sola GPU, mejorando el rendimiento y la interpretabilidad.</p>
                    <div class="paper-points">‚Ä¢ Redes de grafos (GNNs)
‚Ä¢  din√°mica molecular
‚Ä¢  agregaci√≥n jer√°rquica
‚Ä¢  escalabilidad
‚Ä¢  complejos biomoleculares.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06520" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">M√°s all√° de la supervisi√≥n a nivel de token: Liberando el potencial de la regresi√≥n basada en decodificaci√≥n mediante aprendizaje por refuerzo</h3>
                    <p class="paper-summary">üìù Se propone utilizar Aprendizaje por Refuerzo (RL) para alinear la generaci√≥n de secuencias con valores num√©ricos continuos en tareas de regresi√≥n con LLMs. El m√©todo, con recompensas a nivel de secuencia, supera a los basados en tokens y a los cabezales de regresi√≥n tradicionales, mejorando la coherencia global y la precisi√≥n.</p>
                    <div class="paper-points">‚Ä¢ Regresi√≥n basada en decodificaci√≥n
‚Ä¢  Aprendizaje por Refuerzo (RL)
‚Ä¢  LLMs
‚Ä¢  coherencia num√©rica
‚Ä¢  recompensas a nivel de secuencia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06533" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚ö°</span>
                    <h3 class="paper-title">A-3PO: Acelerando el entrenamiento as√≠ncrono de LLMs con Aproximaci√≥n de Pol√≠tica Proximal consciente de la obsolescencia</h3>
                    <p class="paper-summary">üìù Se introduce A-3PO, un m√©todo que aproxima la pol√≠tica proximal mediante interpolaci√≥n para eliminar el cuello de botella computacional en el entrenamiento as√≠ncrono de LLMs con RL. Reduce el tiempo de entrenamiento en un 18% manteniendo un rendimiento comparable, sin necesidad de pases forward adicionales.</p>
                    <div class="paper-points">‚Ä¢ Entrenamiento as√≠ncrono
‚Ä¢  LLMs
‚Ä¢  Aprendizaje por Refuerzo (RL)
‚Ä¢  pol√≠tica proximal aproximada
‚Ä¢  optimizaci√≥n computacional.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06547" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üåå Geometr√≠a Profunda Parte 2: Matem√°ticas de las Redes Neuronales</h3>
                    <p class="paper-summary">üìù Se desarrolla una teor√≠a global de las redes neuronales a trav√©s de m√∫ltiples encadenados, teor√≠a de puntos fijos e iteraci√≥n condicionada por fronteras. La capacidad emerge cuando se estabilizan regiones de punto fijo, lo que motiva arquitecturas distribuidas para manejar la complejidad del mundo real.</p>
                    <div class="paper-points">‚Ä¢ Teor√≠a matem√°tica
‚Ä¢  variedades (manifolds)
‚Ä¢  puntos fijos
‚Ä¢  plasticidad
‚Ä¢  modelos federados
‚Ä¢  complejidad de datos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06563" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíæ</span>
                    <h3 class="paper-title">QL-LSTM: Una LSTM eficiente en par√°metros para el modelado estable de secuencias largas</h3>
                    <p class="paper-summary">üìù Se presenta QL-LSTM, una arquitectura recurrente que reduce par√°metros en ~48% mediante compuertas unificadas y mejora el flujo de informaci√≥n a larga distancia con conexiones de salto. Logra precisi√≥n competitiva en clasificaci√≥n de sentimientos con documentos largos, aunque su naturaleza secuencial limita la velocidad de ejecuci√≥n.</p>
                    <div class="paper-points">‚Ä¢ LSTM
‚Ä¢  modelado de secuencias largas
‚Ä¢  eficiencia de par√°metros
‚Ä¢  compuertas unificadas
‚Ä¢  conexiones de salto.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06582" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Sobre el ajuste fino de Boltz-2 para la predicci√≥n de afinidad prote√≠na-prote√≠na</h3>
                    <p class="paper-summary">üìù Se adapta el predictor de afinidad prote√≠na-ligando Boltz-2 (basado en estructura) para predecir afinidad prote√≠na-prote√≠na. El modelo resultante (Boltz-2-PPI) tiene un rendimiento inferior a los basados en secuencia. La combinaci√≥n de ambos tipos de *embeddings* ofrece mejoras complementarias.</p>
                    <div class="paper-points">‚Ä¢ Afinidad prote√≠na-prote√≠na
‚Ä¢  modelos basados en estructura
‚Ä¢  Boltz-2
‚Ä¢  *embeddings*
‚Ä¢  se√±ales complementarias.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06592" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîç</span>
                    <h3 class="paper-title">Una soluci√≥n r√°pida y efectiva al problema del sesgo de anticipaci√≥n en LLMs</h3>
                    <p class="paper-summary">üìù Se introduce un m√©todo para eliminar el sesgo de anticipaci√≥n (look-ahead bias) en LLMs aplicados a finanzas. Gu√≠a la generaci√≥n ajustando los *logits* del modelo base con un par de modelos peque√±os especializados, uno en informaci√≥n a olvidar y otro en informaci√≥n a retener. Supera a m√©todos anteriores.</p>
                    <div class="paper-points">‚Ä¢ Sesgo de anticipaci√≥n (look-ahead bias)
‚Ä¢  LLMs
‚Ä¢  finanzas
‚Ä¢  ajuste de *logits*
‚Ä¢  inferencia
‚Ä¢  eliminaci√≥n de conocimiento.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06607" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üé®</span>
                    <h3 class="paper-title">Cuantizaci√≥n Vectorial usando Autoencoder Variacional Gaussiano</h3>
                    <p class="paper-summary">üìù Se propone Gaussian Quant (GQ), una t√©cnica que convierte un VAE Gaussiano en un VQ-VAE sin entrenamiento, usando ruido Gaussiano como libro de c√≥digos. Con una restricci√≥n de divergencia objetivo (TDC), GQ supera a VQ-VAEs anteriores como VQGAN y FSQ en tareas de compresi√≥n de im√°genes.</p>
                    <div class="paper-points">‚Ä¢ Cuantizaci√≥n vectorial
‚Ä¢  VQ-VAE
‚Ä¢  autoencoder variacional gaussiano
‚Ä¢  libro de c√≥digos (codebook)
‚Ä¢  discretizaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06609" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öõÔ∏è Redes Neuronales Convolucionales Temporales Cu√°nticas para la Predicci√≥n de Rendimientos de Capitalizaci√≥n Cruzada: Un Estudio Comparativo</h3>
                    <p class="paper-summary">üìù Se propone una Red Neuronal Convolucional Temporal Cu√°ntica (QTCNN) que combina un codificador temporal cl√°sico con circuitos cu√°nticos eficientes para predecir rendimientos burs√°tiles. En el dataset JPX, logra un ratio de Sharpe de 0.538, superando en un ~72% al mejor modelo cl√°sico, demostrando su potencial en finanzas cuantitativas.</p>
                    <div class="paper-points">‚Ä¢ Aprendizaje autom√°tico cu√°ntico
‚Ä¢  predicci√≥n financiera
‚Ä¢  CNN temporal
‚Ä¢  ratio de Sharpe
‚Ä¢  superposici√≥n y entrelazamiento.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06630" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîç</span>
                    <h3 class="paper-title">El Impacto de las Caracter√≠sticas de los Datos en la Evaluaci√≥n de GNN para Detectar Noticias Falsas</h3>
                    <p class="paper-summary">üìù Los conjuntos de datos GossipCop y PolitiFact, com√∫nmente usados para evaluar GNN en detecci√≥n de noticias falsas, tienen topolog√≠as de grafos superficiales y ego-c√©ntricas que ofrecen poca capacidad para diferenciar m√©todos. MLPs simples igualan o se acercan al rendimiento de GNNs complejos, ya que la estructura del grafo juega un papel negligible en estos benchmarks. Se requieren conjuntos de datos con topolog√≠as de grafos m√°s ricas y diversas para evaluar verdaderamente la utilidad de modelar caracter√≠sticas estructurales.</p>
                    <div class="paper-points">‚Ä¢ Benchmarks comunes (GossipCop
‚Ä¢  PolitiFact) tienen grafos poco informativos
‚Ä¢  MLPs igualan rendimiento de GNNs
‚Ä¢  La estructura del grafo contribuye poco
‚Ä¢  &gt
‚Ä¢ 75% de nodos est√°n a un salto de la ra√≠z
‚Ä¢  En datos sint√©ticos informativos
‚Ä¢  los GNNs superan claramente a los MLPs.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06638" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üí∏ Estudio de Identificaci√≥n e Interpretabilidad de Fraude Financiero para Empresas Cotizadas Basado en Redes Neuronales Convolucionales</h3>
                    <p class="paper-summary">üìù Propone un marco de detecci√≥n de fraude financiero para empresas chinas que transforma datos financieros en representaciones tipo imagen para ser procesadas por una CNN, permitiendo capturar patrones temporales y predecir fraudes con antelaci√≥n. La CNN supera a la regresi√≥n log√≠stica y LightGBM en precisi√≥n, robustez y capacidad de alerta temprana. T√©cnicas de interpretabilidad local identifican que la solvencia, estructura de ratios, gobernanza y control interno son predictores clave.</p>
                    <div class="paper-points">‚Ä¢ CNN procesa datos financieros como im√°genes para detectar fraude
‚Ä¢  Supera a modelos tradicionales y permite alerta temprana
‚Ä¢  Interpretabilidad identifica predictores clave (solvencia
‚Ä¢  gobernanza)
‚Ä¢  Estudio de caso de Guanong Shares valida los hallazgos
‚Ä¢  Ajuste del umbral de clasificaci√≥n es crucial en entornos de alto riesgo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06648" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üå´Ô∏è Estimaci√≥n de la Concentraci√≥n de Carbono Negro del Tr√°fico Urbano Usando Aprendizaje Autom√°tico Basado en Visi√≥n</h3>
                    <p class="paper-summary">üìù Propone un sistema que usa v√≠deo de tr√°fico urbano y datos meteorol√≥gicos para estimar la concentraci√≥n de Carbono Negro (BC) a nivel de calle, con un R¬≤ de 0.72. Este enfoque aprovecha infraestructura de monitorizaci√≥n de tr√°fico ya desplegada para generar datos de contaminaci√≥n local, superando la limitaci√≥n de los costosos instrumentos de medici√≥n de BC. Proporciona informaci√≥n procesable para la reducci√≥n de la contaminaci√≥n, planificaci√≥n urbana, salud p√∫blica y justicia ambiental a nivel municipal.</p>
                    <div class="paper-points">‚Ä¢ Modelo estima Carbono Negro (BC) desde v√≠deo de tr√°fico y clima
‚Ä¢  R¬≤ de 0.72
‚Ä¢  RMSE de 129.42 ng/m¬≥
‚Ä¢  Usa infraestructura existente para generar datos ambientales escasos
‚Ä¢  Informaci√≥n para pol√≠ticas locales de contaminaci√≥n
‚Ä¢  Aborda desequilibrio entre datos de tr√°fico y sus consecuencias ambientales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06649" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üè•</span>
                    <h3 class="paper-title">Entrenamiento Adaptativo en Tiempo de Prueba para Predecir la Necesidad de Ventilaci√≥n Mec√°nica Invasiva en Cohortes Multic√©ntrico</h3>
                    <p class="paper-summary">üìù Presenta AdaTTT, un marco de Test-Time Training (TTT) mejorado para predecir la necesidad de ventilaci√≥n mec√°nica invasiva (IMV) en UCI a partir de historiales electr√≥nicos de salud (EHR). Mitiga la degradaci√≥n del modelo por diferencias entre instituciones (desplazamiento de dominio) adapt√°ndose din√°micamente durante la inferencia sin datos etiquetados del dominio objetivo. Combina aprendizaje autosupervisado con tareas de pretexto (reconstrucci√≥n, modelado de caracter√≠sticas enmascaradas), aprendizaje protot√≠pico y alineaci√≥n parcial de caracter√≠sticas para mejorar la robustez.</p>
                    <div class="paper-points">‚Ä¢ AdaTTT adapta modelos de IMV en inferencia a nuevos hospitales sin etiquetas
‚Ä¢  Combate el &#x27
‚Ä¢ domain shift&#x27
‚Ä¢  en datos de EHR
‚Ä¢  Usa tareas autosupervisadas y alineaci√≥n de caracter√≠sticas con Transporte √ìptimo Parcial (POT)
‚Ä¢  Mantiene representaciones cl√≠nicamente significativas
‚Ä¢  Demuestra rendimiento competitivo en cohortes multic√©ntricas de UCI.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06652" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">GSAE: Autoencoders Dispersos Regularizados por Grafos para una Direcci√≥n Robusta de la Seguridad en LLMs</h3>
                    <p class="paper-summary">üìù Introduce Autoencoders Dispersos Regularizados por Grafos (GSAEs) para mejorar la seguridad de los LLMs. A diferencia de los SAE est√°ndar, que asocian conceptos a caracter√≠sticas √∫nicas, los GSAEs capturan representaciones distribuidas y coherentes de seguridad (como el rechazo) a trav√©s de m√∫ltiples caracter√≠sticas neuronales, usando una penalizaci√≥n de suavizado de Laplaciano. Un mecanismo de compuerta de dos etapas activa intervenciones solo ante indicios de contenido da√±ino, logrando altas tasas de rechazo selectivo (82% en promedio) manteniendo la utilidad en consultas benignas.</p>
                    <div class="paper-points">‚Ä¢ GSAE modela seguridad como patrones distribuidos
‚Ä¢  no como una sola caracter√≠stica
‚Ä¢  Penalizaci√≥n de Laplaciano en el grafo de co-activaci√≥n neuronal
‚Ä¢  Mecanismo de compuerta adaptativa activa intervenciones solo cuando es necesario
‚Ä¢  Alto rechazo de contenido da√±ino (82%) manteniendo precisi√≥n en tareas
‚Ä¢  Robusto contra ataques de jailbreak (GCG
‚Ä¢  AutoDAN).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06655" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Repensando la Robustez: Un Nuevo Enfoque para Evaluar M√©todos de Atribuci√≥n de Caracter√≠sticas</h3>
                    <p class="paper-summary">üìù Cuestiona las nociones actuales de robustez en m√©todos de atribuci√≥n (explicabilidad) para redes neuronales, que en gran medida ignoran las diferencias en las salidas del modelo. Propone una nueva definici√≥n de &#x27;entradas similares&#x27;, una nueva m√©trica de robustez y un m√©todo novedoso basado en GANs para generar dichas entradas. El objetivo es proporcionar una evaluaci√≥n m√°s precisa que revele las debilidades del m√©todo de atribuci√≥n en s√≠, no solo de la red neuronal subyacente.</p>
                    <div class="paper-points">‚Ä¢ Critica m√©tricas actuales de robustez para atribuci√≥n
‚Ä¢  Propone nueva definici√≥n de similitud de entrada y nueva m√©trica
‚Ä¢  M√©todo basado en GANs para generar entradas de prueba
‚Ä¢  Evaluaci√≥n exhaustiva con m√©todos de atribuci√≥n state-of-the-art
‚Ä¢  Busca evaluar debilidades del m√©todo de explicaci√≥n
‚Ä¢  no del modelo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06665" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚è≥ La Brecha del Meta-Aprendizaje: Combinando Hydra y Quant para Clasificaci√≥n de Series Temporales a Gran Escala</h3>
                    <p class="paper-summary">üìù Investiga combinar dos algoritmos eficientes (Hydra y Quant) para clasificaci√≥n de series de tiempo a gran escala, buscando el beneficio de los ensembles sin su costo computacional prohibitivo. La mejor combinaci√≥n mejora la precisi√≥n media de 0.829 a 0.836 en 10 grandes conjuntos de datos. Sin embargo, los ensembles por combinaci√≥n de predicciones solo capturan el 11% del potencial te√≥rico de un &#x27;or√°culo&#x27;, revelando una gran brecha de optimizaci√≥n en meta-aprendizaje. El reto actual es aprender a combinarlos efectivamente.</p>
                    <div class="paper-points">‚Ä¢ Combina Hydra (kernels convolucionales) y Quant (cuantiles de intervalos) para series de tiempo
‚Ä¢  Mejora precisi√≥n manteniendo eficiencia
‚Ä¢  Los ensembles capturan solo el 11% del potencial te√≥rico
‚Ä¢  Brecha de meta-aprendizaje: combinarlos bien es el reto clave
‚Ä¢  La complementariedad entre algoritmos existe pero es dif√≠cil de explotar.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06666" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üß© GradientSpace: Agrupamiento de Datos No Supervisado para Mejorar el Afinamiento por Instrucci√≥n</h3>
                    <p class="paper-summary">üìù Propone GradientSpace, un marco que agrupa muestras de datos en el espacio completo de gradientes (no en espacio de embeddings) para mitigar la &#x27;interferencia de gradientes&#x27; durante el afinamiento por instrucci√≥n de LLMs. Usa un algoritmo online basado en SVD sobre gradientes LoRA para identificar &#x27;habilidades&#x27; latentes sin el costo de almacenar todos los gradientes. Entrena expertos LoRA especializados y un enrutador ligero para seleccionar el mejor experto en inferencia, reduciendo latencia y mejorando precisi√≥n respecto a ensembles.</p>
                    <div class="paper-points">‚Ä¢ Agrupa datos en espacio de gradientes completos para afinamiento por instrucci√≥n
‚Ä¢  Algoritmo SVD online sobre gradientes LoRA identifica habilidades
‚Ä¢  Entrena expertos especializados y un enrutador para inferencia
‚Ä¢  Supera a m√©todos de agrupaci√≥n sem√°ntica y t√©cnicas de fine-tuning
‚Ä¢  Reduce latencia vs. ensembles de expertos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06678" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">La Diversidad de Estado Importa en la Destilaci√≥n de Comportamiento Offline</h3>
                    <p class="paper-summary">üìù En Destilaci√≥n de Comportamiento Offline (OBD), descubre que la diversidad de estados en el dataset original es m√°s cr√≠tica que su calidad/rendimiento cuando el error de entrenamiento es alto (escenario t√≠pico de OBD). El an√°lisis te√≥rico asocia la calidad del estado con la reducci√≥n del &#x27;error pivotal&#x27; y la diversidad con el &#x27;error circundante&#x27;. Propone SDW-OBD, un algoritmo simple que pondera el objetivo de destilaci√≥n con la densidad inversa del estado, enfatizando la diversidad y mejorando el rendimiento cuando el dataset original tiene diversidad limitada.</p>
                    <div class="paper-points">‚Ä¢ Diversidad de estados &gt
‚Ä¢  Calidad de estados en OBD con alto error
‚Ä¢  An√°lisis te√≥rico vincula diversidad con reducci√≥n de &#x27
‚Ä¢ error circundante&#x27
‚Ä¢ 
‚Ä¢  Propone SDW-OBD: pondera objetivo por inverso de densidad de estado
‚Ä¢  Enfatiza diversidad en datos sint√©ticos destilados
‚Ä¢  Mejora rendimiento en datasets D4RL con baja diversidad original.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06692" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öõÔ∏è Mitigando Mesetas Est√©riles en Modelos Cu√°nticos Probabil√≠sticos de Difusi√≥n para Eliminaci√≥n de Ruido</h3>
                    <p class="paper-summary">üìù Identifica que las &#x27;barren plateaus&#x27; (mesetas est√©riles) surgen en los Modelos Cu√°nticos de Difusi√≥n para Eliminaci√≥n de Ruido (QuDDPM) debido al uso de estados 2-design (cercanos a la distribuci√≥n de Haar) como entrada al proceso de desruido, lo que perjudica severamente su entrenabilidad. A trav√©s de an√°lisis te√≥rico y experimental, confirma el problema. Introduce un QuDDPM mejorado que utiliza una distribuci√≥n de entrada que mantiene cierta distancia de la distribuci√≥n de Haar, mitigando las mesetas est√©riles y generando muestras de mayor calidad, facilitando el aprendizaje generativo cu√°ntico escalable.</p>
                    <div class="paper-points">‚Ä¢ Los QuDDPM originales sufren de &#x27
‚Ä¢ barren plateaus&#x27
‚Ä¢  por usar estados 2-design
‚Ä¢  Esto dificulta el entrenamiento de modelos generativos cu√°nticos
‚Ä¢  QuDDPM mejorado usa distribuci√≥n alejada de Haar para entradas
‚Ä¢  Mitiga el problema de las mesetas est√©riles
‚Ä¢  Genera muestras de mayor calidad para aprendizaje cu√°ntico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06695" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üî¨</span>
                    <h3 class="paper-title">Sendero hacia la complejidad √≥ptima de muestreo en modelos generativos de flujo</h3>
                    <p class="paper-summary">üìù Proporciona herramientas anal√≠ticas para estimar el error de modelos generativos basados en flujo bajo la m√©trica de Wasserstein y establecer el l√≠mite √≥ptimo de complejidad de iteraciones de muestreo en O(d). El error se controla mediante la Lipschitz de los mapas push-forward y un error local de discretizaci√≥n. Los resultados son v√°lidos para el proceso de F√∂llmer y flujo rectificado bajo supuestos de cola gaussiana.</p>
                    <div class="paper-points">‚Ä¢ Estimaci√≥n de error en modelos de flujo
‚Ä¢  complejidad de muestreo lineal con dimensi√≥n
‚Ä¢  supuestos de cola gaussiana
‚Ä¢  proceso de F√∂llmer
‚Ä¢  flujo rectificado.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06702" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öôÔ∏è Un nuevo marco multimodal de Vida √ötil Remanente (RUL) con explicaciones por capas</h3>
                    <p class="paper-summary">üìù Propone un marco novedoso para estimar la Vida √ötil Remanente (RUL) de rodamientos, combinando representaciones de imagen (ImR) y tiempo-frecuencia (TFR) de se√±ales de vibraci√≥n. Utiliza bloques convolucionales dilatados, LSTM y atenci√≥n multi-cabeza. Incluye una t√©cnica de explicabilidad (LRP multimodal) para mejorar la transparencia. Valida en datasets XJTU-SY y PRONOSTIA con menos datos de entrenamiento y buena robustez al ruido.</p>
                    <div class="paper-points">‚Ä¢ Estimaci√≥n de RUL multimodal (ImR y TFR)
‚Ä¢  arquitectura con CNN dilatada y LSTM
‚Ä¢  explicabilidad con LRP
‚Ä¢  validaci√≥n en datasets industriales
‚Ä¢  reducci√≥n de datos de entrenamiento.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06708" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üíß Una nueva arquitectura de red neuronal profunda para pron√≥stico de demanda de agua en tiempo real</h3>
                    <p class="paper-summary">üìù Presenta un modelo de pron√≥stico de demanda de agua a corto plazo (StWDF) basado en GRU y K-means, con baja complejidad. Propone una extensi√≥n de datos insertando puntos virtuales para reducir el error en puntos extremos. El modelo reduce la complejidad seis veces respecto al estado del arte manteniendo precisi√≥n, y la extensi√≥n de datos reduce el error ~30% aunque aumenta el tiempo de entrenamiento.</p>
                    <div class="paper-points">‚Ä¢ Pron√≥stico de demanda de agua con GRU y K-means
‚Ä¢  reducci√≥n de error en puntos extremos
‚Ä¢  baja complejidad de modelo
‚Ä¢  extensi√≥n de datos con puntos virtuales
‚Ä¢  validaci√≥n en plantas de China.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06714" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Decodificaci√≥n del comportamiento motor usando aprendizaje profundo y computaci√≥n de reservorios</h3>
                    <p class="paper-summary">üìù Integra una Red de Estado de Eco (ESN) dentro de una CNN para decodificar EEG en interfaces cerebro-m√°quina no invasivas, mejorando el modelado de dependencias temporales largas. Eval√∫a en un dataset de trucos de skateboard, logrando 83.2% de precisi√≥n intra-sujeto y 51.3% en validaci√≥n cruzada, superando a baselines CNN como EEGNet y DeepConvNet.</p>
                    <div class="paper-points">‚Ä¢ Decodificaci√≥n de EEG con CNN + ESN
‚Ä¢  mejor captura de dependencias temporales
‚Ä¢  evaluaci√≥n en dataset de comportamiento motor
‚Ä¢  superioridad sobre arquitecturas CNN convencionales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06725" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">KV-CAR: Compresi√≥n de cach√© KV usando autoencoders y reutilizaci√≥n en modelos de lenguaje grandes</h3>
                    <p class="paper-summary">üìù Propone un marco unificado (KV CAR) para reducir la memoria de la cach√© KV en LLMs durante la decodificaci√≥n autoregresiva. Combina autoencoders ligeros para compresi√≥n de embeddings y un mecanismo de reutilizaci√≥n basado en similitud de tensores KV entre capas adyacentes. Logra hasta un 47.85% de reducci√≥n de memoria con impacto m√≠nimo en perplejidad y precisi√≥n, permitiendo secuencias m√°s largas y lotes m√°s grandes.</p>
                    <div class="paper-points">‚Ä¢ Compresi√≥n de cach√© KV con autoencoders
‚Ä¢  reutilizaci√≥n de tensores similares
‚Ä¢  reducci√≥n de memoria ~48%
‚Ä¢  arquitectura agn√≥stica
‚Ä¢  evaluaci√≥n en GPT-2 y TinyLLaMA.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06727" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üëÅÔ∏è Mejora de la interpretabilidad del reconocimiento de intenci√≥n motora basado en AR-SSVEP mediante CNN-BiLSTM y SHAP</h3>
                    <p class="paper-summary">üìù Propone un sistema AR-SSVEP con HoloLens 2 para rehabilitaci√≥n, usando una arquitectura MACNN-BiLSTM con atenci√≥n multi-cabeza para clasificar EEG. Aplica SHAP para visualizar la contribuci√≥n de caracter√≠sticas temporales-espectrales en la decisi√≥n de la red, mejorando la interpretabilidad. Busca aumentar el compromiso del paciente en entrenamiento de rehabilitaci√≥n motora.</p>
                    <div class="paper-points">‚Ä¢ Sistema AR-SSVEP con HoloLens 2
‚Ä¢  arquitectura CNN-BiLSTM con atenci√≥n
‚Ä¢  interpretabilidad con SHAP
‚Ä¢  aplicaci√≥n en rehabilitaci√≥n motora
‚Ä¢  datos de sujetos sanos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06730" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üìà Descenso de Gradiente en Arco: Una reformulaci√≥n con din√°mica de paso controlable por el usuario</h3>
                    <p class="paper-summary">üìù Presenta el optimizador ArcGD, derivado matem√°ticamente del descenso de gradiente con control de fase en la din√°mica del paso. Supera a Adam en la funci√≥n no convexa de Rosenbrock (hasta 50k dimensiones) y logra mayor precisi√≥n en CIFAR-10 con MLPs, mostrando menor sobreajuste. Una variante de ArcGD se interpreta como un caso especial del optimizador Lion.</p>
                    <div class="paper-points">‚Ä¢ Nuevo optimizador ArcGD
‚Ä¢  mejor rendimiento en funciones no convexas y CIFAR-10
‚Ä¢  resistencia al sobreajuste
‚Ä¢  conexi√≥n te√≥rica con el optimizador Lion.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06737" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Modelado multi-escala de estructuras de prote√≠nas con U-Nets de grafos geom√©tricos</h3>
                    <p class="paper-summary">üìù Introduce Geometric Graph U-Nets, una nueva clase de modelos que aprende representaciones jer√°rquicas de estructuras proteicas mediante el coarsening y refinado recursivo del grafo. Supera a GNNs geom√©tricos est√°ndar en clasificaci√≥n de pliegues proteicos, demostrando mayor capacidad para capturar patrones estructurales globales y regulaci√≥n alost√©rica de largo alcance.</p>
                    <div class="paper-points">‚Ä¢ Arquitectura U-Net para grafos geom√©tricos
‚Ä¢  aprendizaje multi-escala de prote√≠nas
‚Ä¢  superioridad en clasificaci√≥n de pliegues
‚Ä¢  modelado de interacciones jer√°rquicas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06752" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öñÔ∏è An√°lisis √≥ptimo para aprendizaje bandido en mercados de emparejamiento con dictadura serial</h3>
                    <p class="paper-summary">üìù Propone un algoritmo de selecci√≥n sucesiva multi-nivel para mercados de emparejamiento de dos lados con dictadura serial (preferencias id√©nticas del lado de los &#x27;arms&#x27;). Logra un l√≠mite de regret de O(N log(T)/Œî¬≤ + K log(T)/Œî), igualando la cota inferior establecida, siendo el primer algoritmo en alcanzar este √≥ptimo en este problema de bandidos.</p>
                    <div class="paper-points">‚Ä¢ Algoritmo √≥ptimo para mercados de emparejamiento bandido
‚Ä¢  dictadura serial
‚Ä¢  l√≠mite de regret que iguala la cota inferior
‚Ä¢  an√°lisis te√≥rico riguroso.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06758" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Medici√≥n del sobre-suavizado m√°s all√° de la energ√≠a de Dirichlet</h3>
                    <p class="paper-summary">üìù Propone una familia generalizada de medidas de similitud de nodos basadas en energ√≠a de derivadas de orden superior para cuantificar el sobre-suavizado en GNNs, superando la limitaci√≥n de la energ√≠a de Dirichlet (solo derivadas de primer orden). Establece tasas de decaimiento de la energ√≠a y conecta la tasa de sobre-suavizado con el gap espectral del Laplaciano del grafo. Demuestra emp√≠ricamente que GNNs basados en atenci√≥n sufren de sobre-suavizado seg√∫n estas m√©tricas.</p>
                    <div class="paper-points">‚Ä¢ Nuevas m√©tricas para sobre-suavizado con derivadas de orden superior
‚Ä¢  conexi√≥n te√≥rica con el gap espectral
‚Ä¢  an√°lisis de decaimiento
‚Ä¢  evaluaci√≥n en GNNs con atenci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06782" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Regularizaci√≥n Angular para Aprendizaje Positivo-No Etiquetado en la Hiperesfera</h3>
                    <p class="paper-summary">üìù Propone AngularPU, un marco para clasificaci√≥n donde solo hay ejemplos positivos etiquetados y el resto no est√° etiquetado. Usa similitud coseno y un prototipo aprendible en la hiperesfera, eliminando la necesidad de modelar negativos expl√≠citos. Introduce un regularizador angular para dispersar los datos no etiquetados y mejora la separaci√≥n con garant√≠as te√≥ricas y resultados superiores en benchmarks.</p>
                    <div class="paper-points">‚Ä¢ Aprendizaje PU (Positive-Unlabeled)
‚Ä¢  Prototipo en hiperesfera
‚Ä¢  Regularizaci√≥n angular
‚Ä¢  Sin necesidad de negativos expl√≠citos
‚Ä¢  Superior a m√©todos estado del arte con pocos positivos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06785" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Nash de Ganancia Peque√±a: Contracci√≥n Certificada hacia Equilibrios de Nash en Juegos Diferenciables</h3>
                    <p class="paper-summary">üìù Introduce Small-Gain Nash (SGN), una condici√≥n de contracci√≥n en geometr√≠as personalizadas para garantizar convergencia en juegos donde el pseudo-gradiente no es mon√≥tono en el sentido euclidiano. Convierte cotas de curvatura y acoplamiento en un certificado de contracci√≥n, identificando una &#x27;banda de escala de tiempo&#x27; certificada para din√°micas con un solo tama√±o de paso. Valida en juegos cuadr√°ticos y extiende a geometr√≠as de espejo para juegos de Markov.</p>
                    <div class="paper-points">‚Ä¢ Convergencia en juegos
‚Ä¢  Condici√≥n Small-Gain Nash
‚Ä¢  Geometr√≠a ponderada por bloques
‚Ä¢  Certificado de contracci√≥n
‚Ä¢  Juegos no mon√≥tonos
‚Ä¢  Tama√±os de paso seguros.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06791" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üèó</span>
                    <h3 class="paper-title">Ô∏è Dise√±o Inverso Parcial de Hormig√≥n de Alto Rendimiento Usando Redes Neuronales Cooperativas para Generaci√≥n de Mezclas Consciente de Restricciones</h3>
                    <p class="paper-summary">üìù Propone un marco de redes neuronales cooperativas para el dise√±o inverso parcial de hormig√≥n, donde algunas variables de la mezcla est√°n fijas. Combina un modelo de imputaci√≥n que infiere variables indeterminadas y un modelo sustituto que predice la resistencia a compresi√≥n, generando dise√±os v√°lidos en un solo paso. Supera a enfoques basados en autoencoders e inferencia bayesiana en precisi√≥n y eficiencia computacional.</p>
                    <div class="paper-points">‚Ä¢ Dise√±o inverso de hormig√≥n
‚Ä¢  Redes neuronales cooperativas
‚Ä¢  Modelo de imputaci√≥n y sustituto
‚Ä¢  Restricciones pr√°cticas
‚Ä¢  Mejora de R¬≤ y reducci√≥n de error.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06813" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîß</span>
                    <h3 class="paper-title">Diagn√≥stico de Fallos en Rodamientos Basado en Factorizaci√≥n Neuronal</h3>
                    <p class="paper-summary">üìù Estudia el diagn√≥stico de fallos en rodamientos de trenes de alta velocidad. Propone un marco de Clasificaci√≥n Basada en Factorizaci√≥n Neuronal (NFC) que incrusta series temporales de vibraci√≥n en vectores de caracter√≠sticas latentes modales y los fusiona usando principios de factorizaci√≥n neural. Instanciado en modelos CP-NFC y Tucker-NFC, logra un rendimiento de diagn√≥stico superior a m√©todos tradicionales de machine learning.</p>
                    <div class="paper-points">‚Ä¢ Diagn√≥stico de fallos en rodamientos
‚Ä¢  Factorizaci√≥n neural
‚Ä¢  Series temporales de vibraci√≥n
‚Ä¢  Fusi√≥n CP y Tucker
‚Ä¢  Aplicaci√≥n en trenes de alta velocidad.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06837" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Conoce tu Trayectoria: Despliegue Confiable de Aprendizaje por Refuerzo mediante An√°lisis de Importancia de Trayectorias</h3>
                    <p class="paper-summary">üìù Aborda la necesidad de explicar el comportamiento a largo plazo de agentes de RL. Introduce un marco que clasifica trayectorias completas usando una nueva m√©trica de importancia de estado que combina diferencia de valores-Q y un &#x27;t√©rmino radical&#x27;. Identifica trayectorias √≥ptimas y genera rollouts contrafactuales para explicaciones del tipo &#x27;¬øPor qu√© esto y no aquello?&#x27;, mejorando la confiabilidad de sistemas aut√≥nomos.</p>
                    <div class="paper-points">‚Ä¢ RL Explicable (XRL)
‚Ä¢  An√°lisis a nivel de trayectoria
‚Ä¢  M√©trica de importancia de estado
‚Ä¢  Rollouts contrafactuales
‚Ä¢  Explicaciones &#x27
‚Ä¢ Why this
‚Ä¢  not that?&#x27
‚Ä¢ .</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06917" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Modelo de Recompensa Sem√°ntica Guiado por Padre (PGSRM): Funciones de Recompensa Basadas en Incrustaciones para RL de Modelos de Lenguaje Transformer</h3>
                    <p class="paper-summary">üìù Introduce PGSRM, un marco liviano de recompensa para RL de modelos de lenguaje transformer. Reemplaza se√±ales binarias o datos de preferencia humana con la similitud coseno entre la incrustaci√≥n de la salida de referencia de un modelo &#x27;padre&#x27; y la generada por un modelo &#x27;hijo&#x27;. Proporciona una recompensa densa y sem√°nticamente significativa sin anotaci√≥n humana, mejorando la estabilidad del entrenamiento PPO en tareas de lenguaje.</p>
                    <div class="paper-points">‚Ä¢ Aprendizaje por Refuerzo para LLMs
‚Ä¢  Recompensa basada en similitud sem√°ntica
‚Ä¢  Alineaci√≥n guiada por padre
‚Ä¢  Sin anotaci√≥n humana
‚Ä¢  Alternativa a RLHF.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06920" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo Profundo para Detecci√≥n de Phishing con Caracter√≠sticas Sem√°nticas Basadas en Transformer</h3>
                    <p class="paper-summary">üìù Propone un enfoque Quantile Regression Deep Q-Network (QR-DQN) que integra incrustaciones sem√°nticas de RoBERTa con caracter√≠sticas l√©xicas artesanales para detectar phishing. Modela la distribuci√≥n de retornos para mejorar la estabilidad y generalizaci√≥n. En un dataset de 105,000 URLs, logra una precisi√≥n del 99.86% y reduce significativamente la brecha de generalizaci√≥n comparado con DQN est√°ndar.</p>
                    <div class="paper-points">‚Ä¢ Detecci√≥n de phishing
‚Ä¢  QR-DQN
‚Ä¢  Incrustaciones sem√°nticas de RoBERTa
‚Ä¢  Caracter√≠sticas l√©xicas
‚Ä¢  Modelado de incertidumbre
‚Ä¢  Alta precisi√≥n y robustez.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06925" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Evaluando la Sensibilidad de Modelos de Pron√≥stico BiLSTM a la Longitud de Secuencia y al Ruido de Entrada</h3>
                    <p class="paper-summary">üìù Analiza sistem√°ticamente c√≥mo la longitud de la secuencia de entrada y el ruido aditivo afectan la robustez y generalizaci√≥n de modelos BiLSTM para pron√≥stico de series temporales. Encuentra que secuencias m√°s largas aumentan el sobreajuste, el ruido degrada la precisi√≥n y su combinaci√≥n causa la mayor inestabilidad. Destaca la necesidad de estrategias de dise√±o conscientes de los datos para sistemas de pron√≥stico confiables.</p>
                    <div class="paper-points">‚Ä¢ Pron√≥stico de series temporales
‚Ä¢  BiLSTM
‚Ä¢  Robustez
‚Ä¢  Longitud de secuencia
‚Ä¢  Ruido aditivo
‚Ä¢  Sobreajuste y fugas de datos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06926" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üìà Mamba de Normalizaci√≥n Adaptativa con Descomposici√≥n de Tendencia Multiescala y Codificaci√≥n Parche MoE</h3>
                    <p class="paper-summary">üìù Propone AdaMamba, una arquitectura unificada para pron√≥stico de series temporales que integra normalizaci√≥n adaptativa, extracci√≥n de tendencia multiescala y modelado contextual. Utiliza un bloque de normalizaci√≥n adaptativa, un codificador de contexto con parches y una capa Transformer mejorada con Mamba y Mixture of Experts (MoE). Mitiga cambios de distribuci√≥n y mejora la estabilidad y precisi√≥n predictiva frente a baselines Transformer convencionales.</p>
                    <div class="paper-points">‚Ä¢ Pron√≥stico de series temporales
‚Ä¢  Normalizaci√≥n adaptativa
‚Ä¢  Mamba
‚Ä¢  Descomposici√≥n de tendencia multiescala
‚Ä¢  Mixture of Experts (MoE)
‚Ä¢  Mitigaci√≥n de covariate shift.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06929" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚ö†Ô∏è Fugas Ocultas en el Pron√≥stico de Series Temporales: C√≥mo la Fuga de Datos Afecta la Evaluaci√≥n de LSTM en Configuraciones y Estrategias de Validaci√≥n</h3>
                    <p class="paper-summary">üìù Investiga el impacto de la fuga de datos (data leakage) en la evaluaci√≥n de modelos LSTM para pron√≥stico. Compara estrategias de validaci√≥n (2-way, 3-way, 10-fold CV) bajo condiciones con y sin fuga. Encuentra que la validaci√≥n cruzada 10-fold es m√°s susceptible (hasta 20.5% de aumento en RMSE), mientras que los splits simples son m√°s robustos. El tama√±o de ventana y el lag step influyen significativamente en la sensibilidad a la fuga.</p>
                    <div class="paper-points">‚Ä¢ Fuga de datos en series temporales
‚Ä¢  Evaluaci√≥n de modelos LSTM
‚Ä¢  Estrategias de validaci√≥n
‚Ä¢  Robustez
‚Ä¢  Tama√±o de ventana y lag step
‚Ä¢  RMSE Gain.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06932" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üî¨</span>
                    <h3 class="paper-title">Un Marco Unificador de Equidad en IA Centrado en el Ser Humano</h3>
                    <p class="paper-summary">üìù Se presenta un marco para la equidad en IA que combina ocho m√©tricas distintas, permitiendo a las partes interesadas ponderar diferentes objetivos de equidad seg√∫n sus valores. El marco ayuda a navegar las compensaciones entre diferentes nociones de equidad y precisi√≥n predictiva. Se aplica a conjuntos de datos del mundo real como predicci√≥n de ingresos y evaluaci√≥n de riesgo crediticio.</p>
                    <div class="paper-points">‚Ä¢ Marco unificador que cubre 8 m√©tricas de equidad
‚Ä¢  permite ponderar objetivos m√∫ltiples
‚Ä¢  aplicado a 4 conjuntos de datos reales
‚Ä¢  facilita decisiones pr√°cticas sensibles a valores.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06944" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Comparaci√≥n de BFGS y OGR para Optimizaci√≥n de Segundo Orden</h3>
                    <p class="paper-summary">üìù Compara el m√©todo cl√°sico BFGS con un nuevo enfoque llamado Regresi√≥n de Gradiente en L√≠nea (OGR) para estimar la matriz Hessiana en el entrenamiento de redes neuronales. OGR permite estimar un Hessiano general (no necesariamente definido positivo) y manejar estructuras no convexas. En entornos no convexos, OGR logra una convergencia m√°s r√°pida y una p√©rdida mejorada.</p>
                    <div class="paper-points">‚Ä¢ OGR estima segundas derivadas en l√≠nea sin invertir el Hessiano
‚Ä¢  maneja estructuras no convexas
‚Ä¢  converge m√°s r√°pido que BFGS en configuraciones no convexas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06969" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Predicci√≥n con Consejo de Expertos bajo Privacidad Diferencial Local</h3>
                    <p class="paper-summary">üìù Estudia el problema cl√°sico de predicci√≥n con consejo de expertos bajo la restricci√≥n de privacidad diferencial local (LDP). Presenta dos nuevos algoritmos, RW-AdaBatch y RW-Meta, que mejoran el rendimiento. RW-Meta supera al algoritmo de l√≠nea base y a un algoritmo de DP central de √∫ltima generaci√≥n en la predicci√≥n de datos hospitalarios de COVID-19.</p>
                    <div class="paper-points">‚Ä¢ Nuevos algoritmos RW-AdaBatch y RW-Meta para LDP
‚Ä¢  RW-Meta supera algoritmos de √∫ltima generaci√≥n en datos de COVID-19
‚Ä¢  an√°lisis con l√≠mites de arrepentimiento formales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06971" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">B√∫squeda de Arquitectura Neural Compuesta Impulsada por LLM para Codificaci√≥n de Estado en RL Multifuente</h3>
                    <p class="paper-summary">üìù Propone una canalizaci√≥n de B√∫squeda de Arquitectura Neural (NAS) impulsada por LLM para dise√±ar codificadores de estado compuestos en Aprendizaje por Refuerzo (RL) con m√∫ltiples fuentes de informaci√≥n. El m√©todo aprovecha se√±ales de salida intermedia y conocimientos previos de modelos de lenguaje. Descubre arquitecturas de mayor rendimiento con menos evaluaciones de candidatos en una tarea de control de tr√°fico.</p>
                    <div class="paper-points">‚Ä¢ NAS impulsado por LLM para RL multifuente
‚Ä¢  utiliza se√±ales de salida intermedia
‚Ä¢  m√°s eficiente en muestras que los baselines tradicionales y GENIUS.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06982" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">OXtal: Un Modelo de Difusi√≥n de Todos los √Åtomos para la Predicci√≥n de Estructuras de Cristales Org√°nicos</h3>
                    <p class="paper-summary">üìù Presenta OXtal, un modelo de difusi√≥n a gran escala para predecir estructuras cristalinas 3D a partir de gr√°ficos qu√≠micos 2D. Utiliza un esquema de entrenamiento novedoso que evita la parametrizaci√≥n expl√≠cita de la red cristalina. Entrenado con 600K estructuras experimentales, logra mejoras de √≥rdenes de magnitud sobre m√©todos previos de predicci√≥n de estructuras cristalinas (CSP).</p>
                    <div class="paper-points">‚Ä¢ Modelo de difusi√≥n para predicci√≥n de estructuras cristalinas
‚Ä¢  esquema de entrenamiento &#x27
‚Ä¢ S^4&#x27
‚Ä¢  sin red expl√≠cita
‚Ä¢  entrena con 600K estructuras
‚Ä¢  supera significativamente m√©todos ab initio anteriores.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06987" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Flash Multi-Head Feed-Forward Network</h3>
                    <p class="paper-summary">üìù Propone Flash Multi-Head FFN (FlashMHF) como reemplazo de la FFN en la arquitectura Transformer. Incluye un n√∫cleo fusionado consciente de E/S y un dise√±o con sub-redes paralelas ponderadas din√°micamente. FlashMHF mejora la perplejidad y la precisi√≥n en tareas posteriores sobre SwiGLU, reduce el uso de memoria y acelera la inferencia.</p>
                    <div class="paper-points">‚Ä¢ FlashMHF reemplaza FFNs en Transformers
‚Ä¢  reduce memoria 3-5x
‚Ä¢  acelera inferencia hasta 1.08x
‚Ä¢  mejora perplejidad y precisi√≥n en modelos de 128M a 1.3B par√°metros.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06989" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Hacia el Olvido en M√°quina Confiable: Teor√≠a, Algoritmos y Evaluaci√≥n</h3>
                    <p class="paper-summary">üìù Introduce nuevos m√©todos para el &#x27;olvido&#x27; en machine learning, incluyendo AMUN para olvidar muestras aleatorias y TRW para olvidar clases enteras. AMUN reduce la confianza del modelo en muestras a &#x27;olvidar&#x27; usando ejemplos adversarios. TRW mitiga fugas de informaci√≥n ajustando la distribuci√≥n de salida para clases olvidadas.</p>
                    <div class="paper-points">‚Ä¢ AMUN para olvidar muestras usando ejemplos adversarios
‚Ä¢  TRW para olvido de clases
‚Ä¢  superan m√©todos anteriores
‚Ä¢  an√°lisis te√≥rico de factores como suavidad.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06993" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">DynamicLRP: Una Soluci√≥n Agn√≥stica al Modelo para la Propagaci√≥n de Relevancia por Capas</h3>
                    <p class="paper-summary">üìù Presenta DynamicLRP, un marco agn√≥stico de modelo para la Propagaci√≥n de Relevancia por Capas (LRP) que opera a nivel de operaci√≥n tensorial. Introduce un &#x27;Sistema de Promesa&#x27; para la resoluci√≥n diferida de activaciones. Logra una alta cobertura en diversos modelos sin c√≥digo espec√≠fico, manteniendo las garant√≠as te√≥ricas de LRP.</p>
                    <div class="paper-points">‚Ä¢ Framework LRP agn√≥stico a nivel de operaci√≥n
‚Ä¢  Sistema de Promesa para activaciones diferidas
‚Ä¢  99.92% de cobertura en nodos de gr√°ficos de computaci√≥n
‚Ä¢  funciona en modelos diversos como Mamba y Whisper.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07010" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Atenci√≥n Flash con Bloque Disperso</h3>
                    <p class="paper-summary">üìù Presenta Block-Sparse FlashAttention (BSFA), un reemplazo directo que acelera la inferencia de contextos largos preservando la calidad del modelo. Selecciona los bloques de valor m√°s importantes para cada consulta bas√°ndose en puntuaciones exactas. Requiere una √∫nica calibraci√≥n de umbrales y logra aceleraciones en tareas de razonamiento y recuperaci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Reemplazo directo de FlashAttention
‚Ä¢  selecciona top-k bloques importantes
‚Ä¢  acelera inferencia (hasta 1.24x)
‚Ä¢  mantiene &gt
‚Ä¢ 99% de precisi√≥n base
‚Ä¢  calibraci√≥n de umbrales √∫nica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07011" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Transferencia de Conocimiento Cl√≠nico a la Representaci√≥n de ECG</h3>
                    <p class="paper-summary">üìù Propone un paradigma de entrenamiento de tres etapas para transferir conocimiento de datos cl√≠nicos multimodales a un codificador de ECG unimodal. El modelo resultante es m√°s preciso y confiable, prediciendo tanto diagn√≥sticos como anomal√≠as de laboratorio asociadas. Supera a un modelo baseline de solo se√±al y se acerca al rendimiento de un modelo multimodal completo.</p>
                    <div class="paper-points">‚Ä¢ Entrenamiento en 3 etapas para enriquecer representaciones de ECG
‚Ä¢  predice diagn√≥sticos y anomal√≠as de laboratorio
‚Ä¢  m√°s preciso y explicable que baseline de solo se√±al
‚Ä¢  usa solo ECG en inferencia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07021" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Transformaci√≥n de Redes Biol√≥gicas en Im√°genes mediante Cartograf√≠a Sem√°ntica para Interpretaci√≥n Visual y An√°lisis Profundo Escalable</h3>
                    <p class="paper-summary">üìù Presenta Graph2Image, un framework que convierte grandes redes biol√≥gicas en im√°genes 2D, permitiendo el uso de CNNs. Supera limitaciones de escalabilidad, captura de dependencias de largo alcance e interpretabilidad. Logra mejoras de hasta 67.2% en precisi√≥n y permite analizar redes con m√°s de mil millones de nodos en un ordenador personal.</p>
                    <div class="paper-points">‚Ä¢ Conversi√≥n de redes a im√°genes 2D
‚Ä¢  Uso de CNNs con campos receptivos globales
‚Ä¢  Mejora escalabilidad e interpretabilidad
‚Ä¢  Integraci√≥n multimodal con otras √≥micas
‚Ä¢  Alta precisi√≥n en clasificaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07040" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚öó</span>
                    <h3 class="paper-title">Ô∏è Aprendizaje Autosupervisado en Grafos Moleculares: Una Investigaci√≥n Sistem√°tica del Dise√±o de Enmascaramiento</h3>
                    <p class="paper-summary">üìù Investiga de forma controlada y te√≥rica las estrategias de enmascaramiento en el preentrenamiento autosupervisado para grafos moleculares. Encuentra que las distribuciones de enmascaramiento sofisticadas no superan consistentemente al muestreo uniforme. La elecci√≥n del objetivo de predicci√≥n y su sinergia con la arquitectura del codificador son m√°s cr√≠ticas.</p>
                    <div class="paper-points">‚Ä¢ Evaluaci√≥n sistem√°tica de estrategias de enmascaramiento (SSL)
‚Ä¢  Comparaci√≥n en un marco probabil√≠stico unificado
‚Ä¢  El objetivo de predicci√≥n es m√°s crucial que la distribuci√≥n de enmascaramiento
‚Ä¢  Sinergia entre objetivo y arquitectura del codificador (ej. Graph Transformers).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07064" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß™</span>
                    <h3 class="paper-title">Lecho de Procusto para la Retros√≠ntesis Impulsada por IA: Un Marco Unificado para Evaluaci√≥n Reproducible</h3>
                    <p class="paper-summary">üìù Introduce RetroCast, un conjunto de evaluaci√≥n unificado para la planificaci√≥n de s√≠ntesis asistida por computadora (CASP). Estandariza las salidas de modelos heterog√©neos para permitir comparaciones rigurosas. Revela una divergencia entre la &#x27;solubilidad&#x27; (tasa de terminaci√≥n) y la calidad real de las rutas sint√©ticas.</p>
                    <div class="paper-points">‚Ä¢ Marco RetroCast para evaluaci√≥n estandarizada en retros√≠ntesis
‚Ä¢  Divergencia entre m√©tricas de &#x27
‚Ä¢ solubilidad&#x27
‚Ä¢  y validez/qu√≠mica real
‚Ä¢  Identifica un &#x27
‚Ä¢ precipicio de complejidad&#x27
‚Ä¢  para m√©todos basados en b√∫squeda
‚Ä¢  Libera infraestructura para desarrollo reproducible.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07079" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ TRACE: Un Detector de Deriva Generalizable para Optimizaci√≥n Basada en Datos en Flujo Continuo</h3>
                    <p class="paper-summary">üìù Propone TRACE, un detector de deriva de concepto transferible para optimizaci√≥n con datos en flujo continuo (SDDO). Utiliza una estrategia de tokenizaci√≥n y aprendizaje de secuencias basado en atenci√≥n para detectar cambios de distribuci√≥n en diversas escalas de tiempo. Se integra como un componente plug-and-play en optimizadores adaptativos.</p>
                    <div class="paper-points">‚Ä¢ Detecci√≥n de deriva de concepto en datos en flujo continuo
‚Ä¢  Enfoque basado en tokenizaci√≥n y atenci√≥n para patrones transferibles
‚Ä¢  Naturaleza plug-and-play para optimizaci√≥n adaptativa
‚Ä¢  Generalizaci√≥n robusta en benchmarks diversos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07082" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">La Geometr√≠a de la Persona: Disentangling de la Personalidad del Razonamiento en Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Propone el &#x27;Soul Engine&#x27;, un framework basado en la Hip√≥tesis de Representaci√≥n Lineal para desenredar rasgos de personalidad en LLMs sin modificar los pesos base. Logra perfiles de alta precisi√≥n, ortogonalidad geom√©trica e inyecci√≥n de personalidad &#x27;zero-shot&#x27;, manteniendo las capacidades de razonamiento originales.</p>
                    <div class="paper-points">‚Ä¢ Desentrelaza personalidad y razonamiento en subespacios lineales ortogonales
‚Ä¢  &#x27
‚Ä¢ Soul Engine&#x27
‚Ä¢  con arquitectura de dos cabezas sobre base congelada
‚Ä¢  Inyecci√≥n de personalidad &#x27
‚Ä¢ zero-shot&#x27
‚Ä¢  sin degradaci√≥n
‚Ä¢  Control determin√≠stico del comportamiento mediante aritm√©tica vectorial.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07092" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ Aprendizaje de Ciclo de Refinamiento Dual: Clasificaci√≥n de Texto no Supervisada con Mamba y Detecci√≥n de Comunidades en Grafos con Atributos de Texto</h3>
                    <p class="paper-summary">üìù Presenta DRCL, un framework no supervisado que integra informaci√≥n estructural y sem√°ntica en grafos con atributos de texto. Combina un m√≥dulo de detecci√≥n de comunidades basado en GCN y un m√≥dulo de modelado sem√°ntico de texto (con Mamba) en un ciclo de refinamiento bidireccional, intercambiando etiquetas pseudo.</p>
                    <div class="paper-points">‚Ä¢ Framework totalmente no supervisado (DRCL) para grafos con texto
‚Ä¢  Ciclo de refinamiento bidireccional entre estructura (GCN) y sem√°ntica (Mamba)
‚Ä¢  Entrenamiento de clasificador Mamba con se√±ales de comunidad
‚Ä¢  Aplicable a escenarios del mundo real sin etiquetas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07100" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíæ</span>
                    <h3 class="paper-title">FOAM: Plegado de Estado Bloqueado para el Entrenamiento Eficiente en Memoria de LLMs</h3>
                    <p class="paper-summary">üìù Introduce FOAM, un m√©todo que comprime los estados del optimizador (ej. Adam) durante el entrenamiento de LLMs. Calcula medias de gradientes por bloques e incorpora una correcci√≥n residual para recuperar informaci√≥n. Reduce la memoria total de entrenamiento ~50% y la sobrecarga de estados del optimizador hasta un 90%.</p>
                    <div class="paper-points">‚Ä¢ Compresi√≥n de estados del optimizador para ahorrar memoria en LLMs
‚Ä¢  T√©cnica de plegado por bloques con correcci√≥n residual
‚Ä¢  Reducci√≥n de ~50% de memoria total y ~90% de estados del optimizador
‚Ä¢  Mantiene tasas de convergencia equivalentes al Adam est√°ndar.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07112" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üå± PlantBiMoE: Un Modelo Fundacional Bidireccional con SparseMoE para Genomas de Plantas</h3>
                    <p class="paper-summary">üìù Propone PlantBiMoE, un modelo de lenguaje ligero y expresivo para genomas de plantas que combina Mamba bidireccional y una Mixture-of-Experts (MoE) Dispersa. Captura dependencias estructurales en ambas hebras de ADN y reduce par√°metros activos. Logra el mejor rendimiento en 20 de 31 datasets de un benchmark gen√≥mico.</p>
                    <div class="paper-points">‚Ä¢ Modelo de lenguaje para genomas de plantas con Mamba bidireccional y SparseMoE
‚Ä¢  Captura dependencias en ambas hebras del ADN
‚Ä¢  Ligero y eficiente computacionalmente
‚Ä¢  Alto rendimiento en tareas gen√≥micas diversas (MPGB).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07113" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üéØ</span>
                    <h3 class="paper-title">Ganando la Loter√≠a Preservando la Din√°mica de Entrenamiento de la Red con B√∫squeda de Tickets de Concreto</h3>
                    <p class="paper-summary">üìù Introduce Concrete Ticket Search (CTS), un algoritmo que enmarca la b√∫squeda de subredes (&#x27;tickets ganadores&#x27;) como un problema de optimizaci√≥n combinatoria. Utiliza una relajaci√≥n de Concreto del espacio de b√∫squeda y un esquema de balance de gradientes (GRADBALANCE). Identifica subredes de alto rendimiento cerca de la inicializaci√≥n, superando a m√©todos basados en saliencia y rivalizando con LTR.</p>
                    <div class="paper-points">‚Ä¢ B√∫squeda de subredes dispersas (&#x27
‚Ä¢ lottery tickets&#x27
‚Ä¢ ) como optimizaci√≥n combinatoria
‚Ä¢  Algoritmo CTS con relajaci√≥n de Concreto y balance de gradientes
‚Ä¢  Supera m√©todos de poda en inicializaci√≥n (PaI) y rivaliza con LTR en precisi√≥n
‚Ä¢  Especialmente eficaz en reg√≠menes de alta dispersi√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07142" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üñºÔ∏è FlowLPS: Muestreo Langevin-Proximal para Solucionadores de Problemas Inversos basados en Flujo</h3>
                    <p class="paper-summary">üìù Propone FlowLPS, un framework sin entrenamiento para resolver problemas inversos con modelos de flujo generativos preentrenados. Combina din√°micas de Langevin para exploraci√≥n consistente en la variedad latente y optimizaci√≥n proximal para b√∫squeda precisa del modo. Logra un equilibrio superior entre fidelidad de reconstrucci√≥n y calidad perceptual.</p>
                    <div class="paper-points">‚Ä¢ Soluci√≥n de problemas inversos con modelos de flujo (flow) preentrenados
‚Ä¢  Estrategia Langevin Proximal Sampling (LPS) para exploraci√≥n y b√∫squeda de modos
‚Ä¢  Evita la desviaci√≥n de la variedad (manifold deviation) en espacios latentes
‚Ä¢  Supera al estado del arte en tareas inversas en FFHQ y DIV2K.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07150" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Mejora del Rendimiento de LLMs Basados en Difusi√≥n Mediante una Calibraci√≥n Consciente de la Confianza sin Entrenamiento</h3>
                    <p class="paper-summary">üìù Se presenta CadLLM, un m√©todo sin entrenamiento para acelerar la inferencia en LLMs basados en difusi√≥n. El m√©todo adapta din√°micamente el tama√±o del bloque de generaci√≥n y el paso bas√°ndose en la confianza promedio de los tokens revelados. Tambi√©n reduce la sobrecarga del softmax utilizando un subconjunto din√°mico del vocabulario, logrando mejoras de rendimiento de hasta 2.28x.</p>
                    <div class="paper-points">‚Ä¢ M√©todo plug-and-play y agn√≥stico al modelo. Calibraci√≥n adaptativa basada en confianza. Reducci√≥n de la sobrecarga computacional del softmax. Compatible con modelos que usan cach√© KV.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07173" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">SPACE: La Estimaci√≥n de Contraste de Ruido Estabiliza el Ajuste Fino por Auto-Juego para Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Se introduce SPACE, un nuevo m√©todo de ajuste fino por auto-juego que utiliza estimaci√≥n de contraste de ruido para capturar la distribuci√≥n de datos del mundo real. Trata las muestras sint√©ticas como componentes auxiliares y las discrimina de las reales, optimizando los valores de recompensa absoluta para cada tipo de dato, lo que garantiza una convergencia estable.</p>
                    <div class="paper-points">‚Ä¢ Evita la inestabilidad de m√©todos basados en brechas. Objetivo alineado con la distribuci√≥n subyacente de datos reales. Supera al ajuste fino supervisado que usa m√°s muestras. Convergencia estable y demostrable.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07175" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">UniDiff: Un Marco de Difusi√≥n Unificado para la Predicci√≥n de Series Temporales Multimodales</h3>
                    <p class="paper-summary">üìù Propone UniDiff, un marco de difusi√≥n unificado para predicci√≥n de series temporales que integra informaci√≥n heterog√©nea (textos y marcas de tiempo). Utiliza un m√≥dulo de fusi√≥n paralelo con atenci√≥n cruzada y un mecanismo de gu√≠a sin clasificador para control desacoplado de la informaci√≥n textual y temporal durante la inferencia.</p>
                    <div class="paper-points">‚Ä¢ Modelado unificado de secuencias num√©ricas
‚Ä¢  textos y timestamps. Fusi√≥n paralela y eficiente mediante atenci√≥n cruzada. Gu√≠a sin clasificador para control multi-fuente. Rendimiento de vanguardia en m√∫ltiples dominios.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07184" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üöå Menos es M√°s: Los Segmentos de Carretera No Uniformes son Eficientes para la Predicci√≥n de Llegada de Autobuses</h3>
                    <p class="paper-summary">üìù Propone un m√©todo basado en Aprendizaje por Refuerzo (RL) para aprender segmentos de carretera no uniformes de manera adaptativa para la predicci√≥n del tiempo de llegada. Desacopla el proceso en extracci√≥n de segmentos √≥ptimos y un modelo lineal de predicci√≥n, logrando mayor eficiencia y rendimiento que los enfoques uniformes tradicionales.</p>
                    <div class="paper-points">‚Ä¢ Segmentaci√≥n no uniforme aprendida mediante RL. Desacoplamiento en dos etapas: selecci√≥n y predicci√≥n lineal. Mejora la eficiencia y el rendimiento de aprendizaje. El enfoque lineal puede superar a m√©todos complejos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07200" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Calibraci√≥n de Prompts Federada Guiada por un Prior Geom√©trico</h3>
                    <p class="paper-summary">üìù Presenta GGTPC, un marco que mitiga la heterogeneidad de datos en el Aprendizaje de Prompts Federado (FPL) corrigiendo el sesgo del entrenamiento local. Proporciona a los clientes un prior geom√©trico global (forma de la distribuci√≥n) reconstruido en el servidor, que usan para alinear sus distribuciones locales mediante una capa de calibraci√≥n (GPCL).</p>
                    <div class="paper-points">‚Ä¢ Corrige el sesgo fundamental del entrenamiento local. Prior geom√©trico global obtenido de manera que preserva la privacidad. M√≥dulo plug-and-play para mejorar algoritmos de FL. Efectivo bajo sesgos extremos de etiquetas y dominios.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07208" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üëÅÔ∏èüí¨ Presta Menos Atenci√≥n a las Palabras Funcionales para una Robustez Gratuita en Modelos de Visi√≥n-Lenguaje</h3>
                    <p class="paper-summary">üìù Observa que las palabras funcionales generan vulnerabilidad en VLMs frente a ataques adversariales cruzados. Propone FDA (Function-word De-Attention), que resta diferencialmente la atenci√≥n cruzada de palabras funcionales de la atenci√≥n original dentro de las cabezas de atenci√≥n, logrando modelos m√°s alineados y robustos con m√≠nima p√©rdida de rendimiento.</p>
                    <div class="paper-points">‚Ä¢ Mitiga el impacto de palabras funcionales vulnerables. Mecanismo inspirado en amplificadores diferenciales. Reducciones significativas en la tasa de √©xito de ataques (ASR). Escalable
‚Ä¢  generalizable y con buen rendimiento zero-shot.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07222" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üï∏Ô∏è PINE: Canalizaci√≥n para la Exploraci√≥n de Nodos Importantes en Redes con Atributos</h3>
                    <p class="paper-summary">üìù Introduce PINE, una canalizaci√≥n no supervisada y consciente de los atributos para identificar nodos importantes en redes atributadas. Utiliza un modelo de grafos basado en atenci√≥n que incorpora caracter√≠sticas sem√°nticas de los nodos en el aprendizaje de las propiedades estructurales del grafo, generando puntuaciones de importancia.</p>
                    <div class="paper-points">‚Ä¢ Enfoque no supervisado y consciente de atributos. Modelo de atenci√≥n que fusiona caracter√≠sticas sem√°nticas y estructura. Aplicable a grafos homog√©neos y heterog√©neos. Implementado para identificar entidades clave en grafos empresariales a gran escala.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07244" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öñÔ∏è IFFair: Reponderaci√≥n de Muestras Impulsada por Funciones de Influencia para Clasificaci√≥n Justa</h3>
                    <p class="paper-summary">üìù Propone IFFair, un m√©todo de pre-procesamiento basado en la funci√≥n de influencia que mitiga el sesgo en clasificaci√≥n. Gu√≠a el ajuste din√°mico de los pesos de las muestras durante el entrenamiento seg√∫n la disparidad de influencia en diferentes grupos, sin modificar la estructura de la red, las caracter√≠sticas o los l√≠mites de decisi√≥n.</p>
                    <div class="paper-points">‚Ä¢ Optimiza m√∫ltiples m√©tricas de equidad (paridad demogr√°fica
‚Ä¢  odds igualados
‚Ä¢  etc.). M√©todo de pre-procesamiento que no altera el modelo. Logra un mejor equilibrio entre utilidad y equidad. Eval√∫a su validez en m√∫ltiples conjuntos de datos reales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07249" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üß∞ SIT-Graph: Grafo de Herramientas con Estado Integrado para Agentes de M√∫ltiples Turnos</h3>
                    <p class="paper-summary">üìù Propone SIT-Graph, un grafo que mejora el uso de herramientas en m√∫ltiples turnos al explotar experiencias superpuestas. Captura tanto representaciones compactas de estados (fragmentos epis√≥dicos) como dependencias entre herramientas (rutinas procedurales) de trayectorias hist√≥ricas, permitiendo un equilibrio entre recuerdo epis√≥dico y ejecuci√≥n procedural.</p>
                    <div class="paper-points">‚Ä¢ Mejora la selecci√≥n de herramientas en escenarios multi-turno con estado. Combina memoria epis√≥dica (estados) y procedural (dependencias). Permite adaptaci√≥n seg√∫n la necesidad de contexto o rutina. Supera a l√≠neas base basadas en memoria y grafos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07287" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Hacia un Transformer Consciente de las Relaciones para Datos Tabulares</h3>
                    <p class="paper-summary">üìù Propone modificaciones al mecanismo de atenci√≥n en Transformers para tener en cuenta posibles relaciones o dependencias externas entre muestras de datos tabulares, √∫til para tareas como la estimaci√≥n del efecto del tratamiento. Los modelos se comparan con √°rboles de decisi√≥n con boosting en tareas de regresi√≥n y estimaci√≥n de efectos.</p>
                    <div class="paper-points">‚Ä¢ Extiende Transformers para datos tabulares con relaciones externas. Mecanismo de atenci√≥n modificado con un t√©rmino adicional para relaciones. Aplicable a grafos dispersos donde las GNNs tienen dificultades. Evaluado en estimaci√≥n de efectos de tratamiento (IHDP) y regresi√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07310" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Alquiler de Esqu√≠ Mejorado por Aprendizaje con Distribuciones Discretas: Un Enfoque Bayesiano</h3>
                    <p class="paper-summary">üìù Revisita el cl√°sico problema del alquiler de esqu√≠ mediante la toma de decisiones bayesiana y predicciones aprendidas por m√°quina. Propone un marco de trabajo bayesiano discreto que mantiene distribuciones posteriores exactas, permitiendo la cuantificaci√≥n de incertidumbre y la incorporaci√≥n de distribuciones previas de expertos. Logra garant√≠as competitivas dependientes de la distribuci√≥n previa y un rendimiento emp√≠rico superior.</p>
                    <div class="paper-points">‚Ä¢ Unificaci√≥n de algoritmos tradicionales y enfoques aumentados por aprendizaje. Marco bayesiano para cuantificaci√≥n de incertidumbre. Interpolaci√≥n entre garant√≠as de caso peor y escenarios con informaci√≥n completa.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07313" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Incrustaci√≥n de Grafos de Conocimiento Consciente de la Curvatura Local: Un Enfoque de Flujo de Ricci Extendido</h3>
                    <p class="paper-summary">üìù Propone RicciKGE, un m√©todo donde la p√©rdida de la incrustaci√≥n del grafo de conocimiento (KGE) se acopla con curvaturas locales en un flujo de Ricci extendido. Permite que las incrustaciones de entidades co-evolucionen din√°micamente con la geometr√≠a del colector subyacente. Demuestra te√≥ricamente la convergencia a un √≥ptimo global y mejoras experimentales en predicci√≥n de enlaces.</p>
                    <div class="paper-points">‚Ä¢ Supera la limitaci√≥n de usar un colector homog√©neo predefinido. Acoplamiento entre la optimizaci√≥n de incrustaciones y la geometr√≠a del colector. Convergencia te√≥rica y mejoras emp√≠ricas en grafos heterog√©neos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07332" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Recuperar-Para-Olvidar: Reconstrucci√≥n de Gradientes desde LoRA para el Desaprendizaje Eficiente en LLMs</h3>
                    <p class="paper-summary">üìù Introduce Recover-to-Forget (R2F), un marco para el desaprendizaje eficiente en Modelos de Lenguaje Grandes (LLMs). Reconstruye direcciones de gradiente del modelo completo a partir de actualizaciones del adaptador LoRA (de bajo rango). Entrena un decodificador de gradientes en un modelo proxy para evitar la retropropagaci√≥n completa, logrando desaprendizaje escalable y ligero.</p>
                    <div class="paper-points">‚Ä¢ Desaprendizaje sin necesidad de ajuste fino completo o acceso a datos originales. Reconstrucci√≥n de gradientes completos desde par√°metros LoRA. Transferibilidad a modelos m√°s grandes o de caja negra.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07374" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">LUNE: Desaprendizaje Eficiente en LLMs mediante Ajuste Fino LoRA con Ejemplos Negativos</h3>
                    <p class="paper-summary">üìù Presenta LUNE, un marco ligero para el desaprendizaje en LLMs que actualiza solo adaptadores de bajo rango (LoRA) mientras congela el modelo base. Realiza desaprendizaje basado √∫nicamente en ejemplos negativos, suprimiendo o reemplazando conocimiento espec√≠fico. Reduce el costo computacional en un orden de magnitud respecto a m√©todos tradicionales.</p>
                    <div class="paper-points">‚Ä¢ Actualizaci√≥n localizada solo en adaptadores LoRA. Enfoque de desaprendizaje solo con ejemplos negativos. Eficacia comparable a m√©todos de edici√≥n de memoria con mucho menor costo computacional.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07375" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Hacia una Adaptaci√≥n en Tiempo de Prueba Confiable: La Invarianza de Estilo como Probabilidad de Correctitud</h3>
                    <p class="paper-summary">üìù Introduce SICL, un marco que utiliza la invarianza de estilo para una estimaci√≥n robusta de incertidumbre en la adaptaci√≥n en tiempo de prueba (TTA). Estima la probabilidad de correctitud de cada instancia midiendo la consistencia de predicciones a trav√©s de variantes con estilos alterados. Es un m√≥dulo complementario, sin retropropagaci√≥n, que reduce el error de calibraci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Mejora la calibraci√≥n de incertidumbre en escenarios din√°micos de prueba. M√©todo plug-and-play compatible con cualquier m√©todo TTA. Reduce el error de calibraci√≥n en promedio 13 puntos porcentuales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07390" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Resultados Emp√≠ricos para Ajustar la Retropropagaci√≥n Truncada en el Tiempo al Entrenar Efectos de Audio Neuronales</h3>
                    <p class="paper-summary">üìù Investiga la optimizaci√≥n de la Retropropagaci√≥n Truncada en el Tiempo (TBPTT) para entrenar redes neuronales que modelan efectos de audio digital, como la compresi√≥n de rango din√°mico. Eval√∫a hiperpar√°metros clave (n√∫mero de secuencias, tama√±o de lote, longitud de secuencia) y su impacto en el rendimiento y la estabilidad del entrenamiento.</p>
                    <div class="paper-points">‚Ä¢ Optimizaci√≥n de hiperpar√°metros de TBPTT para modelado de efectos de audio. Mejora de precisi√≥n y estabilidad del entrenamiento. Validaci√≥n con evaluaciones objetivas y pruebas de escucha subjetivas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07393" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">An√°lisis Asint√≥tico del Olvido Superficial y Profundo en Replay con Colapso Neuronal</h3>
                    <p class="paper-summary">üìù Formaliza la distinci√≥n entre olvido en el espacio de caracter√≠sticas profundas y a nivel del clasificador superficial en aprendizaje continuo (CL). Revela una asimetr√≠a cr√≠tica en la Reexperiencia (Replay): los b√∫feres peque√±os previenen el olvido profundo, pero mitigar el olvido superficial requiere capacidades de b√∫fer mayores. Explica esto extendiendo el marco de Colapso Neuronal.</p>
                    <div class="paper-points">‚Ä¢ Distinci√≥n te√≥rica entre olvido profundo y superficial. Los b√∫feres peque√±os anclan la geometr√≠a de caracter√≠sticas pero no corrigen artefactos estad√≠sticos en el clasificador. Unificaci√≥n del CL con la detecci√≥n fuera de distribuci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07400" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üö¶ Sintonizaci√≥n Adaptativa de Controladores de Tr√°fico Parametrizados mediante Aprendizaje por Refuerzo Multi-Agente</h3>
                    <p class="paper-summary">üìù Propone un marco de aprendizaje por refuerzo multi-agente donde cada agente sintoniza adaptativamente los par√°metros de un controlador de tr√°fico por retroalimentaci√≥n de estado. Combina la reactividad de los controladores convencionales con la adaptabilidad del aprendizaje por refuerzo. Mejora la eficiencia del entrenamiento y la robustez ante fallos parciales en la red.</p>
                    <div class="paper-points">‚Ä¢ Ajuste de par√°metros de controladores
‚Ä¢  no de acciones directas. Estructura multi-agente para robustez y operaci√≥n independiente. Eval√∫a en una red de transporte simulada con condiciones de tr√°fico variables.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07417" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Revolucionando la Cuantizaci√≥n de Precisi√≥n Mixta: Hacia el Descubrimiento Autom√°tico de Proxys sin Entrenamiento mediante Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Propone TAP, un marco impulsado por Modelos de Lenguaje Grandes (LLMs) para descubrir autom√°ticamente proxys superiores para Cuantizaci√≥n de Precisi√≥n Mixta (MPQ), sin involucrar expertos humanos ni entrenamiento. Utiliza una optimizaci√≥n de pol√≠tica directa (DPO) para mejorar el razonamiento de los LLMs y crear un ciclo de retroalimentaci√≥n positivo con la tarea MPQ.</p>
                    <div class="paper-points">‚Ä¢ Dise√±o autom√°tico de proxys para MPQ sin intervenci√≥n humana ni entrenamiento. Uso de LLMs optimizados mediante DPO para la generaci√≥n de proxys. Demuestra rendimiento state-of-the-art en benchmarks principales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07419" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">MIDG: Mezcla de Expertos Invariantes con inyecci√≥n de conocimiento para la Generalizaci√≥n de Dominio en el An√°lisis de Sentimientos Multimodal</h3>
                    <p class="paper-summary">üìù Propone MIDG, un marco novedoso para la generalizaci√≥n de dominio en el An√°lisis de Sentimientos Multimodal (MSA). Incorpora un modelo de Mezcla de Expertos Invariantes para extraer caracter√≠sticas invariantes al dominio, captando sinergias entre modalidades. Incluye un Adaptador Cross-Modal para enriquecer las representaciones mediante inyecci√≥n de conocimiento cross-modal.</p>
                    <div class="paper-points">‚Ä¢ Mezcla de Expertos Invariantes para capturar relaciones sin√©rgicas entre modalidades. Adaptador Cross-Modal para inyecci√≥n de conocimiento entre modalidades. Evaluaci√≥n extensa en tres datasets
‚Ä¢  demostrando superior rendimiento.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07430" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üî¨</span>
                    <h3 class="paper-title">Mitigaci√≥n del Sesgo en la Computaci√≥n Hiperdimensional de Grafos</h3>
                    <p class="paper-summary">üìù Este estudio investiga las implicaciones de equidad en la Computaci√≥n Hiperdimensional de Grafos (GHDC), un paradigma eficiente para datos estructurados en grafos. Se demuestra c√≥mo la codificaci√≥n en hipervectores puede propagar sesgos en los datos. Se propone FairGHDC, un marco de entrenamiento consciente de la equidad que corrige sesgos directamente en el espacio de hipervectores, manteniendo precisi√≥n y logrando aceleraciones de ~10x en el tiempo de entrenamiento.</p>
                    <div class="paper-points">‚Ä¢ Introduce FairGHDC para mitigar sesgos en GHDC. Mantiene la precisi√≥n mientras reduce brechas de paridad demogr√°fica y equidad de oportunidades. Preserva las ventajas computacionales de HDC (hasta 10x m√°s r√°pido).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07433" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">KAN-Dreamer: Evaluaci√≥n de Redes de Kolmogorov-Arnold como Aproximadores de Funciones en Modelos del Mundo</h3>
                    <p class="paper-summary">üìù Investiga la integraci√≥n de Redes de Kolmogorov-Arnold (KANs) en el marco de aprendizaje por refuerzo DreamerV3. Presenta KAN-Dreamer, reemplazando componentes MLP por KANs y FastKANs (una variante eficiente) en un Modelo del Mundo basado en JAX. Los resultados en tareas de control muestran que el uso de FastKAN como reemplazo directo puede igualar el rendimiento, eficiencia de muestras y velocidad de la arquitectura original basada en MLP.</p>
                    <div class="paper-points">‚Ä¢ Integra KANs/FastKANs en el algoritmo DreamerV3 (MBRL). Implementaci√≥n vectorizada para eficiencia dentro del Modelo del Mundo. FastKAN logra rendimiento comparable al MLP original en predicci√≥n de Recompensa/Continuaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07437" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Olvidar y Explicar: Verificaci√≥n Transparente del Desaprendizaje en GNN</h3>
                    <p class="paper-summary">üìù Propone un verificador basado en explicabilidad para confirmar el &#x27;desaprendizaje&#x27; (olvido de datos) en Redes Neuronales de Grafos (GNNs). El m√©todo compara instant√°neas del modelo antes y despu√©s del borrado, usando m√©tricas como cambios en atribuci√≥n y distancia de edici√≥n de grafo como evidencia transparente. Eval√∫a cuatro estrategias de desaprendizaje, mostrando que Retrain y GNNDelete logran un olvido casi completo, mientras otras dejan se√±ales residuales.</p>
                    <div class="paper-points">‚Ä¢ Verificador transparente para el desaprendizaje en GNNs usando explicabilidad. Emplea cinco m√©tricas de explicaci√≥n (ej. desplazamiento del mapa de calor
‚Ä¢  distancia de edici√≥n). Proporciona evidencia legible por humanos del grado de olvido logrado.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07450" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Algoritmos Paralelos para M√°quinas de Vectores de Soporte Regularizadas Combinadas: Aplicaci√≥n en Clasificaci√≥n de G√©neros Musicales</h3>
                    <p class="paper-summary">üìù Propone un marco de optimizaci√≥n unificado y un algoritmo paralelo ADMM distribuido para entrenar M√°quinas de Vectores de Soporte Regularizadas Combinadas (CR-SVM) con datos almacenados de forma distribuida. El marco es aplicable a diversas funciones de p√©rdida y t√©rminos de regularizaci√≥n. Se introduce un nuevo modelo (SGL-SVM) y se aplica a recuperaci√≥n de informaci√≥n musical, demostrando la fiabilidad, estabilidad y eficiencia del algoritmo propuesto.</p>
                    <div class="paper-points">‚Ä¢ Algoritmo ADMM distribuido para CR-SVMs con datos en almacenamiento distribuido. Marco unificado escalable a regularizaciones no convexas. Aplicaci√≥n exitosa en clasificaci√≥n de g√©neros musicales (Music Information Retrieval).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07463" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Materium: Un Enfoque Autoregresivo para la Generaci√≥n de Materiales</h3>
                    <p class="paper-summary">üìù Presenta Materium, un transformador autoregresivo que genera estructuras cristalinas convirtiendo representaciones 3D de materiales en secuencias de tokens (elementos, estados de oxidaci√≥n, coordenadas, par√°metros de red). A diferencia de los enfoques de difusi√≥n, coloca √°tomos en coordenadas precisas de una vez, permitiendo una generaci√≥n r√°pida y escalable. El modelo se entrena y eval√∫a condicionado por m√∫ltiples propiedades, como banda prohibida y densidad, produciendo candidatos que se alinean con las entradas solicitadas.</p>
                    <div class="paper-points">‚Ä¢ Generaci√≥n autoregresiva r√°pida de estructuras cristalinas (vs. difusi√≥n lenta). Entrenamiento condicional con propiedades fundamentales y pr√°cticas. Alta velocidad de entrenamiento y generaci√≥n (horas en una sola GPU).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07486" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Estimaci√≥n Eficiente de Tensores de Bajo Rango Tubular mediante Descenso de Gradiente Precondicionado Alternante</h3>
                    <p class="paper-summary">üìù Aborda el problema de la estimaci√≥n de tensores de bajo rango tubular, crucial en procesamiento de se√±ales y aprendizaje autom√°tico. Propone el algoritmo APGD (Alternating Preconditioned Gradient Descent), que acelera la convergencia en escenarios de sobre-parametrizaci√≥n a√±adiendo un t√©rmino de precondicionamiento y actualizando factores de forma alternada. Demuestra convergencia lineal garantizada te√≥ricamente, independiente del n√∫mero de condici√≥n del tensor, y la valida con simulaciones extensas.</p>
                    <div class="paper-points">‚Ä¢ Algoritmo APGD para estimaci√≥n de tensores de bajo rango tubular. Convergencia lineal incluso bajo sobre-parametrizaci√≥n. Tasa de convergencia independiente del n√∫mero de condici√≥n del tensor.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07490" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üß≠ Explorando Sistemas Vectoriales para un Entrenamiento m√°s R√°pido de Redes Neuronales con Espacios Latentes Preconfigurados</h3>
                    <p class="paper-summary">üìù Explora el uso de sistemas vectoriales predefinidos (como los vectores del sistema de ra√≠ces An) para configurar la estructura del espacio latente (LS) de redes neuronales durante el entrenamiento. Este enfoque permite entrenar clasificadores sin capas de clasificaci√≥n, facilitando el manejo de conjuntos de datos con un n√∫mero extremadamente grande de clases. Muestra que usar el n√∫mero m√≠nimo de dimensiones en el LS acelera la convergencia y puede reducir el tama√±o de las bases de datos de embeddings.</p>
                    <div class="paper-points">‚Ä¢ Configuraci√≥n del espacio latente (LSC) usando sistemas vectoriales predefinidos. Entrenamiento m√°s r√°pido para datasets con muchas clases (ej. ImageNet). Convergencia acelerada al usar dimensiones m√≠nimas necesarias en el LS.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07509" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprendizaje Autom√°tico: Progreso y Perspectivas</h3>
                    <p class="paper-summary">üìù Esta &#x27;Conferencia Inaugural&#x27; de 1996 (actualizada en 2025) ofrece una introducci√≥n hist√≥rica y conceptual al campo del Aprendizaje Autom√°tico. Rastrea los or√≠genes de las ideas desde Arist√≥teles y Ockham hasta Shannon y Fisher, describiendo avances te√≥ricos y proyectos pr√°cticos. Destaca la naturaleza multidisciplinaria del campo, abarcando subcampos como aprendizaje inductivo, redes neuronales, clustering y teor√≠as del aprendizaje.</p>
                    <div class="paper-points">‚Ä¢ Perspectiva hist√≥rica sobre los or√≠genes del Aprendizaje Autom√°tico. Descripci√≥n de los subcampos principales y su evoluci√≥n. Conferencia original de 1996 con comentarios y referencias actualizadas para 2025.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07519" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üéØ</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo Basado en Modelos bajo Confusi√≥n</h3>
                    <p class="paper-summary">üìù Investiga el aprendizaje por refuerzo basado en modelos en Procesos de Decisi√≥n Markovianos Contextuales (C-MDPs) donde el contexto no observado induce confusi√≥n en el conjunto de datos offline. Para abordar la inconsistencia de los m√©todos convencionales, adapta un enfoque de evaluaci√≥n pol√≠tica proximal que identifica la recompensa esperada confundida usando solo trayectorias observables. Esto, combinado con un modelo de transici√≥n, crea un MDP sustituto consistente para la planificaci√≥n en entornos confundidos.</p>
                    <div class="paper-points">‚Ä¢ Enfoque para aprendizaje por refuerzo basado en modelos con variables de confusi√≥n no observadas. Construye un MDP sustituto consistente para pol√≠ticas basadas en estado. Se integra con el marco de aprendizaje de modelos de entrop√≠a causal m√°xima (MaxCausalEnt).</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07528" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚è≥ FRWKV: Atenci√≥n Lineal en el Dominio de la Frecuencia para Pron√≥stico de Series de Tiempo a Largo Plazo</h3>
                    <p class="paper-summary">üìù Propone FRWKV, un marco de atenci√≥n lineal en el dominio de la frecuencia para pron√≥stico de series de tiempo de larga secuencia. Combina mecanismos de atenci√≥n lineal (complejidad O(T)) con an√°lisis espectral para mejorar las representaciones temporales. Supera la limitaci√≥n de complejidad cuadr√°tica de los Transformers tradicionales. Logra el primer puesto en promedio en ocho datasets del mundo real, demostrando la sinergia entre atenci√≥n lineal y modelado en el dominio de la frecuencia.</p>
                    <div class="paper-points">‚Ä¢ Atenci√≥n lineal en el dominio de la frecuencia con complejidad O(T). Mejora la capacidad de modelado de secuencias largas explotando informaci√≥n espectral. Logra el primer lugar en ranking promedio en m√∫ltiples benchmarks.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07539" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üî¨</span>
                    <h3 class="paper-title">RRAEDy: Linealizaci√≥n Latente Adaptativa de Sistemas Din√°micos No Lineales</h3>
                    <p class="paper-summary">üìù Se introduce RRAEDy, un modelo que supera limitaciones de modelos latentes existentes al descubrir autom√°ticamente la dimensi√≥n latente apropiada y hacer cumplir din√°micas regularizadas y linealizadas en el espacio latente. Utiliza Autoencodificadores de Reducci√≥n de Rango (RRAEs) y un operador DMD latente, logrando predicciones precisas y robustas en benchmarks can√≥nicos como el oscilador Van der Pol y la ecuaci√≥n de Burgers.</p>
                    <div class="paper-points">‚Ä¢ Descubrimiento autom√°tico de dimensi√≥n latente
‚Ä¢  Linealizaci√≥n y regularizaci√≥n de din√°micas en espacio latente
‚Ä¢  Basado en RRAEs y operador DMD
‚Ä¢  Estabilidad te√≥rica demostrada
‚Ä¢  C√≥digo abierto disponible.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07542" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">ReLaX: Razonamiento con Exploraci√≥n Latente para Modelos de Razonamiento Grande</h3>
                    <p class="paper-summary">üìù Propone ReLaX, un paradigma que incorpora expl√≠citamente la din√°mica latente para regular la exploraci√≥n y explotaci√≥n durante la optimizaci√≥n de pol√≠ticas en Modelos de Razonamiento Grande (LRMs). Mitiga el colapso de entrop√≠a y la convergencia prematura mediante la teor√≠a de operadores de Koopman y una nueva m√©trica de Dispersi√≥n Espectral Din√°mica (DSD).</p>
                    <div class="paper-points">‚Ä¢ Aborda colapso de entrop√≠a en RLVR
‚Ä¢  Usa teor√≠a de operadores de Koopman para linealizar din√°micas latentes
‚Ä¢  Introduce m√©trica DSD para cuantificar exploraci√≥n
‚Ä¢  Mejora significativamente el rendimiento en benchmarks de razonamiento multimodal y solo texto.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07558" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Aprendizaje Contrastivo Ponderado para Pron√≥stico de Series de Tiempo con Conciencia de Anomal√≠as</h3>
                    <p class="paper-summary">üìù Presenta WECA (Weighted Contrastive Adaptation), un objetivo contrastivo ponderado que alinea representaciones normales y aumentadas con anomal√≠as para pron√≥sticos confiables bajo condiciones an√≥malas. Mejora significativamente el SMAPE en datos afectados por anomal√≠as en un dataset de transacciones de cajeros autom√°ticos, sin degradar el rendimiento en datos normales.</p>
                    <div class="paper-points">‚Ä¢ Alineaci√≥n de representaciones normales y an√≥malas
‚Ä¢  Preserva informaci√≥n relevante de anomal√≠as
‚Ä¢  Mejora del 6.1% en SMAPE en datos an√≥malos
‚Ä¢  Evaluado en dataset real de transacciones de ATM.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07569" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Modelos Fundacionales de Series de Tiempo para Pron√≥stico de Modelos de Proceso</h3>
                    <p class="paper-summary">üìù Investiga el uso de Modelos Fundacionales de Series de Tiempo (TSFMs) preentrenados para la tarea de Pron√≥stico de Modelos de Proceso (PMF). Los TSFMs, usados en modo zero-shot o fine-tuneado, superan a modelos tradicionales y especializados, demostrando una capacidad de generalizaci√≥n efectiva y eficiencia de datos para series de tiempo derivadas de logs de eventos.</p>
                    <div class="paper-points">‚Ä¢ Aplicaci√≥n de TSFMs preentrenados a PMF
‚Ä¢  Zero-shot a menudo supera o iguala a modelos entrenados desde cero
‚Ä¢  Efectiva transferencia de estructura temporal desde dominios no relacionados
‚Ä¢  Primera evaluaci√≥n sistem√°tica de modelos fundacionales temporales para PMF.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07624" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üßÆ</span>
                    <h3 class="paper-title">Una Teor√≠a Matem√°tica de la Atenci√≥n Top-k</h3>
                    <p class="paper-summary">üìù Desarrolla un marco matem√°tico unificado para el truncamiento certificado de atenci√≥n Top-k, cuantificando el error de aproximaci√≥n a nivel de distribuci√≥n y salida. Deriva cotas deterministas no asint√≥ticas y una regla asint√≥tica para el k m√≠nimo que garantiza un presupuesto de variaci√≥n total, validado experimentalmente en modelos como BERT.</p>
                    <div class="paper-points">‚Ä¢ Marco te√≥rico para truncamiento Top-k certificado
‚Ä¢  Relaci√≥n entre distancia de variaci√≥n total y masa de cola softmax descartada
‚Ä¢  Cotas basadas en logits ordenados
‚Ä¢  Regla asint√≥tica para seleccionar k
‚Ä¢  Reducci√≥n experimental de 2-4x en claves puntuadas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07647" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚öôÔ∏è Direccionamiento de Activaci√≥n por Profundidad para Modelos de Lenguaje Honestos</h3>
                    <p class="paper-summary">üìù Presenta un m√©todo de direccionamiento de activaciones sin entrenamiento que distribuye la fuerza de intervenci√≥n a trav√©s de la profundidad de la red usando un programa Gaussiano. Mejora la honestidad (reporte veraz) sobre l√≠neas base sin direccionamiento y de capa √∫nica en seis de siete modelos evaluados en el benchmark MASK.</p>
                    <div class="paper-points">‚Ä¢ Mejora la honestidad
‚Ä¢  no solo la exactitud factual
‚Ä¢  M√©todo sin entrenamiento y agn√≥stico al modelo
‚Ä¢  Programa Gaussiano para ponderar fuerza por capa
‚Ä¢  Simple y de bajo costo
‚Ä¢  Evaluado en familias LLaMA
‚Ä¢  Qwen y Mistral.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07667" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ Una Perspectiva de Bootstrap en el Descenso de Gradiente Estoc√°stico</h3>
                    <p class="paper-summary">üìù Estudia el impacto de SGD en la generalizaci√≥n a trav√©s del lente del bootstrap estad√≠stico. Argumenta que SGD usa la variabilidad del gradiente bajo muestreo por lotes como proxy de la variabilidad bajo el proceso de recolecci√≥n de datos, regularizando impl√≠citamente la traza de la matriz de covarianza del gradiente para mejorar la robustez y generalizaci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Explica ventajas de generalizaci√≥n de SGD v√≠a bootstrap impl√≠cito
‚Ä¢  Regulariza la traza de la covarianza del gradiente
‚Ä¢  Conduce a soluciones robustas al ruido de muestreo
‚Ä¢  Experimentos en redes neuronales apoyan la teor√≠a.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07676" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÆ Aprendizaje en Contexto y Pocos Ejemplos para Pron√≥stico de Series de Tiempo basado en Modelos de Lenguaje Grande</h3>
                    <p class="paper-summary">üìù Investiga el rendimiento de Modelos de Lenguaje Grande (LLMs) y el modelo fundacional TimesFM de Google para la predicci√≥n de series de tiempo usando metodolog√≠as zero-shot, few-shot y en contexto. TimesFM mostr√≥ el mejor rendimiento general, destacando el potencial de los modelos fundacionales preentrenados para pron√≥sticos en tiempo real.</p>
                    <div class="paper-points">‚Ä¢ Compara LLMs (o4-mini
‚Ä¢  Gemini) y TimesFM con modelos cl√°sicos (LSTM
‚Ä¢  TCN)
‚Ä¢  TimesFM logra el menor RMSE
‚Ä¢  Zero-shot con o4-mini tiene buen rendimiento
‚Ä¢  Modelos fundacionales permiten implementaci√≥n precisa y escalable con m√≠nima adaptaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07705" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚ö°</span>
                    <h3 class="paper-title">Habilitando la Carga Completa Retrasada Mediante Modelado Transformer de Tiempo-Real-a-Salida para la Longevidad de Bater√≠as de VE</h3>
                    <p class="paper-summary">üìù Propone un modelo Transformer de tiempo-real-a-evento (TTE) para predecir con precisi√≥n los tiempos de salida de veh√≠culos el√©ctricos (EVs), permitiendo retrasar la carga completa hasta justo antes de la partida para mitigar la degradaci√≥n de bater√≠as de iones de litio. Supera a modelos base al capturar patrones de salida irregulares usando datos de smartphone en tiempo real.</p>
                    <div class="paper-points">‚Ä¢ Predicci√≥n de salida de EVs para optimizar carga y longevidad de bater√≠as
‚Ä¢  Modelo Transformer basado en TTE con tokens de tiempo discretizados
‚Ä¢  Captura patrones irregulares dentro de rutinas individuales
‚Ä¢  Evaluado en estudio real con 93 usuarios.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07723" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Una Red Bayesiana Multimodal para la Predicci√≥n de Depresi√≥n y Ansiedad a Nivel de S√≠ntoma desde Datos de Voz y Habla</h3>
                    <p class="paper-summary">üìù Eval√∫a un modelo de red bayesiana para predecir s√≠ntomas de depresi√≥n y ansiedad a partir de caracter√≠sticas de voz y habla en datasets a gran escala. El modelo ofrece rendimiento s√≥lido, equidad demogr√°fica e integraci√≥n transparente de modalidades, present√°ndose como una herramienta de apoyo cl√≠nico explicable y supervisable.</p>
                    <div class="paper-points">‚Ä¢ Predicci√≥n a nivel de s√≠ntoma
‚Ä¢  no solo trastorno
‚Ä¢  Alto rendimiento (ROC-AUC &gt
‚Ä¢ 0.83 para condiciones)
‚Ä¢  Evaluaci√≥n de equidad demogr√°fica
‚Ä¢  Enfoque transparente y explicable para supervisi√≥n cl√≠nica
‚Ä¢  Basado en datos de 30
‚Ä¢ 135 hablantes √∫nicos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07741" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Redes de Hopfield y M√°quinas de Boltzmann Formalizadas</h3>
                    <p class="paper-summary">üìù Se presenta una formalizaci√≥n en Lean 4 de redes neuronales, cubriendo modelos deterministas y estoc√°sticos. Se formalizan las redes de Hopfield, probando convergencia y correcci√≥n del aprendizaje de Hebb para patrones ortogonales. Luego, se formalizan m√°quinas de Boltzmann estoc√°sticas, demostrando su ergodicidad y convergencia a una distribuci√≥n estacionaria √∫nica usando un nuevo teorema de Perron-Frobenius.</p>
                    <div class="paper-points">‚Ä¢ Formalizaci√≥n matem√°tica rigurosa en Lean 4. Demostraci√≥n de convergencia para redes de Hopfield (deterministas) y m√°quinas de Boltzmann (estoc√°sticas). Aplicaci√≥n del teorema de Perron-Frobenius para probar ergodicidad.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07766" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">GatedFWA: Atenci√≥n por Ventana Flash Lineal con Memoria Asociativa Controlada</h3>
                    <p class="paper-summary">üìù Propone GatedFWA, un mecanismo de atenci√≥n por ventana eficiente y lineal que estabiliza las actualizaciones de memoria y controla el flujo de gradientes. Introduce una compuerta por token/cabezal que act√∫a como un sesgo de decaimiento aprendible en los logits de atenci√≥n. Se implementa con un kernel compatible con FlashAttention, logrando alto rendimiento y mejor uso del contexto global en modelado de lenguaje.</p>
                    <div class="paper-points">‚Ä¢ Atenci√≥n de ventana lineal (O(n)) que evita inestabilidades de memoria. Mecanismo de compuerta aprendible para controlar contracci√≥n/expansi√≥n de memoria. Kernel fusionado eficiente y estable num√©ricamente
‚Ä¢  compatible con m√©todos de compresi√≥n de tokens.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07782" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üßÆ</span>
                    <h3 class="paper-title">Codificaci√≥n de Posici√≥n por Representaci√≥n de Grupo (GRAPE)</h3>
                    <p class="paper-summary">üìù Presenta GRAPE, un marco unificado para codificaci√≥n posicional basado en acciones de grupo. Unifica mecanismos multiplicativos (rotaciones en SO(d)) y aditivos (sesgos en logits de GL). Recupera RoPE y ALiBi como casos especiales. Permite geometr√≠as posicionales extendidas para capturar acoplamiento entre subespacios, ofreciendo un espacio de dise√±o para modelos de contexto largo.</p>
                    <div class="paper-points">‚Ä¢ Marco te√≥rico unificado basado en teor√≠a de grupos para codificaci√≥n posicional. Subsumye RoPE (multiplicativo) y ALiBi/FoX (aditivo) como casos particulares. Permite extensiones aprendidas de bajo costo (O(d)
‚Ä¢  O(rd)) para geometr√≠as m√°s ricas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07805" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîç</span>
                    <h3 class="paper-title">Beneficios de Largo Alcance (Probados) de la Predicci√≥n del Siguiente Token</h3>
                    <p class="paper-summary">üìù Demuestra te√≥ricamente que optimizar la predicci√≥n del siguiente token en Redes Neuronales Recurrentes (RNN) produce modelos que aproximan estrechamente la distribuci√≥n de entrenamiento. Se prueba que, para cualquier k, un observador limitado a k tokens no puede distinguir entre documentos reales y texto generado por el modelo tras un prefijo com√∫n. Los l√≠mites de complejidad son polinomiales en k, explicando la coherencia de largo alcance observada emp√≠ricamente.</p>
                    <div class="paper-points">‚Ä¢ Demostraci√≥n te√≥rica del poder de la predicci√≥n del siguiente token para capturar estructura de largo alcance. Garant√≠a de indistinguibilidad de k-tokens entre datos reales y generados. Explicaci√≥n complejidad-te√≥rica para la coherencia en modelos de lenguaje.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07818" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">La Adopci√≥n y Uso de Agentes de IA: Evidencia Temprana desde Perplexity</h3>
                    <p class="paper-summary">üìù Primer estudio a gran escala del uso de agentes de IA de prop√≥sito general (Comet Assistant de Perplexity). Analiza cientos de millones de interacciones, revelando heterogeneidad en la adopci√≥n: mayor en usuarios de pa√≠ses ricos, sectores digitales y acad√©micos. Introduce una taxonom√≠a de casos de uso: 57% para Productividad/Flujo de trabajo e Investigaci√≥n/Aprendizaje. Los usos son &#x27;pegajosos&#x27; a corto plazo, pero evolucionan hacia temas m√°s cognitivos.</p>
                    <div class="paper-points">‚Ä¢ Estudio emp√≠rico masivo sobre adopci√≥n y uso de agentes de IA. Taxonom√≠a jer√°rquica que clasifica consultas por tema
‚Ä¢  subtema y tarea. Identificaci√≥n de factores demogr√°ficos y de contexto (55% personal
‚Ä¢  30% profesional
‚Ä¢  16% educativo) que influyen en el uso.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07828" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Inteligencia Artificial">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Inteligencia Artificial</h2>
                <span class="category-count">42</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Apost√°ndolo todo a la Precisi√≥n del LLM: Mercados de Predicci√≥n Ficticios, Se√±ales Reales de Confianza</h3>
                    <p class="paper-summary">üìù Este estudio piloto prueba si enmarcar una tarea de evaluaci√≥n de LLMs como un juego de apuestas (un mercado de predicci√≥n ficticio) mejora la precisi√≥n de los pron√≥sticos y revela se√±ales de confianza calibradas. Los modelos que apostaron una moneda ficticia (LLMCoin) mostraron una mejora modesta en precisi√≥n y, lo m√°s importante, el tama√±o de la apuesta se correlacion√≥ fuertemente con la confianza, proporcionando una se√±al legible del grado de certeza del modelo.</p>
                    <div class="paper-points">‚Ä¢ Uso de un mercado de predicci√≥n ficticio para evaluar la confianza de los LLMs. Las apuestas altas (&#x27
‚Ä¢ ballenas&#x27
‚Ä¢ ) correspondieron a una precisi√≥n del ~99%. El marco financiero transforma a los LLMs en pronosticadores conscientes del riesgo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05998" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprendizaje profundo para la detecci√≥n del autismo usando notas cl√≠nicas: Una comparaci√≥n del aprendizaje por transferencia para un enfoque transparente y de caja negra</h3>
                    <p class="paper-summary">üìù Compara enfoques de aprendizaje autom√°tico transparentes y de caja negra para la detecci√≥n del trastorno del espectro autista (TEA) a partir de texto cl√≠nico no estructurado. El modelo transparente, basado en BioBERT, etiqueta comportamientos y los mapea a criterios diagn√≥sticos, superando al modelo de caja negra en generalizaci√≥n y rendimiento. Mejores resultados se obtuvieron mezclando conjuntos de datos durante el entrenamiento.</p>
                    <div class="paper-points">‚Ä¢ Enfoque interpretable para diagn√≥stico de TEA basado en lenguaje cl√≠nico. Supera a un modelo de caja negra en rendimiento y capacidad de transferencia. La estrategia de entrenamiento mixto con m√∫ltiples conjuntos de datos ofrece los mejores resultados.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06161" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">ARCANE: Un Marco Multi-Agente para Alineaci√≥n Interpretable y Configurable</h3>
                    <p class="paper-summary">üìù ARCANE enmarca la alineaci√≥n de agentes de IA como un problema de colaboraci√≥n multi-agente, representando las preferencias de las partes interesadas como r√∫bricas de lenguaje natural (conjuntos ponderados de criterios verificables). Mediante una optimizaci√≥n de pol√≠ticas regularizada (GSPO), equilibra interpretabilidad, fidelidad y eficiencia computacional. Las r√∫bricas aprendidas permiten compensaciones configurables en tiempo real sin necesidad de reentrenar el modelo.</p>
                    <div class="paper-points">‚Ä¢ Marco multi-agente para alineaci√≥n interpretable. R√∫bricas de lenguaje natural como recompensa. Optimizaci√≥n GSPO para equilibrio interpretabilidad-fidelidad. Configurabilidad en tiempo de ejecuci√≥n sin reentrenamiento.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06196" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Sobre la Medici√≥n de la Conexi√≥n a la Realidad y la Generalizaci√≥n de sus Problemas</h3>
                    <p class="paper-summary">üìù Reformula el &#x27;problema de la conexi√≥n a la realidad&#x27; (symbol grounding) de un juicio binario a una auditor√≠a basada en deseables (autenticidad, preservaci√≥n, fidelidad, robustez, composicionalidad). Aplica el marco a cuatro modos de conexi√≥n y tres estudios de caso, incluyendo modelos de lenguaje grandes y lenguaje humano. Proporciona un lenguaje t√©cnico com√∫n para filosof√≠a, inform√°tica y ling√º√≠stica.</p>
                    <div class="paper-points">‚Ä¢ Marco auditivo con m√∫ltiples deseables para evaluar la &#x27
‚Ä¢ conexi√≥n a la realidad&#x27
‚Ä¢ . An√°lisis de LLMs (encaje correlacional
‚Ä¢  falta de conexi√≥n causal con el mundo). El lenguaje humano cumple los deseables por adquisici√≥n evolutiva.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06205" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">üîí Aplicaci√≥n de la IA en el Lavado de Activos para Sistemas Financieros Sostenibles y Transparentes</h3>
                    <p class="paper-summary">üìù Revisa c√≥mo la IA puede modernizar los flujos de trabajo contra el lavado de activos (AML), mejorando la precisi√≥n y reduciendo falsos positivos. Destaca direcciones futuras como aprendizaje federado, IA justa e interpretable, y aprendizaje por refuerzo. Propone una aplicaci√≥n KYC impulsada por IA que integra Generaci√≥n Aumentada por Recuperaci√≥n basada en Grafos (RAG-Graph) para mayor eficiencia y transparencia.</p>
                    <div class="paper-points">‚Ä¢ IA para mejorar detecci√≥n de lavado de activos y reducir falsos positivos. Futuro: aprendizaje federado
‚Ä¢  IA interpretable
‚Ä¢  refuerzo. Propuesta de arquitectura RAG-Graph para KYC
‚Ä¢  mostrando alta fidelidad y relevancia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06240" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">¬øQu√© Tan Precisa y Robusta es un Modelo? Perspectivas Duales de Evaluaci√≥n en Completado de Grafos de Conocimiento</h3>
                    <p class="paper-summary">üìù Observa que las m√©tricas existentes para completado de grafos de conocimiento (KGC) pasan por alto dos perspectivas clave: nitidez predictiva y robustez al sesgo de popularidad. Propone PROBE, un marco de evaluaci√≥n novedoso con un transformador de rango y un agregador de rango consciente de la popularidad. Los experimentos muestran que PROBE ofrece una evaluaci√≥n m√°s completa y confiable que las m√©tricas tradicionales.</p>
                    <div class="paper-points">‚Ä¢ Identifica dos carencias en evaluaci√≥n de KGC: nitidez predictiva y robustez al sesgo de popularidad. Marco PROBE con transformador y agregador de rango. Proporciona evaluaci√≥n m√°s confiable y comprensiva que m√©tricas est√°ndar.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06296" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">DaGRPO: Rectificando Conflictos de Gradiente en Razonamiento mediante Optimizaci√≥n de Pol√≠tica Relativa Grupal Consciente de la Distinci√≥n</h3>
                    <p class="paper-summary">üìù Identifica te√≥ricamente que la falta de distinci√≥n en las muestras on-policy causa conflictos destructivos de gradiente en GRPO. Propone DaGRPO, que incorpora: Rectificaci√≥n de Gradiente a Nivel de Secuencia (enmascara pares de baja distinci√≥n) y Aumento de Datos Off-policy (introduce anclas de alta calidad). Logra ganancias significativas de precisi√≥n en razonamiento matem√°tico y generalizaci√≥n fuera de distribuci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Soluciona inestabilidad y baja eficiencia de GRPO. Mecanismo de rectificaci√≥n de gradiente por distinci√≥n. Aumento de datos off-policy para tareas dif√≠ciles. Logra estado del arte en benchmarks de razonamiento matem√°tico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06337" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Menos Es M√°s para el Razonamiento L√≥gico Multi-Etapa de LLMs: Generalizaci√≥n bajo Eliminaci√≥n, Parafraseo y Compresi√≥n de Reglas</h3>
                    <p class="paper-summary">üìù Introduce un marco de evaluaci√≥n controlado que prueba la confiabilidad del razonamiento mediante cuatro pruebas de estr√©s: eliminaci√≥n de reglas (esenciales/redundantes), inyecci√≥n de evidencia contradictoria, reescrituras que preservan la l√≥gica y transformaciones l√≥gicas m√∫ltiples. Los LLMs muestran invariancia a transformaciones que preservan significado, pero son fr√°giles ante reglas faltantes o evidencia contradictoria.</p>
                    <div class="paper-points">‚Ä¢ LLMs son invariantes a reescrituras l√≥gicas que preservan el significado. Fracasan bruscamente al eliminar reglas esenciales o ante contradicciones expl√≠citas. Marco diagn√≥stico para aislar modos de falla en razonamiento l√≥gico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06393" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">üß¨ GENIUS: Un Marco de IA Ag√©ntica para el Dise√±o y Ejecuci√≥n Aut√≥noma de Protocolos de Simulaci√≥n</h3>
                    <p class="paper-summary">üìù GENIUS es un flujo de trabajo ag√©ntico que fusiona un grafo de conocimiento de Quantum ESPRESSO con una jerarqu√≠a de LLMs supervisada por una m√°quina de estados de recuperaci√≥n de errores. Traduce instrucciones en lenguaje natural a archivos de entrada validados que se ejecutan con √©xito en ~80% de benchmarks diversos, con reparaci√≥n aut√≥noma del 76%. Democratiza las simulaciones de estructura electr√≥nica DFT automatizando generaci√≥n y validaci√≥n de protocolos.</p>
                    <div class="paper-points">‚Ä¢ Automatizaci√≥n inteligente de simulaciones DFT mediante agentes de IA. Combina grafo de conocimiento
‚Ä¢  LLMs jer√°rquicos y recuperaci√≥n de errores. Alto √©xito en generaci√≥n y reparaci√≥n aut√≥noma de protocolos. Reduce costos y alucinaciones vs. baselines solo con LLM.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06404" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">üìä UncertaintyZoo: Un Kit de Herramientas Unificado para Cuantificar la Incertidumbre Predictiva en Sistemas de Aprendizaje Profundo</h3>
                    <p class="paper-summary">üìù Presenta UncertaintyZoo, un kit de herramientas unificado que integra 29 m√©todos de cuantificaci√≥n de incertidumbre (UQ) en 5 categor√≠as principales bajo una interfaz estandarizada. Eval√∫a la utilidad de los m√©todos UQ en la tarea de detecci√≥n de vulnerabilidades de c√≥digo usando modelos CodeBERT y ChatGLM3. Los resultados demuestran que la herramienta revela efectivamente la incertidumbre de las predicciones, facilitando investigaci√≥n y uso pr√°ctico.</p>
                    <div class="paper-points">‚Ä¢ Kit de herramientas unificado con 29 m√©todos de cuantificaci√≥n de incertidumbre. Interfaz estandarizada para facilitar investigaci√≥n y uso pr√°ctico. Evaluaci√≥n demostrativa en detecci√≥n de vulnerabilidades de c√≥digo. Disponible p√∫blicamente con video demostrativo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06406" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üèôÔ∏èü§ñ Planificaci√≥n Espacial Inteligente en Egipto: Un Enfoque Basado en Algoritmos para la Evaluaci√≥n de Servicios P√∫blicos en la Ciudad de Qena</h3>
                    <p class="paper-summary">üìù Desarrolla un modelo de planificaci√≥n localizado para Qena usando un algoritmo de an√°lisis espacial inteligente basado en Diagramas de Voronoi implementado en Python. Eval√∫a la cobertura actual de servicios p√∫blicos, revelando un promedio general del 81.3%. Las estaciones de ambulancias tienen la mayor eficiencia (99.8%) y los parques la menor (10%). El an√°lisis espacial muestra alta densidad de servicios en el centro y baja en las periferias.</p>
                    <div class="paper-points">‚Ä¢ Modelo de est√°ndares de planificaci√≥n localizado para ciudad egipcia. Algoritmo basado en Diagramas de Voronoi para an√°lisis de cobertura de servicios. Cobertura promedio del 81.3%
‚Ä¢  con grandes disparidades entre tipos de servicio y zonas. Marco replicable para planificaci√≥n urbana basada en datos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06431" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">ü§îüí¨ El Efecto de las &#x27;Cajas de Creencias&#x27; y la Mentalidad Abierta en la Persuasi√≥n</h3>
                    <p class="paper-summary">üìù Explora c√≥mo incluir declaraciones de creencias (en &#x27;cajas de creencias&#x27;) en el prompt de agentes basados en LLMs afecta su comportamiento y persuasi√≥n en escenarios multi-agente. Encontr√≥ que instruir a los agentes a ser de mentalidad abierta aumenta su predisposici√≥n al cambio de creencias. La t√©cnica de la caja de creencias influye en la resistencia a opiniones opuestas y en la probabilidad de cambio, especialmente bajo presi√≥n grupal.</p>
                    <div class="paper-points">‚Ä¢ La &#x27
‚Ä¢ caja de creencias&#x27
‚Ä¢  en el prompt afecta resistencia y persuasi√≥n de agentes. Mentalidad abierta instruida aumenta predisposici√≥n al cambio de creencias. La presi√≥n grupal (estar en minor√≠a) influye en la probabilidad de cambio. Valida la t√©cnica para tareas de razonamiento y toma de decisiones.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06573" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">FlatFormer: Un Modelo de Seguimiento del Conocimiento con Transformer Plano Basado en Inyecci√≥n de Sesgo Cognitivo</h3>
                    <p class="paper-summary">üìù Propone FlatFormer, una arquitectura simplificada que evita la complejidad jer√°rquica para el Seguimiento del Conocimiento (KT). Utiliza mecanismos de inyecci√≥n ligeros, como identificadores de sesi√≥n y un sesgo de ley de potencia precalculado, para modelar la curva del olvido. Logra un rendimiento superior con menos del 15% de par√°metros y es tres veces m√°s r√°pido en inferencia que los modelos jer√°rquicos.</p>
                    <div class="paper-points">‚Ä¢ Resuelve la &#x27
‚Ä¢ trampa complejidad-rendimiento&#x27
‚Ä¢  en KT. Combina codificaci√≥n h√≠brida de entrada y sesgo de atenci√≥n basado en ley de potencia. Logra un aumento del 8.3% en AUC con una reducci√≥n dr√°stica de par√°metros y tiempo de inferencia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06629" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">LightSearcher: B√∫squeda Profunda Eficiente mediante Memoria Experiencial</h3>
                    <p class="paper-summary">üìù Presenta LightSearcher, un marco de RL eficiente para sistemas de DeepSearch que equilibra precisi√≥n y eficiencia. Incorpora una memoria experiencial textual que aprende trayectorias de razonamiento contrastivas y utiliza un mecanismo adaptativo de conformaci√≥n de recompensas. Reduce las invocaciones de herramientas de b√∫squeda en un 39.6% manteniendo una precisi√≥n comparable al estado del arte.</p>
                    <div class="paper-points">‚Ä¢ Aborda la disyuntiva precisi√≥n-eficiencia en DeepSearch impulsado por RL. Memoria experiencial basada en trayectorias de razonamiento contrastivas. Recompensa adaptativa que penaliza llamadas redundantes solo en escenarios correctos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06653" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Las pol√≠ticas de IA de las revistas acad√©micas no logran frenar el aumento de la escritura acad√©mica asistida por IA</h3>
                    <p class="paper-summary">üìù Analiza el impacto real de las pol√≠ticas de uso de IA en m√°s de 5,000 revistas y 5.2 millones de art√≠culos. Muestra que, a pesar de que el 70% de las revistas tienen pol√≠ticas (principalmente de divulgaci√≥n), el uso de herramientas de escritura con IA ha aumentado dr√°sticamente sin diferencias significativas entre revistas con o sin pol√≠ticas. Existe una gran brecha de transparencia, con solo un 0.1% de divulgaci√≥n expl√≠cita.</p>
                    <div class="paper-points">‚Ä¢ Las pol√≠ticas actuales de IA no promueven la transparencia ni restringen la adopci√≥n. Uso de IA crece m√°s en pa√≠ses no angloparlantes
‚Ä¢  ciencias f√≠sicas y revistas de alto acceso abierto (OA). Brecha de transparencia cr√≠tica: divulgaci√≥n casi inexistente a pesar de las pol√≠ticas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06705" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Estocasticidad en las Evaluaciones Ag√©nticas: Cuantificando la Inconsistencia con la Correlaci√≥n Intraclase</h3>
                    <p class="paper-summary">üìù Propone usar el Coeficiente de Correlaci√≥n Intraclase (ICC) para cuantificar la varianza y confiabilidad en la evaluaci√≥n de sistemas ag√©nticos con LLMs. El ICC descompone la varianza en dificultad de la tarea e inconsistencia del agente. Demuestra que la ICC var√≠a con la complejidad de la tarea y que las mejoras en precisi√≥n solo son confiables si la ICC tambi√©n mejora.</p>
                    <div class="paper-points">‚Ä¢ Introduce ICC para hacer visible la estabilidad de la evaluaci√≥n en sistemas ag√©nticos. La ICC converge con 8-16 ensayos para tareas estructuradas y &gt
‚Ä¢ =32 para razonamiento complejo. Recomienda reportar precisi√≥n junto con ICC y varianza intra-consulta como pr√°ctica est√°ndar.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06710" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Cognitive Control Architecture (CCA): Un Marco de Supervisi√≥n de Ciclo de Vida para Agentes de IA Robusto Alineados</h3>
                    <p class="paper-summary">üìù Propone la Arquitectura de Control Cognitivo (CCA), un marco hol√≠stico de defensa contra ataques de Inyecci√≥n Indirecta de Prompt (IPI) en agentes de LLM aut√≥nomos. CCA logra supervisi√≥n de ciclo de vida completo mediante un &#x27;Grafo de Intenci√≥n&#x27; proactivo y un &#x27;√Årbitro Escalonado&#x27; que inicia razonamiento profundo tras detectar desviaciones. Logra seguridad sin compromisos en eficiencia y robustez.</p>
                    <div class="paper-points">‚Ä¢ Defensa integral contra ataques IPI sofisticados que explotan la disyuntiva seguridad-funcionalidad. Dos pilares: Integridad de flujo de control/datos proactiva y un √Årbitro Escalonado para desviaciones. Se valida en el benchmark AgentDojo
‚Ä¢  reconciliando seguridad
‚Ä¢  funcionalidad y eficiencia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06716" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">ProAgent: Aprovechando Contextos Sensoriales Bajo Demanda para Sistemas de Agentes LLM Proactivos</h3>
                    <p class="paper-summary">üìù Presenta ProAgent, el primer sistema de agente proactivo de extremo a extremo que utiliza contextos sensoriales masivos y razonamiento de LLM para ofrecer asistencia proactiva. Emplea extracci√≥n de contexto orientada a la proactividad con percepci√≥n escalonada y un razonador proactivo consciente del contexto. Implementado en gafas de Realidad Aumentada (AR), mejora la precisi√≥n de predicci√≥n proactiva en un 33.4%.</p>
                    <div class="paper-points">‚Ä¢ Primer marco de agente proactivo de extremo a extremo para LLMs. Extracci√≥n de contexto jer√°rquico con percepci√≥n escalonada bajo demanda. Mejoras significativas en precisi√≥n de predicci√≥n
‚Ä¢  puntuaci√≥n F1 en llamadas a herramientas y satisfacci√≥n del usuario.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06721" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">DoVer: Depuraci√≥n Autom√°tica Impulsada por Intervenci√≥n para Sistemas Multi-Agente con LLM</h3>
                    <p class="paper-summary">üìù Introduce DoVer, un marco de depuraci√≥n impulsado por intervenciones que valida hip√≥tesis de fallos mediante intervenciones activas (editar mensajes, alterar planes). Enfocado en resolver el fallo o lograr progreso cuantificable, no solo en atribuir la culpa. Convierte entre 18-28% de intentos fallidos en exitosos y valida/refuta un 30-60% de hip√≥tesis.</p>
                    <div class="paper-points">‚Ä¢ Depuraci√≥n basada en intervenci√≥n activa
‚Ä¢  no solo en an√°lisis de logs. M√©trica orientada a resultados: resolver el fallo o progresar
‚Ä¢  no solo atribuci√≥n. Eficacia demostrada en m√∫ltiples frameworks de agentes (Magnetic-One
‚Ä¢  AG2) y conjuntos de datos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06749" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Decouple to Generalize: Aprendizaje Autoevolutivo Contexto-Primero para Razonamiento Visi√≥n-Lenguaje con Escasez de Datos</h3>
                    <p class="paper-summary">üìù Propone DoGe, un marco de desacoplamiento dual para entrenar VLMs con RL en dominios de datos escasos. Gu√≠a a los modelos a aprender primero del contexto del problema, no de resolverlo, para evitar el &#x27;reward hacking&#x27;. Desacopla el proceso en &#x27;Thinker&#x27; y &#x27;Solver&#x27; y utiliza un pipeline de aprendizaje curricular evolutivo. Supera consistentemente a la l√≠nea base en varios benchmarks.</p>
                    <div class="paper-points">‚Ä¢ Aborda el problema del &#x27
‚Ä¢ reward hacking&#x27
‚Ä¢  y la escasez de datos en RL para VLMs. Desacopla aprendizaje en dos componentes: Thinker (contexto) y Solver (tarea). Pipeline de aprendizaje curricular con corpus de conocimiento nativo expandido y grupo de problemas semilla evolutivo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06835" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">JT-DA: Mejorando el An√°lisis de Datos con Modelos de Lenguaje Grande de Razonamiento Tabular Integrado con Herramientas</h3>
                    <p class="paper-summary">üìù Presenta JT-DA-8B, un LLM especializado en razonamiento tabular complejo. Construye un corpus diverso con 34 tareas de razonamiento definidas a partir de 29 conjuntos de datos p√∫blicos. Utiliza un pipeline autom√°tico para generar tareas anal√≠ticas multietapa realistas y optimiza el modelo con SFT y RL. Propone un flujo de trabajo de cuatro etapas para mejorar la interpretabilidad y precisi√≥n.</p>
                    <div class="paper-points">‚Ä¢ LLM especializado (8B par√°metros) para razonamiento tabular en escenarios del mundo real. Corpus de entrenamiento generado centrado en datos de alta calidad y diversidad. Flujo de trabajo de cuatro etapas: preprocesado
‚Ä¢  detecci√≥n
‚Ä¢  razonamiento con herramientas e ingenier√≠a de prompts.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06859" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">¬øAfectan los LLM Infundidos con Personas al Rendimiento en un Juego de Razonamiento Estrat√©gico?</h3>
                    <p class="paper-summary">üìù Investiga el impacto del prompt de personas en el rendimiento estrat√©gico de LLMs en PERIL, un juego de mesa de dominaci√≥n mundial. Encuentra que ciertas personas asociadas al pensamiento estrat√©gico mejoran el rendimiento, pero solo cuando se usa un &#x27;mediador&#x27; para traducir las respuestas del LLM a valores heur√≠sticos. El m√©todo propuesto mejora la confiabilidad y validez de las heur√≠sticas generadas.</p>
                    <div class="paper-points">‚Ä¢ Eval√∫a si las &#x27
‚Ä¢ personas&#x27
‚Ä¢  en LLMs afectan el comportamiento estrat√©gico medible. Introduce un mediador inspirado en an√°lisis factorial para traducir respuestas de inventario a heur√≠sticas. Personas estrat√©gicas mejoran el rendimiento en el juego solo con la traducci√≥n mediada.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06867" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Sobre la Memoria: Una comparaci√≥n de mecanismos de memoria en modelos de mundo</h3>
                    <p class="paper-summary">üìù Los modelos de mundo permiten a los agentes planificar en entornos imaginados, pero su alcance de memoria limitado dificulta el cierre de bucles en trayectorias largas. Este trabajo investiga y clasifica mecanismos de aumento de memoria (codificaci√≥n e inyecci√≥n) en transformadores, evalu√°ndolos mediante una tarea de recuperaci√≥n de estado. Los hallazgos muestran que estos mecanismos extienden la memoria efectiva y mejoran la capacidad de cierre de bucles en la imaginaci√≥n del modelo.</p>
                    <div class="paper-points">‚Ä¢ Taxonom√≠a de mecanismos de memoria (codificaci√≥n/inyecci√≥n)
‚Ä¢  Evaluaci√≥n de capacidad de recuperaci√≥n de memoria en transformadores
‚Ä¢  Mejora del cierre de bucles en trayectorias imaginadas largas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06983" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Utilizando Aprendizaje por Refuerzo Multi-Agente con Agentes de Arquitectura Codificador-Decodificador para Identificar la Ubicaci√≥n √ìptima de Resecci√≥n en Pacientes con Glioblastoma Multiforme</h3>
                    <p class="paper-summary">üìù Se desarrolla un sistema de IA integral para diagn√≥stico y planificaci√≥n del tratamiento del Glioblastoma Multiforme (GBM). Combina un marco de diagn√≥stico secuencial con 4 modelos y un sistema de RL con 3 modelos generativos (resecci√≥n, radioterapia, quimioterapia) que iteran mediante optimizaci√≥n de pol√≠tica proximal para encontrar la ubicaci√≥n de resecci√≥n √≥ptima. El enfoque reduce costes computacionales, acelera la inferencia y mejora las m√©tricas, proyectando un aumento en la tasa de supervivencia.</p>
                    <div class="paper-points">‚Ä¢ Sistema IA integral (diagn√≥stico + tratamiento) para GBM
‚Ä¢  Combinaci√≥n de modelos de clasificaci√≥n secuencial y modelos generativos con RL (PPO)
‚Ä¢  Reducci√≥n de costes computacionales (22.28x) y mejora de precisi√≥n
‚Ä¢  con impacto potencial en la supervivencia.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06990" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">ClinNoteAgents: Un Sistema Multi-Agente Basado en LLM para Predecir e Interpretar la Rehospitalizaci√≥n a 30 D√≠as por Insuficiencia Cardiaca a partir de Notas Cl√≠nicas</h3>
                    <p class="paper-summary">üìù Se presenta ClinNoteAgents, un marco multi-agente basado en LLM que transforma notas cl√≠nicas de texto libre en representaciones estructuradas de factores de riesgo y abstracciones estilo cl√≠nico para predecir la rehospitalizaci√≥n por insuficiencia cardiaca a 30 d√≠as. Evaluado en miles de notas, muestra un fuerte rendimiento en la extracci√≥n de factores de riesgo y predicci√≥n, ofreciendo un enfoque escalable e interpretable con m√≠nima anotaci√≥n manual.</p>
                    <div class="paper-points">‚Ä¢ Marco multi-agente con LLM para procesar notas cl√≠nicas de texto libre
‚Ä¢  Extrae factores de riesgo estructurados y predice rehospitalizaci√≥n
‚Ä¢  Enfoque escalable e interpretable que reduce la dependencia de campos estructurados y anotaci√≥n manual.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07081" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">VIGIL: Un Entorno de Ejecuci√≥n Reflexivo para Agentes de Autoreparaci√≥n</h3>
                    <p class="paper-summary">üìù VIGIL es un entorno de ejecuci√≥n reflexivo que supervisa a un agente hermano, realizando mantenimiento aut√≥nomo en lugar de ejecuci√≥n de tareas. Ingestiona registros de comportamiento, los valora en representaciones emocionales estructuradas, mantiene un &#x27;EmoBank&#x27; persistente y genera diagn√≥sticos y planes de reparaci√≥n (actualizaciones de prompt y c√≥digo). Funciona como una canalizaci√≥n con compuertas de estado, demostrando capacidad de autoreparaci√≥n a nivel meta.</p>
                    <div class="paper-points">‚Ä¢ Entorno de ejecuci√≥n reflexivo para supervisi√≥n y autoreparaci√≥n de agentes
‚Ä¢  Mantiene un &#x27
‚Ä¢ EmoBank&#x27
‚Ä¢  y genera diagn√≥sticos RBT (fortalezas
‚Ä¢  oportunidades
‚Ä¢  fallos)
‚Ä¢  Produce planes de reparaci√≥n aut√≥nomos (prompts y c√≥digo) demostrando autoreparaci√≥n a nivel meta.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07094" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Un Marco de Afinidad Neuronal para el Razonamiento Abstracto: Diagnosticando la Brecha Composicional en Arquitecturas Transformer mediante una Taxonom√≠a de Tareas Procedimentales</h3>
                    <p class="paper-summary">üìù Se presenta una taxonom√≠a de 9 categor√≠as para las 400 tareas de ARC, usada para diagnosticar la &#x27;brecha composicional&#x27; en Transformers. El an√°lisis revela que un 35.3% de las tareas tienen baja &#x27;afinidad neuronal&#x27; para esta arquitectura. Experimentos muestran que muchas tareas logran alta precisi√≥n a nivel de celda pero baja a nivel de cuadr√≠cula, evidenciando un &#x27;Efecto Techo de Afinidad Neuronal&#x27;. Los hallazgos apuntan a la necesidad de arquitecturas h√≠bridas con m√≥dulos alineados a la afinidad de la tarea.</p>
                    <div class="paper-points">‚Ä¢ Taxonom√≠a de tareas ARC para diagnosticar la &#x27
‚Ä¢ afinidad neuronal&#x27
‚Ä¢ 
‚Ä¢  Evidencia de una &#x27
‚Ä¢ Brecha Composicional&#x27
‚Ä¢  y un &#x27
‚Ä¢ Efecto Techo de Afinidad Neuronal&#x27
‚Ä¢  en Transformers
‚Ä¢  El rendimiento est√° limitado por la idoneidad arquitect√≥nica
‚Ä¢  no solo por el curr√≠culum de aprendizaje.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07109" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">ContextualSHAP: Mejorando las Explicaciones SHAP mediante Generaci√≥n de Lenguaje Contextual</h3>
                    <p class="paper-summary">üìù Se propone un paquete de Python que extiende SHAP integrando un LLM (como GPT) para generar explicaciones textuales contextualizadas, guiadas por par√°metros definidos por el usuario (alias de caracter√≠sticas, descripciones). Evaluado en un caso de estudio sanitario, las explicaciones generadas fueron percibidas como m√°s comprensibles y contextualmente apropiadas que las salidas visuales tradicionales de SHAP, mejorando la confiabilidad percibida del modelo.</p>
                    <div class="paper-points">‚Ä¢ Extensi√≥n de SHAP que integra un LLM para generar explicaciones textuales contextualizadas
‚Ä¢  Las explicaciones se adaptan al contexto del modelo y la perspectiva del usuario
‚Ä¢  Evaluaci√≥n con usuarios muestra mejora en la comprensibilidad percibida.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07178" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">PICKT: Rastreo de Conocimiento de Conceptos Interconectados Pr√°ctico para el Aprendizaje Personalizado usando Relaciones de Conceptos en Mapas de Conocimiento</h3>
                    <p class="paper-summary">üìù Se propone PICKT, un modelo pr√°ctico de rastreo de conocimiento que procesa m√∫ltiples tipos de datos de entrada y utiliza un mapa de conocimiento que estructura las relaciones entre conceptos. Este enfoque aborda problemas de arranque en fr√≠o (nuevos estudiantes o preguntas) y valida su estabilidad en entornos operativos reales, proporcionando una base t√©cnica para Sistemas Tutores Inteligentes (ITS) de pr√≥xima generaci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Modelo de rastreo de conocimiento (KT) que usa mapas de conocimiento para relaciones entre conceptos
‚Ä¢  Supera desaf√≠os de arranque en fr√≠o (nuevos estudiantes/preguntas)
‚Ä¢  Validado por su rendimiento y estabilidad en entornos operativos pr√°cticos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07179" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Muestrea lo que Ves: Aprendizaje de Pol√≠ticas Visuomotoras mediante Puentes de Difusi√≥n con Ecuaciones Diferenciales Estoc√°sticas Integradas a la Observaci√≥n</h3>
                    <p class="paper-summary">üìù Se introduce BridgePolicy, una pol√≠tica visomotora generativa que integra expl√≠citamente las observaciones en la ecuaci√≥n diferencial estoc√°stica mediante una formulaci√≥n de puente de difusi√≥n. Esto permite que el muestreo comience desde un prior informado por la observaci√≥n, no desde ruido aleatorio, mejorando la precisi√≥n y confiabilidad en el control. Incluye m√≥dulos para fusi√≥n multimodal y alineaci√≥n sem√°ntica, y supera a pol√≠ticas generativas de √∫ltima generaci√≥n en m√∫ltiples tareas simuladas y del mundo real.</p>
                    <div class="paper-points">‚Ä¢ Pol√≠tica generativa (BridgePolicy) que usa puentes de difusi√≥n con observaciones integradas en el proceso estoc√°stico
‚Ä¢  El muestreo comienza desde un prior informado
‚Ä¢  mejorando la precisi√≥n
‚Ä¢  Supera a m√©todos SOTA en 52 tareas de simulaci√≥n y 5 del mundo real.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07212" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Emparejamiento de Productos Multiplataforma Basado en Alineaci√≥n de Entidades de Grafos de Conocimiento con el Modelo RAEA</h3>
                    <p class="paper-summary">üìù El emparejamiento de productos entre plataformas se aborda como una tarea de alineaci√≥n de entidades (EA) en grafos de conocimiento (KGs). Se propone un modelo RAEA (Relation-aware and Attribute-aware Graph Attention Networks) que enfatiza las interacciones entre triples de atributos y de relaci√≥n para aprender representaciones de entidades. RAEA logra mejoras significativas en datasets de referencia para EA, demostrando su efectividad en el emparejamiento de productos entre eBay y Amazon.</p>
                    <div class="paper-points">‚Ä¢ Conversi√≥n del emparejamiento de productos a una tarea de Alineaci√≥n de Entidades (EA) en Grafos de Conocimiento
‚Ä¢  Modelo RAEA que captura interacciones entre atributos y relaciones de las entidades
‚Ä¢  Logra mejoras de rendimiento en datasets de referencia como DBP15K.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07232" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">M-STAR: Autoregresi√≥n Espaciotemporal Multi-Escala para el Modelado de Movilidad Humana</h3>
                    <p class="paper-summary">üìù Se propone M-STAR, un marco para generar trayectorias de movilidad humana a largo plazo mediante un proceso de predicci√≥n autoregresiva de grueso a fino a m√∫ltiples escalas espaciotemporales. Combina un &#x27;Tokenizer&#x27; que codifica patrones jer√°rquicos de movilidad con un decodificador basado en Transformer. M-STAR supera a m√©todos existentes en fidelidad y velocidad de generaci√≥n en dos datasets del mundo real.</p>
                    <div class="paper-points">‚Ä¢ Generaci√≥n de trayectorias de movilidad a largo plazo mediante autoregresi√≥n multi-escala (de grueso a fino)
‚Ä¢  Combina un tokenizer jer√°rquico con un decodificador Transformer
‚Ä¢  Supera a m√©todos existentes en fidelidad y velocidad de generaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07314" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Una Unificaci√≥n Geom√©trica del Aprendizaje de Conceptos con Conos de Conceptos</h3>
                    <p class="paper-summary">üìù Este trabajo muestra que los Modelos de Cuello de Botella de Conceptos (CBMs) y los Autoencoders Dispersos (SAEs) instancian la misma estructura geom√©trica: ambos aprenden un conjunto de direcciones lineales en el espacio de activaci√≥n cuyas combinaciones no negativas forman un &#x27;cono de concepto&#x27;. Se propone un marco unificado que eval√∫a qu√© tan bien los conos aprendidos por SAEs se aproximan o contienen los conos definidos por humanos de los CBMs, descubriendo un &#x27;punto √≥ptimo&#x27; en par√°metros como la dispersi√≥n.</p>
                    <div class="paper-points">‚Ä¢ Unificaci√≥n geom√©trica de CBMs y SAEs. Conos de concepto como estructura subyacente com√∫n. M√©tricas cuantitativas para alineaci√≥n sem√°ntica y geom√©trica. Punto √≥ptimo en dispersi√≥n y factor de expansi√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07355" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">LocalSearchBench: Evaluaci√≥n de B√∫squeda Ag√©ntica en Servicios de Vida Local del Mundo Real</h3>
                    <p class="paper-summary">üìù Se presenta LocalSearchBench, un benchmark integral para sistemas de b√∫squeda ag√©ntica en el dominio de servicios de vida local. Incluye m√°s de 150,000 entradas de alta calidad y 300 tareas de preguntas y respuestas de m√∫ltiples pasos basadas en consultas reales. Los experimentos muestran que incluso los modelos de razonamiento grandes m√°s avanzados tienen dificultades, destacando la necesidad de benchmarks especializados y entrenamiento espec√≠fico de dominio.</p>
                    <div class="paper-points">‚Ä¢ Primer benchmark para b√∫squeda ag√©ntica en servicios locales. 150k+ entradas y 300 tareas QA multi-paso. Los mejores modelos (ej. DeepSeek-V3.1) logran solo ~34% de correcci√≥n. Necesidad de entrenamiento espec√≠fico de dominio.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07436" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">¬øC√≥mo Fracallan los LLMs en Escenarios Ag√©nticos? Un An√°lisis Cualitativo de Escenarios de √âxito y Fracaso</h3>
                    <p class="paper-summary">üìù Se investigan los modos de fracaso de los LLMs que operan como agentes aut√≥nomos con capacidades de uso de herramientas. Mediante un an√°lisis detallado de 900 trazas de ejecuci√≥n, se identifican cuatro arquetipos recurrentes de falla, como la acci√≥n prematura sin fundamento y la vulnerabilidad a distracciones. Se concluye que la escala del modelo por s√≠ sola no predice la robustez ag√©ntica.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis cualitativo de 900 trazas de agentes LLM. Identificaci√≥n de 4 arquetipos de falla recurrentes. La escala no predice robustez ag√©ntica. La fiabilidad depende de elecciones de dise√±o y entrenamiento deliberadas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07497" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">An√°lisis Comparativo y Ajuste Param√©trico de PPO, GRPO y DAPO para la Mejora del Razonamiento en LLMs</h3>
                    <p class="paper-summary">üìù Estudio sistem√°tico que compara tres algoritmos de Aprendizaje por Refuerzo para mejorar el razonamiento complejo en LLMs. Los modelos entrenados con RL superan a sus versiones base. El an√°lisis param√©trico ofrece gu√≠as pr√°cticas: aumentar el tama√±o del grupo en GRPO/DAPO mejora la estabilidad, y el componente de Muestreo Din√°mico (DS) en DAPO no mejora el rendimiento.</p>
                    <div class="paper-points">‚Ä¢ Comparaci√≥n controlada de PPO
‚Ä¢  GRPO y DAPO para LLMs. Modelos RL superan consistentemente a los modelos base. Gu√≠a pr√°ctica para ajuste param√©trico (tama√±o de grupo
‚Ä¢  penalizaci√≥n KL). El muestreo din√°mico en DAPO no mejor√≥ los resultados.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07611" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">El Problema de la Capacidad del Agente: Predicci√≥n de Resolubilidad Mediante L√≠mites Te√≥rico-Informacionales</h3>
                    <p class="paper-summary">üìù Se introduce el Problema de la Capacidad del Agente (ACP), un marco te√≥rico-informacional para predecir si un agente puede resolver un problema bajo restricciones de recursos. Se formula la resoluci√≥n como adquisici√≥n de informaci√≥n, derivando un costo efectivo que limita inferiormente el esfuerzo de b√∫squeda esperado. Las predicciones del marco se alinean estrechamente con el rendimiento real de agentes basados en LLMs.</p>
                    <div class="paper-points">‚Ä¢ Marco te√≥rico-informacional para predecir resolubilidad. Define el costo efectivo basado en bits de informaci√≥n requeridos/obtenidos. Proporciona l√≠mites probabil√≠sticos para los recursos necesarios. Generalizable a flujos de trabajo basados en LLMs y agentes.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07631" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Cada Prompt Importa: Escalando el Aprendizaje por Refuerzo Sin Desperdiciar Rollouts en MoE de Cien Mil Millones de Par√°metros</h3>
                    <p class="paper-summary">üìù Se presenta un nuevo marco de Aprendizaje por Refuerzo para entrenar modelos de razonamiento MoE a gran escala, basado en el principio de que cada prompt debe importar. Se introducen innovaciones como la eliminaci√≥n de prompts de varianza cero, un m√©todo de optimizaci√≥n adaptativo de entrop√≠a y una estrategia de reproducci√≥n del enrutador para mitigar discrepancias entre entrenamiento e inferencia.</p>
                    <div class="paper-points">‚Ä¢ Nuevo marco RL eficiente para MoE a gran escala. Eliminaci√≥n de prompts no informativos para evitar rollouts desperdiciados. Alineaci√≥n del enrutador MoE entre entrenamiento e inferencia. Sistema de alto rendimiento con rollouts en precisi√≥n FP8.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07710" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">RL-MTJail: Aprendizaje por Refuerzo para el Jailbreaking Automatizado de M√∫ltiples Turnos de Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Se estudian ataques de jailbreaking de m√∫ltiples turnos contra LLMs, formulando el problema como una tarea de aprendizaje por refuerzo para optimizar la nocividad de la salida final. Se proponen recompensas heur√≠sticas para el proceso que controlan la nocividad intermedia y mantienen la relevancia sem√°ntica, logrando tasas de √©xito de ataque mejoradas de manera consistente.</p>
                    <div class="paper-points">‚Ä¢ Formulaci√≥n de jailbreaking multi-turno como tarea de RL. Recompensas de proceso para guiar estrategias de ataque a largo plazo. Tasas de √©xito de ataque mejoradas en m√∫ltiples benchmarks. Advertencia: El art√≠culo contiene ejemplos de contenido da√±ino.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07761" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">ReasonBENCH: Evaluaci√≥n de la (In)Estabilidad del Razonamiento en LLMs</h3>
                    <p class="paper-summary">üìù Se presenta ReasonBENCH, el primer benchmark dise√±ado para cuantificar la inestabilidad inherente en el razonamiento de los LLMs. Introduce un protocolo de m√∫ltiples ejecuciones para reportar m√©tricas estad√≠sticamente confiables de calidad y costo. Los hallazgos muestran que la mayor√≠a de las estrategias de razonamiento exhiben alta inestabilidad, comprometiendo la reproducibilidad.</p>
                    <div class="paper-points">‚Ä¢ Primer benchmark para medir inestabilidad en razonamiento de LLMs. Protocolo multi-ejecuci√≥n para m√©tricas fiables de calidad/costo. Alta inestabilidad observada en la mayor√≠a de m√©todos. La reproducibilidad es una dimensi√≥n cr√≠tica para LLMs confiables.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07795" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Modelos Causales Grandes a partir de Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Se introduce un nuevo paradigma para construir Modelos Causales Grandes (LCMs) aprovechando el conocimiento latente en los LLMs. Se describe el sistema DEMOCRITUS, que utiliza un LLM para proponer temas, generar preguntas causales y extraer afirmaciones causales de diversos dominios, teji√©ndolas luego en un modelo causal coherente.</p>
                    <div class="paper-points">‚Ä¢ Nuevo paradigma para construir modelos causales a gran escala desde LLMs. Sistema DEMOCRITUS para extraer
‚Ä¢  organizar y visualizar relaciones causales. Abarca dominios como arqueolog√≠a
‚Ä¢  biolog√≠a
‚Ä¢  clima
‚Ä¢  econom√≠a
‚Ä¢  medicina. Requiri√≥ inventar nuevos m√©todos de aprendizaje autom√°tico categ√≥rico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07796" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Auditor√≠a de Juegos para la Detecci√≥n de Sandbagging (Ocultaci√≥n de Capacidades)</h3>
                    <p class="paper-summary">üìù Se eval√∫an t√©cnicas para detectar si sistemas de IA ocultan deliberadamente sus capacidades (&#x27;sandbagging&#x27;) durante evaluaciones. Mediante un juego de auditor√≠a, se encontr√≥ que los equipos de defensa no pod√≠an discriminar de manera confiable modelos que hac√≠an sandbagging. La eliciaci√≥n basada en entrenamiento consistente mostr√≥ ser efectiva para obtener el rendimiento completo, pero con riesgo de falsos positivos.</p>
                    <div class="paper-points">‚Ä¢ Juego de auditor√≠a para probar la detecci√≥n de sandbagging. Los enfoques de caja negra fueron derrotados por una imitaci√≥n efectiva. La eliciaci√≥n basada en entrenamiento fue m√°s prometedora. Se recomienda entrenamiento en-distribuci√≥n para mitigar riesgos a corto plazo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07810" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ingenier√≠a de Software">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Ingenier√≠a de Software</h2>
                <span class="category-count">24</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Auto-SPT: Automatizaci√≥n de Transformaciones que Preservan la Sem√°ntica para C√≥digo</h3>
                    <p class="paper-summary">üìù Propone Auto-SPT, un marco que utiliza LLMs para generar autom√°ticamente transformaciones que preservan la sem√°ntica (SPTs) del c√≥digo, alterando su estructura sint√°ctica pero no su funcionalidad. Estas SPTs sint√©ticas se utilizan para evaluar y mejorar la robustez de los detectores de clones de c√≥digo frente a transformaciones del mundo real y adversarias.</p>
                    <div class="paper-points">‚Ä¢ Generaci√≥n autom√°tica de transformaciones sem√°nticas (SPTs)
‚Ä¢  Uso de LLMs para crear y componer SPTs
‚Ä¢  Evaluaci√≥n de detectores de clones de c√≥digo
‚Ä¢  Mejora de la robustez de los modelos mediante datos aumentados.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06042" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üè¢</span>
                    <h3 class="paper-title">M√°s All√° del Prototipado: Desarrollo Frontend Aut√≥nomo y de Grado Empresarial de P√≠xel a Producci√≥n Mediante un Marco Multi-Agente Especializado</h3>
                    <p class="paper-summary">üìù Presenta AI4UI, un marco de agentes aut√≥nomos especializados para el desarrollo frontend de grado empresarial. Convierte dise√±os de Figma (anotados con una gram√°tica espec√≠fica) en c√≥digo UI listo para producci√≥n de forma aut√≥noma, centr√°ndose en seguridad, escalabilidad y mantenibilidad. Logra altas tasas de √©xito en benchmarks a gran escala y es preferido por evaluadores expertos.</p>
                    <div class="paper-points">‚Ä¢ Marco multi-agente AI4UI
‚Ä¢  Desarrollo frontend aut√≥nomo para empresas
‚Ä¢  Gram√°tica de Figma para interpretaci√≥n precisa
‚Ä¢  M√©tricas altas en compatibilidad
‚Ä¢  seguridad y calidad de c√≥digo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06046" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprendizaje por Refuerzo Integrado en RAG Ag√©ntico para la Creaci√≥n de Casos de Prueba de Software</h3>
                    <p class="paper-summary">üìù Introduce un marco que combina RAG (Recuperar, Aumentar, Generar) ag√©ntico con Aprendizaje por Refuerzo (RL) para mejorar continuamente la generaci√≥n autom√°tica de casos de prueba a partir de documentos de requisitos. Los agentes aprenden del feedback de ingenieros de calidad para optimizar sus estrategias, logrando aumentos en la precisi√≥n de generaci√≥n y en las tasas de detecci√≥n de defectos en proyectos empresariales.</p>
                    <div class="paper-points">‚Ä¢ Generaci√≥n de casos de prueba con RL y agentes
‚Ä¢  B√∫squeda de conocimiento h√≠brida (vector-grafo)
‚Ä¢  Aprendizaje continuo a partir del feedback humano
‚Ä¢  Mejoras medibles en precisi√≥n y detecci√≥n de defectos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06060" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Hacia la Certificaci√≥n y Detecci√≥n de Robustez ante Parches para Sistemas de Aprendizaje Profundo M√°s All√° de las Muestras Consistentes</h3>
                    <p class="paper-summary">üìù Propone HiCert, una novedosa t√©cnica de detecci√≥n certificada basada en enmascaramiento contra ataques de parches adversariales. Formula un an√°lisis formal para certificar tanto muestras &#x27;inconsistentes&#x27; (antes problem√°ticas) como consistentes, estableciendo un nuevo estado del arte en certificaci√≥n de robustez con mayor precisi√≥n y menor tasa de falsos silencios.</p>
                    <div class="paper-points">‚Ä¢ Certificaci√≥n de robustez ante parches (HiCert)
‚Ä¢  T√©cnica basada en enmascaramiento
‚Ä¢  Certificaci√≥n de muestras inconsistentes y consistentes
‚Ä¢  Mayor efectividad y menor falsa tasa de silencio que trabajos anteriores.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06123" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Pensar sistem√°ticamente sobre la complejidad de los ejercicios de estructuraci√≥n de c√≥digo a nivel introductorio</h3>
                    <p class="paper-summary">üìù Se presenta un marco para evaluar la complejidad de tareas de estructuraci√≥n de c√≥digo, donde los estudiantes identifican abstracciones en c√≥digo no estructurado. El marco define tres dimensiones: repetici√≥n, patr√≥n de c√≥digo y dependencia de datos. Incluye tareas de ejemplo y una herramienta interactiva para desarrollar habilidades de descomposici√≥n y abstracci√≥n.</p>
                    <div class="paper-points">‚Ä¢ Marco de evaluaci√≥n de complejidad
‚Ä¢  Dimensiones: repetici√≥n/patr√≥n/dependencia
‚Ä¢  Enfoque en descomposici√≥n y abstracci√≥n
‚Ä¢  Herramienta educativa interactiva
‚Ä¢  Relevancia ante la IA generativa</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06178" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîå</span>
                    <h3 class="paper-title">DUET: Comprensi√≥n del dise√±o de hardware mediante experimentaci√≥n y pruebas</h3>
                    <p class="paper-summary">üìù DUET es una metodolog√≠a para que agentes de IA comprendan dise√±os de hardware (c√≥digo RTL) mediante experimentaci√≥n iterativa, imitando a expertos. Genera hip√≥tesis, las prueba con herramientas EDA (simulaci√≥n, verificaci√≥n formal) y construye una comprensi√≥n ascendente. Mejora el rendimiento en tareas como la verificaci√≥n formal.</p>
                    <div class="paper-points">‚Ä¢ Metodolog√≠a para comprensi√≥n de RTL
‚Ä¢  Enfoque iterativo de hip√≥tesis-prueba
‚Ä¢  Uso de herramientas EDA (simulaci√≥n/verificaci√≥n)
‚Ä¢  Supera limitaciones de LLMs en sintaxis
‚Ä¢  Mejora rendimiento en verificaci√≥n</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06247" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">CFCEval: Evaluaci√≥n de aspectos de seguridad en c√≥digo generado por modelos de lenguaje grandes</h3>
                    <p class="paper-summary">üìù Se presenta CFCEval, un marco para evaluar la calidad y seguridad del c√≥digo generado por LLMs. Mitiga el sesgo de datos con un nuevo benchmark (MLVBench) e introduce una m√©trica (ELRM) que se alinea mejor con el juicio humano. Eval√∫a cuatro dimensiones: calidad, capacidad de reparaci√≥n de vulnerabilidades, post-transformaci√≥n y relevancia.</p>
                    <div class="paper-points">‚Ä¢ Marco de evaluaci√≥n calidad/seguridad
‚Ä¢  Nueva m√©trica ELRM vs CodeBLEU
‚Ä¢  Benchmark MLVBench sin sesgo
‚Ä¢  4 dimensiones de evaluaci√≥n
‚Ä¢  Mejor alineaci√≥n con juicio humano</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06248" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß™</span>
                    <h3 class="paper-title">LLMCFG-TGen: Uso de grafos de flujo de control generados por LLM para crear casos de prueba a partir de casos de uso</h3>
                    <p class="paper-summary">üìù Propone LLMCFG-TGen, un enfoque que genera casos de prueba a partir de descripciones en lenguaje natural de casos de uso. Un LLM transforma el caso de uso en un Grafo de Flujo de Control, se enumeran todos los caminos de ejecuci√≥n y se generan los casos de prueba. Logra cobertura completa de caminos y reduce el esfuerzo manual.</p>
                    <div class="paper-points">‚Ä¢ Generaci√≥n de pruebas desde NL
‚Ä¢  Transformaci√≥n a CFG por LLM
‚Ä¢  Enumeraci√≥n de caminos completos
‚Ä¢  Cobertura completa de caminos
‚Ä¢  Evaluaci√≥n favorable por profesionales</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06401" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîÑ Traducci√≥n de procedimientos macro de PL/I a Java usando templatizaci√≥n autom√°tica y modelos de lenguaje grandes</h3>
                    <p class="paper-summary">üìù Aborda la compleja modernizaci√≥n de sistemas legacy PL/I con macros a Java. Propone un m√©todo de &#x27;templatizaci√≥n&#x27; que usa ejecuci√≥n simb√≥lica para generar plantillas de c√≥digo como representaci√≥n intermedia. Esto facilita que los LLMs generen c√≥digo Java legible y mantenible que reproduce el comportamiento del c√≥digo macro original.</p>
                    <div class="paper-points">‚Ä¢ Modernizaci√≥n de legacy PL/I a Java
‚Ä¢  M√©todo de templatizaci√≥n con ejecuci√≥n simb√≥lica
‚Ä¢  Plantillas como representaci√≥n intermedia
‚Ä¢  Facilita traducci√≥n por LLMs
‚Ä¢  Experimentos exitosos preliminares</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06448" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚ö°</span>
                    <h3 class="paper-title">METRION: Un marco para la medici√≥n precisa de la energ√≠a del software</h3>
                    <p class="paper-summary">üìù Introduce METRION, un marco extensible para medir con precisi√≥n el consumo de energ√≠a de aplicaciones a nivel de hilo, en CPU y DRAM. Considera efectos como Multihilo Simult√°neo, escalado de frecuencia y arquitecturas multi-socket. La evaluaci√≥n muestra un error bajo (4.2% CPU, 16.1% DRAM) para cargas de trabajo espec√≠ficas.</p>
                    <div class="paper-points">‚Ä¢ Modelo de atribuci√≥n de energ√≠a a nivel de hilo
‚Ä¢  Considera SMT
‚Ä¢  NUMA
‚Ä¢  escalado de frecuencia
‚Ä¢  Marco extensible (implementaci√≥n Linux/Intel)
‚Ä¢  Bajo error en evaluaci√≥n (MAPE 4.2%/16.1%)</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06806" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Aprovechar LLMs para apoyar la co-evoluci√≥n entre definiciones e instancias de DSLs textuales</h3>
                    <p class="paper-summary">üìù Explora el uso de LLMs para co-evolucionar gram√°ticas de DSLs textuales y sus instancias, preservando informaci√≥n auxiliar como comentarios. Eval√∫a modelos como Claude-3.5 y GPT-4o en siete lenguajes. Los LLMs muestran habilidad en casos a peque√±a escala, pero enfrentan desaf√≠os de escalabilidad con instancias m√°s grandes.</p>
                    <div class="paper-points">‚Ä¢ Co-evoluci√≥n gram√°tica/instancias DSL
‚Ä¢  Preservaci√≥n de comentarios/formato
‚Ä¢  Evaluaci√≥n de LLMs (Claude
‚Ä¢  GPT)
‚Ä¢  Factible en casos peque√±os
‚Ä¢  Desaf√≠os de escalabilidad</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06836" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üåê BabelCoder: Traducci√≥n de c√≥digo basada en agentes con alineaci√≥n de especificaciones</h3>
                    <p class="paper-summary">üìù Presenta BabelCoder, un marco de agentes especializados para traducir c√≥digo entre lenguajes. Los agentes colaboran en traducci√≥n, pruebas y refinamiento. Evaluado en cuatro benchmarks, supera a m√©todos state-of-the-art en la mayor√≠a de los casos, logrando una precisi√≥n promedio del 94.16%.</p>
                    <div class="paper-points">‚Ä¢ Marco de agentes para traducci√≥n de c√≥digo
‚Ä¢  Agentes especializados (traducir/probar/refinar)
‚Ä¢  Enfoque colaborativo
‚Ä¢  Supera baselines en 94% de casos
‚Ä¢  Precisi√≥n promedio 94.16%</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06902" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üõ°Ô∏è MINES: Detecci√≥n de anomal√≠as explicable mediante inferencia de invariantes de API web</h3>
                    <p class="paper-summary">üìù Propone MINES, un m√©todo para detectar anomal√≠as en aplicaciones web inferiendo invariantes de API a nivel de esquema, no de logs. Usa un LLM para inferir relaciones potenciales entre APIs y tablas de BD a partir del esquema, valida invariantes con logs normales y genera c√≥digo Python para verificaci√≥n. Logra alta precisi√≥n y bajo falso positivo.</p>
                    <div class="paper-points">‚Ä¢ Detecci√≥n de anomal√≠as en APIs web
‚Ä¢  Inferencia de invariantes a nivel de esquema
‚Ä¢  Uso de LLM para proponer relaciones
‚Ä¢  Traducci√≥n a c√≥digo verificador
‚Ä¢  Alta recall y casi cero falsos positivos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06906" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üê≥ Multi-Docker-Eval: Un benchmark para la construcci√≥n autom√°tica de entornos en Ingenier√≠a de Software</h3>
                    <p class="paper-summary">üìù Presenta el benchmark Multi-Docker-Eval con 40 repositorios reales en 9 lenguajes para evaluar la configuraci√≥n autom√°tica de entornos. La evaluaci√≥n de LLMs y frameworks de agentes muestra bajas tasas de √©xito (&lt;=37.7%), siendo la construcci√≥n del entorno el cuello de botella. Modelos open-source son competitivos, y el lenguaje/framework influye significativamente.</p>
                    <div class="paper-points">‚Ä¢ Benchmark para construcci√≥n de entornos
‚Ä¢  40 repositorios reales / 9 lenguajes
‚Ä¢  √âxito bajo (F2P &lt
‚Ä¢ =37.7%)
‚Ä¢  Construcci√≥n de entorno es cuello de botella
‚Ä¢  Modelos open-source competitivos</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06915" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Reformular, Recuperar, Localizar: Agentes para la Localizaci√≥n de Errores a Nivel de Repositorio</h3>
                    <p class="paper-summary">üìù Propone un agente impulsado por LLM que mejora la localizaci√≥n de errores a nivel de archivo en repositorios de software. Reformula consultas extrayendo informaci√≥n clave de informes de errores antes de la recuperaci√≥n. Logra un rendimiento superior al baseline BM25 y al SWE-agent en la recuperaci√≥n del primer archivo.</p>
                    <div class="paper-points">‚Ä¢ Agente con LLM para localizaci√≥n de errores
‚Ä¢  reformulaci√≥n de consultas pre-recuperaci√≥n
‚Ä¢  mejora del ranking en un 35% respecto a BM25
‚Ä¢  automatizaci√≥n del flujo de trabajo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07022" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">RisConFix: Reparaci√≥n Automatizada de Configuraciones de Drones Propensas a Riesgos Basada en LLM</h3>
                    <p class="paper-summary">üìù Presenta RisConFix, un m√©todo basado en LLM para reparar en tiempo real configuraciones de drones que degradan su robustez. Monitorea el estado de vuelo y activa un mecanismo iterativo de reparaci√≥n que actualiza par√°metros. Logra una alta tasa de √©xito de reparaci√≥n en un estudio de caso con ArduPilot.</p>
                    <div class="paper-points">‚Ä¢ Reparaci√≥n autom√°tica de configuraciones de drones
‚Ä¢  uso de LLM para an√°lisis y actualizaci√≥n de par√°metros
‚Ä¢  proceso iterativo
‚Ä¢  alta tasa de √©xito (97%) en estudio experimental.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07122" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Hacia la Evaluaci√≥n Comparativa de la Detecci√≥n de Patrones de Dise√±o Bajo Ofuscaci√≥n: Reproducci√≥n y Evaluaci√≥n del M√©todo Basado en Atenci√≥n</h3>
                    <p class="paper-summary">üìù Investiga la robustez sem√°ntica de los clasificadores basados en atenci√≥n para la detecci√≥n de patrones de dise√±o bajo ofuscaci√≥n de c√≥digo. Reproduce el enfoque DPDAtt y eval√∫a su desempe√±o en un corpus ofuscado. Revela una dependencia de caracter√≠sticas sint√°cticas superficiales.</p>
                    <div class="paper-points">‚Ä¢ Evaluaci√≥n de detectores de patrones de dise√±o bajo ofuscaci√≥n
‚Ä¢  dependencia de caracter√≠sticas sint√°cticas superficiales
‚Ä¢  creaci√≥n de un corpus ofuscado como benchmark para evaluar generalizaci√≥n sem√°ntica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07193" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Reparaci√≥n Autom√°tica de Errores de Sintaxis para la S√≠ntesis de Controladores Discretos Usando Modelos de Lenguaje Grandes</h3>
                    <p class="paper-summary">üìù Propone un enfoque automatizado que utiliza LLMs para reparar errores de sintaxis en modelos de S√≠ntesis de Controladores Discretos (DCS). Emplea una estrategia de prompting informada por conocimiento de dominio espec√≠fico. Demuestra alta efectividad y un ahorro de tiempo significativo respecto a desarrolladores humanos.</p>
                    <div class="paper-points">‚Ä¢ Reparaci√≥n autom√°tica de errores de sintaxis en modelos formales DCS
‚Ä¢  prompting informado por conocimiento de dominio
‚Ä¢  evaluaci√≥n con un benchmark nuevo
‚Ä¢  velocidad 3.46 veces mayor que la humana.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07261" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">La Necesidad Humana de Narrativa: Reflexiones sobre la Investigaci√≥n Cualitativa en Ingenier√≠a de Software con un Grupo Focal de Expertos</h3>
                    <p class="paper-summary">üìù Reflexiona sobre el estado de la investigaci√≥n cualitativa en ingenier√≠a de software mediante una conversaci√≥n con un grupo focal de expertos. Discute su importancia, evoluci√≥n, impedimentos comunes y futuro. Basado en una columna regular de investigaci√≥n emp√≠rica en software.</p>
                    <div class="paper-points">‚Ä¢ Reflexi√≥n sobre investigaci√≥n cualitativa en ingenier√≠a de software
‚Ä¢  discusi√≥n con expertos
‚Ä¢  an√°lisis de importancia
‚Ä¢  evoluci√≥n
‚Ä¢  desaf√≠os y futuro del campo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07293" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Desaf√≠os en el Desarrollo de Software Seguro: Resultados de un Estudio de Entrevistas en la Industria Alemana del Software</h3>
                    <p class="paper-summary">üìù Presenta un estudio de entrevistas con expertos de la industria alemana para identificar los desaf√≠os en el desarrollo de software seguro. Los principales desaf√≠os son la alta complejidad, falta de concienciaci√≥n en seguridad, procesos inadecuados y escasez de personal calificado.</p>
                    <div class="paper-points">‚Ä¢ Estudio cualitativo en la industria
‚Ä¢  identificaci√≥n de desaf√≠os clave en desarrollo seguro (complejidad
‚Ä¢  concienciaci√≥n
‚Ä¢  procesos
‚Ä¢  personal)
‚Ä¢  derivaci√≥n de direcciones de investigaci√≥n futuras.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07368" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">¬øConf√≠an los LLMs en el C√≥digo que Escriben?</h3>
                    <p class="paper-summary">üìù Explora si los LLMs representan internamente la correcci√≥n del c√≥digo que generan. Identifica una representaci√≥n de correcci√≥n contrastando estados ocultos entre c√≥digo correcto e incorrecto. Demuestra que usar esta se√±al interna mejora la selecci√≥n de c√≥digo de mayor calidad sin necesidad de ejecutar pruebas.</p>
                    <div class="paper-points">‚Ä¢ Representaci√≥n interna de la correcci√≥n del c√≥digo en LLMs
‚Ä¢  mejora sobre el ranking por verosimilitud
‚Ä¢  selecci√≥n de c√≥digo de calidad sin ejecuci√≥n
‚Ä¢  aumento de la confiabilidad en la generaci√≥n de c√≥digo.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07404" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üî¨</span>
                    <h3 class="paper-title">Evaluaci√≥n Sistem√°tica de la Verificaci√≥n de Caja Negra para la Detecci√≥n R√°pida de Errores</h3>
                    <p class="paper-summary">üìù Eval√∫a sistem√°ticamente la t√©cnica de verificaci√≥n de caja negra (BBC) para encontrar errores r√°pidamente en implementaciones de protocolos y controladores. Encuentra que BBC detecta violaciones de especificaciones con una fracci√≥n m√≠nima de las consultas necesarias y es muy efectiva incluso cuando no se puede aprender el modelo completo.</p>
                    <div class="paper-points">‚Ä¢ Evaluaci√≥n de Black-Box Checking (BBC)
‚Ä¢  detecci√≥n r√°pida de errores
‚Ä¢  uso de modelos de hip√≥tesis intermedios
‚Ä¢  alta efectividad en benchmarks reales y de la industria.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07434" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">AutoICE: S√≠ntesis Autom√°tica de C√≥digo C Verificable Mediante Evoluci√≥n Impulsada por LLM</h3>
                    <p class="paper-summary">üìù Propone AutoICE, un m√©todo de b√∫squeda evolutiva impulsada por LLM para sintetizar c√≥digo C verificable a partir de requisitos en lenguaje natural. Introduce inicializaci√≥n diversa, cruce colaborativo y mutaci√≥n autorreflexiva. Supera el estado del arte en la tasa de √©xito de verificaci√≥n del c√≥digo generado.</p>
                    <div class="paper-points">‚Ä¢ S√≠ntesis de c√≥digo C verificable
‚Ä¢  b√∫squeda evolutiva con LLMs
‚Ä¢  t√©cnicas para diversidad y descubrimiento de conocimiento impl√≠cito
‚Ä¢  alto porcentaje de verificaci√≥n exitosa superando el estado del arte.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07501" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">Comprendiendo los Riesgos de Privacidad en los Modelos de C√≥digo a trav√©s de la Din√°mica de Entrenamiento: Un Enfoque Causal</h3>
                    <p class="paper-summary">üìù Investiga los riesgos de privacidad en LLMs para c√≥digo, analizando c√≥mo la facilidad de aprendizaje de diferentes tipos de Informaci√≥n de Identificaci√≥n Personal (PII) afecta causalmente su filtraci√≥n. Muestra que los riesgos son heterog√©neos y correlacionados con la din√°mica de entrenamiento.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis causal de riesgos de privacidad en LLMs para c√≥digo
‚Ä¢  relaci√≥n entre din√°mica de entrenamiento y filtraci√≥n de PII
‚Ä¢  riesgos heterog√©neos seg√∫n el tipo de dato
‚Ä¢  gu√≠a para defensas conscientes del tipo y capacidad de aprendizaje.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07814" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Computadoras y Sociedad">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Computadoras y Sociedad</h2>
                <span class="category-count">14</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">üèõ</span>
                    <h3 class="paper-title">Ô∏è La Tragedia de la Productividad: Un Marco Unificado para Diagnosticar Fallas de Coordinaci√≥n en Mercados Laborales y Gobernanza de IA</h3>
                    <p class="paper-summary">üìù Propone un marco de teor√≠a de juegos con cinco condiciones para diagnosticar &#x27;tragedias estructurales&#x27; de coordinaci√≥n. Aplica el marco a dos problemas: la desconexi√≥n entre productividad y bienestar laboral (trabajadores trabajan el doble de lo predicho por Keynes) y la gobernanza de IA (riesgo existencial). Introduce un &#x27;√çndice de Tragedia&#x27; que muestra que la gobernanza de IA enfrenta dificultades de coordinaci√≥n √≥rdenes de magnitud mayores que el cambio clim√°tico o las armas nucleares.</p>
                    <div class="paper-points">‚Ä¢ Marco te√≥rico unificado para fallas de coordinaci√≥n con 5 condiciones necesarias y suficientes. Aplicaci√≥n a la paradoja productividad-bienestar y a la carrera de desarrollo de IA. √çndice de Tragedia cuantifica la dificultad extrema de coordinaci√≥n en gobernanza de IA.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05995" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Descubriendo Patrones de Indagaci√≥n de Estudiantes en Pr√°ctica Cl√≠nica con Soporte de GenAI: Un An√°lisis de Red Epist√©mica y Miner√≠a de Patrones Secuenciales</h3>
                    <p class="paper-summary">üìù Analiza logs de interacci√≥n de 323 estudiantes de farmacia con pacientes virtuales impulsados por GenAI. Combina An√°lisis de Red Epist√©mica y Miner√≠a de Patrones Secuenciales para entender el desarrollo de competencias cl√≠nicas. Los de alto rendimiento centran la indagaci√≥n en reconocer informaci√≥n cl√≠nicamente relevante e integran construcci√≥n de rapport, mientras los de bajo rendimiento caen en bucles de verificaci√≥n. Factores demogr√°ficos como lengua materna y experiencia moldean los patrones.</p>
                    <div class="paper-points">‚Ä¢ Metodolog√≠a innovadora que combina dos t√©cnicas de an√°lisis de aprendizaje (ENA y SPM) en educaci√≥n m√©dica. Identificaci√≥n de patrones estrat√©gicos vs. rutinarios en la indagaci√≥n cl√≠nica. Implicaciones para el dise√±o de sistemas GenAI adaptativos y evaluaci√≥n formativa en salud.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06018" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">‚è≥ Futurizaci√≥n de Protocolos: Especulando sobre Din√°micas de Segundo Orden de Protocolos en Futuros Infraestructurales Sociot√©cnicos</h3>
                    <p class="paper-summary">üìù Introduce &#x27;Protocol Futuring&#x27;, un marco metodol√≥gico de dise√±o especulativo que pone a los protocolos (reglas, est√°ndares) como material central de investigaci√≥n. En lugar de artefactos, estudia c√≥mo los protocolos acumulan &#x27;deriva&#x27;, &#x27;bloqueos&#x27; y otros efectos de segundo orden a escalas temporales largas. Se demuestra con un taller (Knowledge Futurama) sobre preservaci√≥n del conocimiento a escala milenial, mostrando c√≥mo los protocolos se transforman al pasar entre comunidades y √©pocas.</p>
                    <div class="paper-points">‚Ä¢ Marco metodol√≥gico para especular sobre la evoluci√≥n a largo plazo de protocolos sociot√©cnicos. Caso de estudio revela efectos de reinterpretaci√≥n
‚Ä¢  normas culturales cambiantes y din√°micas de crisis. Hace visible la pol√≠tica infraestructural y las consecuencias de largo plazo del dise√±o de protocolos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06108" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üèôÔ∏è El Papel de las Ciudades Inteligentes en el Marco de Dise√±o √âtico</h3>
                    <p class="paper-summary">üìù Discute los desaf√≠os √©ticos de las ciudades inteligentes (privacidad, equidad, inclusi√≥n, transparencia) utilizando el marco de Beard y Longstaff. Analiza principios de autodeterminaci√≥n, justicia, accesibilidad y prop√≥sito a trav√©s de estudios de caso. Recomienda adoptar &#x27;sandboxes&#x27; regulatorios, fomentar la gobernanza participativa y cerrar brechas digitales para alinear el desarrollo de ciudades inteligentes con valores sociales inclusivos.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis √©tico de ciudades inteligentes usando un marco estructurado (Beard &amp
‚Ä¢  Longstaff). Enfoque en dilemas de gobernanza
‚Ä¢  roles de las partes interesadas y modelos de implementaci√≥n. Recomendaciones pr√°cticas como sandboxes regulatorios y gobernanza participativa para un desarrollo urbano √©tico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06336" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üí¨ Por Qu√© Discrepan: Descifrando las Diferencias de Opini√≥n sobre el Riesgo de la IA en el Podcast de Lex Fridman</h3>
                    <p class="paper-summary">üìù Analiza debates contempor√°neos sobre riesgo de IA (&#x27;doomers&#x27; vs &#x27;boomers&#x27;) descomponiendo las posturas en premisas definicionales, f√°cticas, causales y morales. Las diferencias sobre riesgo existencial (X-risk) surgen de premisas causales sobre dise√±o vs. emergencia en sistemas complejos. Las discrepancias sobre riesgo laboral (E-risk) se relacionan con la aplicabilidad de teor√≠as del pasado (evoluci√≥n vs. revoluci√≥n). Ambos desacuerdos comparten que no son sobre valores morales, sino sobre los l√≠mites de la racionalidad humana.</p>
                    <div class="paper-points">‚Ä¢ Marco anal√≠tico para desglosar cadenas de razonamiento en debates de riesgo (definici√≥n
‚Ä¢  hechos
‚Ä¢  causas
‚Ä¢  moral). Identificaci√≥n de puntos clave de desacuerdo en riesgo existencial y laboral de la IA. Metodolog√≠a escalable usando LLMs para analizar datos textuales de debates p√∫blicos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06350" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">La Variable Faltante: Alineaci√≥n Socio-T√©cnica en la Evaluaci√≥n de Riesgos</h3>
                    <p class="paper-summary">üìù El art√≠culo identifica una brecha cr√≠tica en la evaluaci√≥n de riesgos de sistemas cr√≠ticos para la seguridad habilitados por IA, que funcionan como sistemas socio-t√©cnicos complejos. Se introduce una variable de alineaci√≥n socio-t√©cnica (STASTA) para integrar en la ecuaci√≥n de riesgo fundamental, estimando la interacci√≥n armoniosa entre la IA, operadores humanos y procesos organizacionales. Un estudio de caso en un sistema de bunkering de hidr√≥geno l√≠quido demuestra c√≥mo esta variable capta implicaciones de seguridad que los m√©todos tradicionales pasan por alto.</p>
                    <div class="paper-points">‚Ä¢ Brecha en evaluaci√≥n de riesgo socio-t√©cnico
‚Ä¢  Variable STASTA
‚Ä¢  Caso de estudio con sistema de hidr√≥geno l√≠quido
‚Ä¢  Evaluaci√≥n hol√≠stica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06354" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">C√≥digo vs. Contexto: La Resistencia de Estudiantes STEM a Cursos No T√©cnicos</h3>
                    <p class="paper-summary">üìù Investiga la resistencia de estudiantes de ingenier√≠a y ciencias de la computaci√≥n a cursos no t√©cnicos. La &#x27;Ambiguidad de Rol&#x27; (incongruencia con la identidad profesional emergente) es el predictor m√°s fuerte de la resistencia afectiva, superando la sobrecarga de trabajo y el costo del cambio cognitivo. La resistencia afectiva reduce la voluntad de participar, lo que a su vez afecta la adopci√≥n a largo plazo de habilidades blandas.</p>
                    <div class="paper-points">‚Ä¢ Ambiguidad de rol como principal predictor
‚Ä¢  Encuesta a 212 estudiantes
‚Ä¢  Impacto en voluntad de participar y adopci√≥n
‚Ä¢  Recomendaciones para contextualizar cursos de humanidades.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06529" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">¬øVisualidad gen√©rica de la guerra? C√≥mo los modelos de IA generativa (mis)representan la guerra de Rusia contra Ucrania</h3>
                    <p class="paper-summary">üìù Audita c√≥mo dos modelos generativos de im√°genes (Midjourney de EE.UU. y Kandinsky de Rusia) representan episodios ficticios y factuales de la guerra en Ucrania. Encuentra variaci√≥n en la representaci√≥n debido a factores contextuales entre modelos y dentro de un mismo modelo, pero tambi√©n patrones consistentes que pueden contribuir a una homogeneizaci√≥n de la est√©tica de la guerra.</p>
                    <div class="paper-points">‚Ä¢ Comparaci√≥n entre modelos occidental y no occidental
‚Ä¢  An√°lisis de est√©tica y contenido
‚Ä¢  Riesgo de homogeneizaci√≥n y sanitizaci√≥n de la violencia
‚Ä¢  Caso de estudio de guerra moderna.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06570" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîí</span>
                    <h3 class="paper-title">¬øCu√°ndo Funciona la Regulaci√≥n por Seguros? El Caso de la IA de Frontera</h3>
                    <p class="paper-summary">üìù Desarrolla un marco para evaluar cu√°ndo la adopci√≥n de seguros puede tener un efecto regulatorio neto (reduciendo da√±os) en lugar de un efecto de riesgo moral. Identifica distorsiones como insolvencia, din√°micas competitivas y sesgos conductuales que crean el potencial. Aplica el marco a la industria de IA de frontera, sugiriendo que puede ser efectiva para riesgos catastr√≥ficos no relacionados con productos.</p>
                    <div class="paper-points">‚Ä¢ Marco para &#x27
‚Ä¢ regulaci√≥n por seguros&#x27
‚Ä¢ 
‚Ä¢  Potencial para IA de frontera
‚Ä¢  Enfoque en riesgos catastr√≥ficos
‚Ä¢  Recomendaci√≥n de mandatos dise√±ados cuidadosamente.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06597" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">IyaCare: Una Plataforma Integrada de IA-IoT-Blockchain para la Salud Materna en Entornos de Recursos Limitados</h3>
                    <p class="paper-summary">üìù Presenta IyaCare, una prueba de concepto que integra IA (para predicci√≥n de riesgo), IoT (para monitoreo de signos vitales) y blockchain (para registros seguros) en una sola plataforma para salud materna en entornos de bajos recursos. Logra 85.2% de precisi√≥n en predicci√≥n de alto riesgo e integridad de datos en blockchain, con funcionalidad fuera de l√≠nea y comunicaci√≥n por SMS.</p>
                    <div class="paper-points">‚Ä¢ Plataforma integrada para salud materna
‚Ä¢  85.2% precisi√≥n en predicci√≥n de riesgo
‚Ä¢  Dise√±ada para bajos recursos
‚Ä¢  Contribuye a los ODS.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07333" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Inteligencia Artificial y Proliferaci√≥n de Armas Nucleares: La Carrera Armamentista Tecnol√≥gica por la (In)visibilidad</h3>
                    <p class="paper-summary">üìù Analiza c√≥mo la IA est√° intensificando una carrera tecnol√≥gica entre tecnolog√≠as que habilitan la proliferaci√≥n (PET) y tecnolog√≠as que mejoran la detecci√≥n (DET). Desarrolla un modelo formal con un √çndice de Ventaja Relativa (RAI) para cuantificar este equilibrio. Simulaciones muestran que el avance asim√©trico, impulsado por la IA en las PET, expande la incertidumbre sobre la detectabilidad de la proliferaci√≥n nuclear.</p>
                    <div class="paper-points">‚Ä¢ Carrera entre PETs y DETs
‚Ä¢  Modelo con √çndice de Ventaja Relativa (RAI)
‚Ä¢  Impacto de la IA en la proliferaci√≥n
‚Ä¢  Simulaciones de riesgo de proliferaci√≥n.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07487" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Un Marco para la Valoraci√≥n y Monetizaci√≥n de Datos</h3>
                    <p class="paper-summary">üìù Introduce un marco unificado de valoraci√≥n de datos que integra perspectivas econ√≥micas, de gobernanza y estrat√©gicas. Combina puntuaci√≥n cualitativa, estimaci√≥n basada en coste/utilidad, indexaci√≥n de relevancia/calidad y ponderaci√≥n multicriterio. El marco, anclado en el Cuadro de Mando Integral (BSC), ayuda a evaluar el potencial de monetizaci√≥n a trav√©s de diferentes v√≠as (Data-as-a-Service, etc.).</p>
                    <div class="paper-points">‚Ä¢ Marco integrado de valoraci√≥n de datos
‚Ä¢  Basado en Balanced Scorecard (BSC)
‚Ä¢  Utiliza proceso de red anal√≠tica (ANP)
‚Ä¢  Desarrollado en proyecto DATAMITE.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07664" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">La Ingenier√≠a de Agentes Confiables Debe Integrar Principios Organizacionales Compatibles con M√°quinas</h3>
                    <p class="paper-summary">üìù Argumenta que para dise√±ar agentes de IA (LLM) confiables, se deben considerar principios de la ciencia de las organizaciones humanas. Examina paralelos en dise√±o, escalado y gesti√≥n organizacional, proponiendo tres principios para equilibrar agencia/capacidades, restricciones de recursos/rendimiento, y mecanismos internos/externos en sistemas agentivos.</p>
                    <div class="paper-points">‚Ä¢ Principios organizacionales para agentes de IA
‚Ä¢  Equilibrio entre agencia y capacidades
‚Ä¢  Lecciones de ciencia de organizaciones
‚Ä¢  Mejora de la fiabilidad de sistemas agentivos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07665" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Uso de LLM para Salud Mental: Perspectivas y Valores de Usuarios Basados en Sentimiento desde Discusiones Sociales</h3>
                    <p class="paper-summary">üìù Analiza discusiones en redes sociales sobre el uso de chatbots de LLM para salud mental. Los sentimientos y perspectivas var√≠an seg√∫n la condici√≥n: neurodivergencias (como TDAH) muestran sentimientos positivos y apoyo instrumental, mientras que trastornos de mayor riesgo (esquizofrenia) muestran m√°s negatividad. Identifica valores subyacentes como identidad y autonom√≠a, abogando por dise√±os espec√≠ficos por condici√≥n y sensibles a valores.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis de sentimientos por condici√≥n mental
‚Ä¢  Dise√±o Sensible al Valor (VSD)
‚Ä¢  Neurodivergencia vs. trastornos de alto riesgo
‚Ä¢  Aboga por dise√±os personalizados.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07797" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ingenier√≠a Computacional, Finanzas y Ciencia">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Ingenier√≠a Computacional, Finanzas y Ciencia</h2>
                <span class="category-count">7</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Los Modelos de Lenguaje Peque√±os pueden usar razonamiento matizado para la clasificaci√≥n de investigaci√≥n en ciencias de la salud: Un estudio de caso de oncog√©nesis microbiana</h3>
                    <p class="paper-summary">üìù Eval√∫a la capacidad de los Modelos de Lenguaje Peque√±os (SLMs) para clasificar art√≠culos de investigaci√≥n m√©dica, usando como caso de estudio la literatura sobre virus tipo HMTV/MMTV en c√°ncer de mama. Compara el rendimiento con modelos grandes (LLMs) usando estrategias zero-shot y aprendizaje en contexto (ICL). Los SLMs muestran un rendimiento competitivo, pero sus decisiones pueden verse influenciadas por artefactos textuales, destacando la necesidad de interpretabilidad.</p>
                    <div class="paper-points">‚Ä¢ Evaluaci√≥n de SLMs para clasificaci√≥n de literatura m√©dica especializada. Comparaci√≥n de rendimiento contra LLMs de vanguardia. An√°lisis de la solidez del razonamiento cient√≠fico en los modelos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06502" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Modelo Fundacional para la Inform√°tica de Materiales Policristalinos</h3>
                    <p class="paper-summary">üìù Presenta un modelo fundacional 3D para microestructuras policristalinas, entrenado mediante aprendizaje auto-supervisado a gran escala. El modelo aprende representaciones estructuradas f√≠sicamente de orientaciones cristalogr√°ficas y demuestra una fuerte capacidad de generalizaci√≥n en tareas posteriores, como la predicci√≥n de rigidez homogenizada y la modelizaci√≥n de respuesta no lineal, siendo especialmente √∫til en entornos con datos etiquetados limitados.</p>
                    <div class="paper-points">‚Ä¢ Modelo fundacional 3D entrenado de forma auto-supervisada en 100
‚Ä¢ 000 microestructuras. Evaluaci√≥n en tareas de predicci√≥n de propiedades mec√°nicas. Alta capacidad de transferencia y generalizaci√≥n para el dise√±o de materiales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06770" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Red de Materiales Profunda Basada en Interacciones Conscientes de la Orientaci√≥n, Generalizable a Texturas Cristalogr√°ficas, para Modelado de Policristales y Evoluci√≥n de la Textura</h3>
                    <p class="paper-summary">üìù Introduce un marco (TACS-GNN-ODMN) que mejora la generalizaci√≥n de la Red de Materiales Profunda ODMN para modelar policristales. Combina un esquema de agrupamiento adaptativo a la textura (TACS) con una Red Neuronal de Grafo (GNN) para predecir par√°metros de equilibrio de tensiones. Esto elimina la necesidad de reentrenar para cada textura distinta, permitiendo predicciones precisas de respuesta no lineal y evoluci√≥n de la textura.</p>
                    <div class="paper-points">‚Ä¢ Marco que generaliza el modelo ODMN a diversas texturas cristalogr√°ficas sin reentrenar. Integra un esquema de agrupamiento (TACS) y una GNN. Predice con precisi√≥n respuestas no lineales y evoluci√≥n de la textura.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06779" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìÑ</span>
                    <h3 class="paper-title">üîó MATEX: Un Marco de Multi-Agentes para Explicar Transacciones de Ethereum</h3>
                    <p class="paper-summary">üìù Presenta MATEX, un marco cognitivo de m√∫ltiples agentes dise√±ado para generar explicaciones paso a paso de transacciones complejas de Ethereum. El sistema modela la comprensi√≥n como una investigaci√≥n colaborativa que combina generaci√≥n de hip√≥tesis, recuperaci√≥n de conocimiento externo, s√≠ntesis basada en evidencia y validaci√≥n adversaria, con el objetivo de ofrecer explicaciones fiables y comprensibles para usuarios, desarrolladores y auditores.</p>
                    <div class="paper-points">‚Ä¢ Marco multi-agente para explicar transacciones complejas de blockchain. Genera explicaciones fiables basadas en evidencia on-chain y sem√°ntica del mundo real. Dise√±ado a partir de entrevistas con usuarios
‚Ä¢  desarrolladores y auditores.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06933" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Extracci√≥n de geometr√≠a suave a partir de optimizaci√≥n topol√≥gica SIMP: Enfoque con funci√≥n de distancia signada y preservaci√≥n de volumen</h3>
                    <p class="paper-summary">üìù Propone una nueva metodolog√≠a de post-procesamiento para extraer geometr√≠as de alta calidad a partir de resultados de optimizaci√≥n topol√≥gica basada en densidad. El m√©todo, basado en una funci√≥n de distancia signada (SDF) y funciones de base radial (RBF), genera l√≠mites suaves que preservan la fracci√≥n de volumen y las caracter√≠sticas topol√≥gicas, mejorando la transici√≥n geom√©trica y reduciendo los esfuerzos m√°ximos comparado con m√©todos convencionales.</p>
                    <div class="paper-points">‚Ä¢ M√©todo de post-procesamiento para optimizaci√≥n topol√≥gica basado en SDF y RBF. Genera geometr√≠as suaves preservando volumen y topolog√≠a. Reduce el estr√©s m√°ximo equivalente en un 18% respecto a m√©todos convencionales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06976" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">M√©todo de Elementos Finitos de Balance Arm√≥nico Homogeneizado con Polarizaci√≥n DC</h3>
                    <p class="paper-summary">üìù Extiende el m√©todo de elementos finitos de balance arm√≥nico homogeneizado para manejar se√±ales de excitaci√≥n con un sesgo de corriente continua (DC). Adapta la t√©cnica de homogeneizaci√≥n para tener en cuenta mejor la saturaci√≥n ferromagn√©tica, utilizando una tabla de b√∫squeda derivada de simulaciones 1D. El m√©todo reduce dr√°sticamente los grados de libertad y el tiempo de simulaci√≥n, manteniendo una buena precisi√≥n en la predicci√≥n de p√©rdidas y energ√≠a magn√©tica.</p>
                    <div class="paper-points">‚Ä¢ Extensi√≥n del m√©todo homogeneizado para incluir polarizaci√≥n DC en simulaciones de corrientes par√°sitas. Reduce √≥rdenes de magnitud en el tiempo de simulaci√≥n (de d√≠as a 90 minutos). Mantiene precisi√≥n en la predicci√≥n de p√©rdidas y saturaci√≥n magn√©tica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06978" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">Herramientas de Computaci√≥n Blanda para Predecir Componentes de Peso Variado, y Propiedades Materiales y Tribol√≥gicas de Al2219-B4C-Gr</h3>
                    <p class="paper-summary">üìù Emplea herramientas de computaci√≥n blanda (l√≥gica difusa, √°rboles de decisi√≥n, algoritmos gen√©ticos) para predecir la composici√≥n √≥ptima y las propiedades mec√°nicas/tribol√≥gicas del material compuesto Al2219 con refuerzos de B4C y grafito. Los algoritmos gen√©ticos multi-objetivo NSGA II optimizan las propiedades, mostrando que la inclusi√≥n de B4C tiene un mayor impacto en la mejora de la resistencia mec√°nica y al desgaste que el grafito.</p>
                    <div class="paper-points">‚Ä¢ Uso de computaci√≥n blanda para predecir y optimizar composiciones y propiedades de materiales compuestos. El refuerzo de B4C impacta m√°s en las propiedades mec√°nicas que el grafito. Resultados comparables con estudios previos de redes neuronales y experimentales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07063" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Computaci√≥n Neuronal y Evolutiva">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Computaci√≥n Neuronal y Evolutiva</h2>
                <span class="category-count">6</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">ü§ñ</span>
                    <h3 class="paper-title">Un Enfoque de Optimizaci√≥n Multi-objetivo para la Selecci√≥n de Caracter√≠sticas en Sistemas Genteligentes</h3>
                    <p class="paper-summary">üìù Propone un marco h√≠brido con un algoritmo evolutivo multi-objetivo para optimizar simult√°neamente la selecci√≥n de caracter√≠sticas y el rendimiento de clasificaci√≥n en sistemas de fabricaci√≥n &#x27;genteligentes&#x27;. El enfoque ayuda a monitorizar operaciones con objetivos conflictivos y se valida con dos conjuntos de datos industriales reales, demostrando generalizabilidad y efectividad.</p>
                    <div class="paper-points">‚Ä¢ Sistemas genteligentes en fabricaci√≥n
‚Ä¢  Algoritmo evolutivo multi-objetivo
‚Ä¢  Selecci√≥n de caracter√≠sticas y clasificaci√≥n simult√°nea
‚Ä¢  Validaci√≥n con datos industriales reales.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05971" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß¨</span>
                    <h3 class="paper-title">SEB-ChOA: Un Algoritmo de Optimizaci√≥n de Chimpanc√©s Mejorado Usando Comportamiento de Explotaci√≥n Espiral</h3>
                    <p class="paper-summary">üìù Mejora el algoritmo de optimizaci√≥n de chimpanc√©s (ChOA) introduciendo seis funciones espirales y dos funciones h√≠bridas novedosas (SEB-ChOA) para superar la convergencia lenta y prematura. Eval√∫a el rendimiento en m√°s de 65 benchmarks est√°ndar y problemas de ingenier√≠a, mostrando resultados de primer nivel y un desempe√±o competitivo con los ganadores de competiciones recientes.</p>
                    <div class="paper-points">‚Ä¢ Algoritmo de optimizaci√≥n inspirado en la naturaleza
‚Ä¢  Funciones espirales h√≠bridas (SEB-ChOA)
‚Ä¢  Evaluaci√≥n extensa en benchmarks est√°ndar y problemas de ingenier√≠a
‚Ä¢  Rendimiento superior o comparable a optimizadores establecidos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.05981" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üìä</span>
                    <h3 class="paper-title">Regularizaci√≥n Entr√≥pica en la Red Lineal Profunda</h3>
                    <p class="paper-summary">üìù Estudia la regularizaci√≥n para redes lineales profundas usando una f√≥rmula de entrop√≠a. Caracteriza los equilibrios y el flujo gradiente de la energ√≠a libre en la variedad Riemanniana de mapas extremo a extremo, mostrando que los √∫nicos equilibrios son minimizadores. El flujo gradiente se reduce a una ecuaci√≥n diferencial ordinaria unidimensional que proporciona tasas de relajaci√≥n expl√≠citas.</p>
                    <div class="paper-points">‚Ä¢ Regularizaci√≥n entr√≥pica
‚Ä¢  Red lineal profunda (DLN)
‚Ä¢  Geometr√≠a Riemanniana
‚Ä¢  Flujo gradiente unidimensional y tasas de relajaci√≥n expl√≠citas.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06137" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üß†</span>
                    <h3 class="paper-title">Neuro-Ves√≠culas: La Neuromodulaci√≥n Deber√≠a Ser un Sistema Din√°mico, No una Decoraci√≥n Tensorial</h3>
                    <p class="paper-summary">üìù Introduce Neuro-Ves√≠culas, un marco que aumenta las redes neuronales con una poblaci√≥n din√°mica de ves√≠culas m√≥viles y discretas que interact√∫an de manera estoc√°stica con la red. Estas ves√≠culas, que emiten, migran, se acoplan y liberan contenido, permiten una neuromodulaci√≥n emergente y estructurada, ofreciendo un puente entre mecanismos densos tipo atenci√≥n y agentes m√≥viles escasos.</p>
                    <div class="paper-points">‚Ä¢ Marco de ves√≠culas neuromoduladoras
‚Ä¢  Interacci√≥n estoc√°stica y basada en eventos
‚Ä¢  Din√°mica de reacci√≥n-difusi√≥n en grafos
‚Ä¢  Extensible a redes de picos y hardware neurom√≥rfico.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.06966" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">‚ö°</span>
                    <h3 class="paper-title">Plasticidad Controlada por Sincron√≠a con Modulaci√≥n de Dopamina para Redes Neuronales de Picos</h3>
                    <p class="paper-summary">üìù Presenta DA-SSDP, una regla de aprendizaje local basada en sincron√≠a de picos y modulada por dopamina para redes neuronales de picos (SNNs). Condensa patrones de picos en una m√©trica de sincron√≠a que se relaciona con la p√©rdida de la tarea, actuando como una puerta que ajusta la magnitud de la actualizaci√≥n local. Logra mejoras de precisi√≥n en varios benchmarks con una sobrecarga computacional menor.</p>
                    <div class="paper-points">‚Ä¢ Regla de aprendizaje local DA-SSDP
‚Ä¢  M√©trica de sincron√≠a de picos
‚Ä¢  Modulaci√≥n por dopamina y p√©rdida
‚Ä¢  Mejoras de precisi√≥n en CIFAR e ImageNet.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07194" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

                <article class="paper-card">
                    <span class="paper-emoji">üîå</span>
                    <h3 class="paper-title">Co-dise√±o Algoritmo-Hardware de Redes Neurom√≥rficas con V√≠as de Memoria Dual</h3>
                    <p class="paper-summary">üìù Propone una arquitectura de v√≠a de memoria dual (DMP) inspirada en la organizaci√≥n cortical r√°pida-lenta del cerebro, que combina actividad de picos r√°pida con un estado de memoria compacto y expl√≠cito. A nivel de hardware, introduce una arquitectura de computaci√≥n cercana a la memoria que optimiza el flujo de datos, logrando mejoras de m√°s de 4x en rendimiento y 5x en eficiencia energ√©tica respecto al estado del arte.</p>
                    <div class="paper-points">‚Ä¢ Arquitectura de v√≠a de memoria dual (DMP)
‚Ä¢  Estado de memoria compacto y expl√≠cito
‚Ä¢  Co-dise√±o algoritmo-hardware
‚Ä¢  Mejoras significativas en rendimiento y eficiencia energ√©tica.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07602" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

        <section class="category" data-category="Ingenier√≠a del Software">
            <div class="category-header">
                <span style="font-size: 1.5rem;">üìÑ</span>
                <h2 class="category-title">Ingenier√≠a del Software</h2>
                <span class="category-count">1</span>
            </div>
            
            <div class="papers-grid">

                <article class="paper-card">
                    <span class="paper-emoji">üíª</span>
                    <h3 class="paper-title">Estudiar el rol de la reutilizaci√≥n del conocimiento de la crowdsourcing en el desarrollo de software</h3>
                    <p class="paper-summary">üìù Este trabajo investiga el impacto de reutilizar conocimiento de plataformas de crowdsourcing (como Stack Overflow) en proyectos de software. Los estudios emp√≠ricos a gran escala muestran que, si bien esta pr√°ctica puede aumentar la productividad, tambi√©n afecta negativamente la calidad del software, generando sobrecarga de dependencias y mayor esfuerzo de mantenimiento. Los hallazgos se utilizan para examinar y mejorar m√©todos de aseguramiento de calidad, como la integraci√≥n continua.</p>
                    <div class="paper-points">‚Ä¢ An√°lisis del impacto de la reutilizaci√≥n de conocimiento de crowdsourcing (Stack Overflow
‚Ä¢  npm). Identificaci√≥n de efectos negativos en la calidad del software. Propuesta de mejora de la integraci√≥n continua para mitigar riesgos.</div>
                    <div class="paper-footer">
                        <a href="https://arxiv.org/pdf/2512.07824" class="paper-link" target="_blank" rel="noopener">
                            üìñ Leer Paper
                        </a>
                        <span class="paper-date">2025-12-09</span>
                    </div>
                </article>

            </div>
        </section>

    </main>

    <footer class="footer">
        <p>üî¨ Portal generado autom√°ticamente desde arXiv ‚Ä¢ 09 de December de 2025</p>
        <p>Procesado por TagUI + DeepSeek AI</p>
    </footer>

    <button class="scroll-top" onclick="scrollToTop()">‚Üë</button>

    <script>
        // Mostrar bot√≥n de scroll to top
        window.addEventListener('scroll', function() {
            const scrollTop = document.querySelector('.scroll-top');
            if (window.pageYOffset > 300) {
                scrollTop.classList.add('visible');
            } else {
                scrollTop.classList.remove('visible');
            }
        });

        // Funci√≥n para scroll to top
        function scrollToTop() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        }

        // Animaci√≥n de entrada para las tarjetas
        const observer = new IntersectionObserver((entries) => {
            entries.forEach((entry) => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        });

        document.querySelectorAll('.paper-card').forEach((card) => {
            card.style.opacity = '0';
            card.style.transform = 'translateY(20px)';
            card.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(card);
        });

        // Dropdown functionality
        const dropdown = document.getElementById('categoryDropdown');
        const dropdownToggle = dropdown.querySelector('.dropdown-toggle');
        const categories = document.querySelectorAll('.category');
        const papersCount = document.getElementById('papersCount');
        
        dropdownToggle.addEventListener('click', function() {
            dropdown.classList.toggle('open');
        });

        function filterByCategory(category) {
            const dropdownItems = document.querySelectorAll('.dropdown-item');
            dropdownItems.forEach(item => item.classList.remove('active'));
            event.target.classList.add('active');
            
            if (category === 'all') {
                categories.forEach(cat => cat.style.display = 'block');
                dropdownToggle.textContent = 'Filtrar por categor√≠a';
                papersCount.textContent = `Mostrando 239 papers en 7 categor√≠as`;
            } else {
                let visiblePapers = 0;
                categories.forEach(cat => {
                    if (cat.dataset.category === category) {
                        cat.style.display = 'block';
                        visiblePapers += cat.querySelectorAll('.paper-card').length;
                    } else {
                        cat.style.display = 'none';
                    }
                });
                dropdownToggle.textContent = category;
                papersCount.textContent = `Mostrando ${visiblePapers} papers en 1 categor√≠a`;
            }
            dropdown.classList.remove('open');
        }

        // Close dropdown when clicking outside
        document.addEventListener('click', function(e) {
            if (!dropdown.contains(e.target)) {
                dropdown.classList.remove('open');
            }
        });
    </script>
</body>
</html>
